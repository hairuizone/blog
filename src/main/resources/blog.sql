DROP TABLE artical;
CREATE TABLE artical
(
  ID            int NOT NULL AUTO_INCREMENT COMMENT '' 自增主键 '',
  AUTHOR        varchar(255) COMMENT '' 作者 '',
  ORIGINAUTHOR  varchar(255) COMMENT '' 原文作者 '',
  ORIGINURL     varchar(255) COMMENT '' 原文URL '',
  TITTLE        varchar(255) COMMENT '' 标题 '',
  IMGPATH       varchar(50) COMMENT '' 背景图片路径 '',
  CONTENT       longtext COMMENT '' 内容 '',
  TAGS          varchar(255) COMMENT '' 标签 '',
  NAVID         int COMMENT '' 导航编号 '',
  TOPICID       varchar(255) COMMENT '' 专题编号 '',
  CATEGORIES    int COMMENT '' 分类 '',
  TYPE          varchar(255) COMMENT '' 类型（原创/转载）'',
  CREATEDATE    varchar(50) COMMENT '' 创建日期 '',
  UPDATEDATE    varchar(50) COMMENT '' 更新日期 '',
  ARTICALURL    varchar(100) COMMENT '' 文章URL '',
  SUMMARY       varchar(500) COMMENT '' 摘要 '',
  LASTARTICALID bigint COMMENT '' 上一篇文章编号 '',
  NEXTARTICALID bigint COMMENT '' 下一篇文章编号 '',
  LIKENUMS      int COMMENT '' 喜欢 '',
  DISSNUMS      int COMMENT '' 不喜欢 '',
  INTOP         varchar(1) COMMENT '' 是否置顶 '',
  PRIMARY KEY (ID)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='' 文章 '';
INSERT INTO artical (ID, AUTHOR, ORIGINAUTHOR, ORIGINURL, TITTLE, IMGPATH, CONTENT, TAGS, NAVID, TOPICID, CATEGORIES,
                     TYPE, CREATEDATE, UPDATEDATE, ARTICALURL, SUMMARY, LASTARTICALID, NEXTARTICALID, LIKENUMS,
                     DISSNUMS, INTOP)
VALUES (1, '' 老干部 '', '' 不详 '', '' http://blog.sina.com.cn/s/blog_b2f22e8b0101b3r0.html '', '' 拥有梦想的时候 拿出勇气和行动 '',
        '' images/2.jpg '', '' > 我们常常听到人们各种各样的梦想，每一个梦想听起来都很美好，但在现实中，我们却很少见到真正坚韧不拔、全力以赴去实现梦想的人。人们热衷于谈论梦想，把它当作一句口头禅，一种对日复一日、枯燥贫乏生活的安慰。很多人带着梦想活了一辈子，却从来没有认真地去尝试实现梦想。

          > 只有人类能够去梦想，并把梦想变成现实。没有梦想就没有精彩的生活，梦想是人们对未来的向往。它意味着还没有体会过的生活，意味着无穷的可能性，意味着意想不到的惊喜，意味着对自己的信心。

          > 可是什么阻止人们去实现自己的梦想呢？

          > 我们听到的理由多如牛毛。比如说想去某地旅游，但没有足够的钱；想学习英语，但没有足够的时间；想要追求某人，但觉得条件还不够成熟等等。人们对于做不成的，或者还没有做的事情，很少把原因归结到自己身上，往往都是习惯性地寻找某个外在的理由，为自己开脱一下，舒口气，然后继续过自己平庸的日子，让梦想躺在身体里的某个角落呼呼大睡。

          > 其实，能否实现自己的梦想，外在因素只占小部分原因，主观因素才是能否实现自己梦想的主要原因。

          > 一个人要实现自己的梦想，最重要的是要具备以下两个条件：勇气和行动。勇气，是指放弃和投入的勇气。一个人要为某个梦想而奋斗，就一定要放弃目前自己坚守的某些东西。既想经历大海的风浪，又想保持小河的平静；既想攀登无限风光的险峰，又想散步平坦舒适的平原，是不太可能的事情。投入，是指一旦确定了值得自己去追求的梦想，就一定要全身心投入。心想不一定事成。事成的前提是全力以赴去做，比如一个人想学游泳，惟一的办法就是一头扎到游泳池里去，也许开始会呛几口水，但最后一定能够学会游泳。

          > 因此，实现梦想的关键是能否果断地采取行动。行动才是最强大的力量。

          > 有一个学生曾经说，他以后想要走遍全世界，变成像徐霞客、马可·波罗那样的旅行家和冒险家，去感受大海一望无际的壮阔，体会沙漠高低起伏的雄浑，探索落日下尼罗河畔金字塔的奥秘，追寻云雾中喜马拉雅之巅的神圣。但是他说现在还没有钱，要等到成了百万富翁以后再去做这些事情。我问了他两个问题，一是如果这辈子没有成为百万富翁还去不去旅行？二是如果成为百万富翁的时候已经老得走不动路了还去不去旅行？我告诉他，最好的办法是现在就上路，拿根棍子拿只碗，一路要饭也能实现自己的梦想。梦想是不能等待的，尤其不能以实现另外一个条件为前提。很多人正是因为陷入了要做这个就必须先做那个的定势思维，最后一辈子在原地转圈，生活再也没有走出过精彩来。

          > 所以，当我们拥有梦想的时候，就要拿出勇气和行动来，穿过岁月的迷雾，让生命展现别样的色彩。'', ''#梦想#/#勇气#'', 2, '' 请选择 '', 5, '' ZZ '', '' 2019-06-17 '',
        null, null,
        '' 我们常常听到人们各种各样的梦想，每一个梦想听起来都很美好，但在现实中，我们却很少见到真正坚韧不拔、全力以赴去实现梦想的人。人们热衷于谈论梦想，把它当作一句口头禅，一种对日复一日、枯燥贫乏生活的安慰。很多人带着梦想活了一辈子，却从来没有认真地去尝试实现梦想。'',
        null, null, 0, 0, null);
INSERT INTO artical (ID, AUTHOR, ORIGINAUTHOR, ORIGINURL, TITTLE, IMGPATH, CONTENT, TAGS, NAVID, TOPICID, CATEGORIES,
                     TYPE, CREATEDATE, UPDATEDATE, ARTICALURL, SUMMARY, LASTARTICALID, NEXTARTICALID, LIKENUMS,
                     DISSNUMS, INTOP)
VALUES (2, '' 老干部 '', '' 戴登国 '', '' http://blog.sina.com.cn/s/articlelist_1237731013_10_1.html '', '' 好的心态，是最大的财富 '',
        '' images/6.jpg '', ''## 烦恼的根源都在自己
          生气，是因为你不够大度；

          郁闷，是因为你不够豁达；

          焦虑，是因为你不够从容；

          悲伤，是因为你不够坚强；

          惆怅，是因为你不够阳光；

          嫉妒，是因为你不够优秀。

          凡此种种烦恼的根源都在自己这里，

          所以，每一次烦恼的出现，

          都是一个给我们寻找自己缺点的机会。

          ## 越计较越痛苦
          人生，

          有多少计较，就有多少痛苦；

          有多少宽容，就有多少欢乐。

          痛苦与欢乐都是心灵的折射，

          就像镜子里面有什么，

          决定于镜子面前的事物。

          心里放不下，自然成了负担，

          负担越多，人生越不快乐。

          计较的心如同口袋，宽容的心犹如漏斗。

          复杂的心爱计较，简单的心易快乐。

          ## 抱怨是一种毒药。
          它摧毁你的意志，削减你的热情。

          抱怨命运不如改变命运，

          抱怨生活不如改善生活，

          毕竟抱怨≠解决。

          凡事多找方法，少找借口，

          强者不是没有眼泪，

          而是含着眼泪在奔跑!

          ## 无怨无悔
          人生无悔便是道，人生无怨便是德。

          得到的要珍惜；失去的就放弃。

          过多的在乎会将人生的乐趣减半，

          看淡了，一切也就释然了。

          执着其实是一种负担，甚至是一种苦楚，

          计较得太多就成了一种羁绊，迷失太久便成了一种痛苦。

          放弃，不是放弃追求，

          而是让我们以豁达的心去面对生活。

          ## 心好，一切都好
          心态好，人缘就好，因为懂得宽容；

          心态好，做事顺利，因为不拘小节；

          心态好，生活愉快，因为懂得放下。

          别让脾气和本事一样大，越有本事的人越没脾气。

          心态好的人，处处圆融，处处圆满。

          好的心态，能激发人生最大的潜能，是你最大的财富。'', ''#心态#/#财富#'', 2, '' 请选择 '', 5, '' ZZ '', '' 2019-06-17 '', '' 2019-06-17 '',
        null,
        '' 烦恼的根源都在自己。生气，是因为你不够大度；郁闷，是因为你不够豁达；焦虑，是因为你不够从容；悲伤，是因为你不够坚强；惆怅，是因为你不够阳光；嫉妒，是因为你不够优秀。凡此种种烦恼的根源都在自己这里，所以，每一次烦恼的出现，都是一个给我们寻找自己缺点的机会。'',
        null, null, 0, 0, null);
INSERT INTO artical (ID, AUTHOR, ORIGINAUTHOR, ORIGINURL, TITTLE, IMGPATH, CONTENT, TAGS, NAVID, TOPICID, CATEGORIES,
                     TYPE, CREATEDATE, UPDATEDATE, ARTICALURL, SUMMARY, LASTARTICALID, NEXTARTICALID, LIKENUMS,
                     DISSNUMS, INTOP)
VALUES (3, '' 老干部 '', '''', '''', '' 谁也不知道明天会发生什么 '', '' images/2.jpg '', '' >
                                                                          生活如同一场赛跑，我们都是参赛选手，目标都是跑向终点，但在这个过程中，也许我们会经历很多的困苦和磨难，但幸运的是，我们都还在继续，我们终将为了我们最初的理想而持之以恒的走下去，不论明天会发生什么，也不论我们能否如愿，只要经历了，我们就无悔。'',
        ''#期待#'', 1, '' 请选择 '', 1, '' YC '', '' 2019-06-18 '', null, null,
        '' 生活如同一场赛跑，我们都是参赛选手，目标都是跑向终点，但在这个过程中，也许我们会经历很多的困苦和磨难，但幸运的是，我们都还在继续，我们终将为了我们最初的理想而持之以恒的走下去，不论明天会发生什么，也不论我们能否如愿，只要经历了，我们就无悔。'',
        null, null, 0, 0, null);
INSERT INTO artical (ID, AUTHOR, ORIGINAUTHOR, ORIGINURL, TITTLE, IMGPATH, CONTENT, TAGS, NAVID, TOPICID, CATEGORIES,
                     TYPE, CREATEDATE, UPDATEDATE, ARTICALURL, SUMMARY, LASTARTICALID, NEXTARTICALID, LIKENUMS,
                     DISSNUMS, INTOP)
VALUES (4, '' 老干部 '', '' 老舍 '', '' https://toutiao.sanhao.com/m/news-detail-12571.html '', '' 宗月大师 '',
        '' images/8.jpg '', ''　　在我小的时候，我因家贫而身体很弱。我九岁才入学。因家贫体弱，母亲有时候想教我去上学，又怕我受人家的欺侮，更因交不上学费，所以一直到九岁我还不识一个字。说不定，我会一辈子也得不到读书的机会。因为母亲虽然知道读书的重要，可是每月间三四吊钱的学费，实在让她为难。


          　　母亲是最喜脸面的人。她迟疑不决，光阴又不等待着任何人，荒来荒去，我也许就长到十多岁了。一个十多岁的贫而不识字的孩子，很自然的去作个小买卖——弄个小筐，卖些花生、煮豌豆、或樱桃什么的。要不然就是去学徒。母亲很爱我，但是假若我能去作学徒，或提篮沿街卖樱桃而每天赚几百钱，她或者就不会坚决的反对。穷困比爱心更有力量。


          　　有一天刘大叔偶然的来了。我说“偶然的”，因为他不常来看我们。他是个极富的人，尽管他心中并无贫富之别，可是他的财富使他终日不得闲，几乎没有工夫来看穷朋友。一进门，他看见了我。“孩子几岁了？上学没有？”他问我的母亲。他的声音是那么洪亮，（在酒后，他常以学喊俞振庭的《金钱豹》自傲）他的衣服是那么华丽，他的眼是那么亮，他的脸和手是那么白嫩肥胖，使我感到我大概是犯了什么罪。我们的小屋，破桌凳，土炕，几乎禁不住他的声音的震动。等我母亲回答完，刘大叔马上决定：“明天早上我来，带他上学，学钱、书籍，大姐你都不必管！”我的心跳起多高，谁知道上学是怎么一回事呢！


          　　第二天，我象一条不体面的小狗似的，随着这位阔人去入学。学校是一家改良私垫，在离我的家有半里多地的一座道士庙里。庙不甚大，而充满了各种气味：一进山门先有一股大烟味，紧跟着便是糖精味，（有一家熬制糖球糖块的作坊）再往里，是厕所味，与别的臭味。学校是在大殿里。大殿两旁的小屋住着道士，和道士的家眷。


          　　大殿里很黑、很冷。神像都用黄布挡着，供桌上摆着孔圣人的牌位。学生都面朝西坐着，一共有三十来人。西墙上有一块黑板——这是“改良”私塾。老师姓李，一位极死板而极有爱心的中年人。刘大叔和李老师“嚷”了一顿，而后教我拜圣人及老师。老师给了我一本《地球韵言》和一本《三字经》。我于是，就变成了学生。


          　　自从作了学生以后，我时常的到刘大叔的家中去。他的宅子有两个大院子，院中几十间房屋都是出廊的。院后，还有一座相当大的花园。宅子的左右前后全是他的房屋，若是把那些房子齐齐的排起来，可以占半条大街。此外，他还有几处铺店。每逢我去，他必招呼我吃饭，或给我一些我没有看见过的点心。他绝不以我为一个苦孩子而冷淡我，他是阔大爷，但是他不以富做人。


          　　在我由私塾转入公立学校去的时候，刘大叔又来帮忙。这时候，他的财产已大半出了手。他是阔大爷，他只懂得花钱，而不知道计算。人们吃他，他甘心教他们吃；人们骗他，他付之一笑。他的财产有一部分是卖掉的，也有一部分是被人骗了去的。他不管；他的笑声照旧是洪亮的。


          　　到我在中学毕业的时候，他已一贫如洗，什么财产也没有了，只剩了那个后花园。不过，在这个时候，假若他肯用用心思，去调整他的产业，他还能有办法教自己丰衣足食，因为他的好多财产是被人家骗了去的。可是，他不肯去请律师。贫与富在他心中是完全一样的。假若在这时候，他要是不再随便花钱，他至少可以保住那座花园，和城外的地产。可是，他好善。尽管他自己的儿女受着饥寒，尽管他自己受尽折磨，他还是去办贫儿学校，粥厂，等等慈善事业。他忘了自己。


          　　就是在这个时候，我和他过往的最密。他办贫儿学校，我去作义务教师。他施舍粮米，我去帮忙调查及散放。在我的心里，我很明白：放粮放钱不过只是延长贫民的受苦难的日期，而不足以阻拦住死亡。但是，看刘大叔那么热心，那么真诚，我就顾不得和他辩论，而只好也出点力了。即使我和他辩论，我也不会得胜，人情是往往能战败理智的。


          　　在我出国以前，刘大叔的儿子死了。而后，他的花园也出了手。他入庙为僧，夫人与小姐入庵为尼。由他的性格来说，他似乎势必走入避世学掸的一途。但是由他的生活习惯上来说，大家总以为他不过能念念经，布施布施僧道而已，而绝对不会受戒出家。他居然出了家。在以前，他吃的是山珍海味，穿的是续罗绸缎。他也嫖也赌。现在，他每日一餐，入秋还穿着件夏布道袍。这样苦修，他的脸上还是红红的，笑声还是洪亮的。对佛学，他有多么深的认识，我不敢说。我却真知道他是个好和尚，他知道一点便去作一点，能作一点便作一点。他的学问也许不高，但是他所知道的都能见诸实行。


          　　出家以后，他不久就作了一座大寺的方丈。可是没有好久就被驱除出来。他是要作真和尚，所以他不惜变卖庙产去救济苦人。庙里不要这种方丈。一般的说，方丈的责任是要扩充庙产，而不是救苦救难的。离开大寺，他到一座没有任何产业的庙里作方丈。他自己既没有钱，他还须天天为僧众们找到斋吃。同时，他还举办粥厂等等慈善事业。他穷，他忙，他每日只进一顿简单的素餐，可是他的笑声还是那么洪亮。


          　　他的庙里不应佛事，赶到有人来请，他便领着僧众给人家去唪真经，不要报酬。他整天不在庙里，但是他并没忘了修持；他持戒越来越严，对经义也深有所获。他白天在各处筹钱办事，晚间在小室里作工夫。谁见到这位破和尚也不曾想到他曾是个在金子里长起来的阔大爷。


          　　去年，有一天他正给一位圆寂了的和尚念经，他忽然闭上了眼，就坐化了。火葬后，人们在他的身上发现许多舍利。


          　　没有他，我也许一辈子也不会入学读书。没有他，我也许永远想不起帮助别人有什么乐趣与意义。他是不是真的成了佛？我不知道。但是，我的确相信他的居心与言行是与佛相近似的。我在精神上物质上都受过他的好处，现在我的确愿意他真的成了佛，并且盼望他以佛心引领我向善，正象在三十五年前，他拉着我去入私塾那样！


          　　他是宗月大师。'', ''#朗读者#/#诗词大会#'', 2, '' 请选择 '', 4, '' ZZ '', '' 2019-06-18 '', '' 2019-06-18 '', null,
        '' 在我小的时候，我因家贫而身体很弱。我九岁才入学。因家贫体弱，母亲有时候想教我去上学，又怕我受人家的欺侮，更因交不上学费，所以一直到九岁我还不识一个字。说不定，我会一辈子也得不到读书的机会。因为母亲虽然知道读书的重要，可是每月间三四吊钱的学费，实在让她为难。'',
        null, null, 0, 0, null);
INSERT INTO artical (ID, AUTHOR, ORIGINAUTHOR, ORIGINURL, TITTLE, IMGPATH, CONTENT, TAGS, NAVID, TOPICID, CATEGORIES,
                     TYPE, CREATEDATE, UPDATEDATE, ARTICALURL, SUMMARY, LASTARTICALID, NEXTARTICALID, LIKENUMS,
                     DISSNUMS, INTOP)
VALUES (5, '' 老干部 '', '' 柳传志 '', '' https://toutiao.sanhao.com/m/news-detail-12574.html '', '' 柳传志给儿子的结婚致辞 '',
        '' images/7.jpg '', ''　　柳林结婚对我们全家来说毫无疑义是头等大事。我的主要任务是把今天的话要讲好，要把方方面面的意思都表达了，还要有点深刻的内容，以便于将来载入家庭史册。所以准备这个讲话还真是费神思的事。


          　　我荣幸地有机会给柳林当父亲有四十几年的历史了，近十余年来，他虽也常有欢笑的时候，我总觉得他的大多数快乐是短暂的，是发自皮肤层面的。多数的时候表情平淡，略有忧郁。而自从和康乐交了朋友以后，感情明显发生变化，随着时间的推进，他的快乐从皮肤进入到了骨髓、筋脉，进入到了五脏六腑。看来康乐的笑容融化在了柳林的心田里面。柳林开始脑门发亮，眉眼中总带着愉悦和笑意。


          　　柳林是个比较成熟稳重的男人，遇事前思后想，不易冲动。柳林的变化我和他妈自然看在眼里。我和柳林交流广泛且深刻，其中关于择偶标准，我和他讨论过无数次，所以只要柳林由衷的高兴、幸福，康乐大致属于什么类型，不用我再做了解，只看柳林的态度，心中已有分晓。


          　　在我家的相亲相爱一家人的微信群中，康乐以前是见习秘书长。今天，公元2016年12月24日起，康乐将正式担任秘书长一职。康乐的阳光将不仅照向柳林，而且洒向全家，为全家的和睦、幸福、昌盛贡献力量。


          　　这时候应该表达感谢了。首先，我们全家、我们整个大家庭对康健民先生、陈秋霞女士能培养出康乐这样善良、贤淑、聪明、能干，形象内涵俱佳的女儿感到由衷地钦佩，更重要的是能把女儿无私地输送到老柳家当儿媳妇，且掌管钥匙，表示万分感谢。对这样无比珍贵的礼物，我们实在无以回报，只能把儿子送到您那儿当女婿，以表达感激之情。柳林还行，以后如果有冬天存储大白菜、搬蜂窝煤这样的重活尽管叫他干，他绝无二话，因为他从小就这么跟着我给他妈干过很多年。


          　　在我们公司考察干部有句行话：叫既要看前门脸也要看后脑勺。前门脸指的是这个人的业绩、能力，他要给人看的地方；后脑勺是人的品行，一般考核不到的地方。


          　　柳林不在我们公司上班，我的注意力不放在他的前门脸上，而是在后脑勺上。如实讲，柳林的后脑勺长得还是很漂亮的。柳林善良、忠厚、孝顺，对朋友讲情义、重承诺，说话幽默，有味儿，而且从不高调，他的朋友都认可他。


          　　在我们大家庭中有一个至高无上的尊者，那就是我的父亲。由于柳林在家族中独苗单传的特殊位置，也由于柳林孝顺善良的性格，爷爷奶奶对他的成长高度关注。在他结婚的重要时刻，我要对他讲的一句深刻的话，就是我父亲送给我的一句话，转送给柳林。


          　　我十七岁高中毕业的时刻，由于家庭成分的原因，发生过一个突然的变故，我曾受到重重的一击，我被完全打懵了。在这时候，父亲和母亲一起和我谈了话。


          　　父亲说：“只要你是一个正直的人，不管你做什么行业，你都是我的好孩子”。父亲的话让我无比温暖，在我的一生中经历坎坷、天上地下、水中火中，但我父亲的这句话，让我直面任何环境坦荡应对。


          　　今天，当我要把这句话转送给儿子的时候，我想加一点补充。正直两个字本身它含了忠诚坦荡、光明磊落等多种真善美的内涵，我想加的半句话是“懂得融通”，也就是说“有理想而不理想化”。


          　　在我懂事成人的上个世纪五十年代，何曾想过今天世界会是这样，而对你们——你和康乐，将面临着一个更大不确定性的未来，真正理解有理想而不理想化也会让你们以强大的心脏面对未来，我想会受益无穷。


          　　每当看到柳林和康乐相视，会心一笑的时候，这种幸福的光环不但笼罩着你们，而且传递到了我们心中。做父母的有什么比儿女生活幸福还幸福的事呢！——尤其是此刻，我从沙场退下来，希望要充分享受天伦之乐的时候。


          　　希望柳林康乐永远相亲相爱。这是柳家的传统，爷爷奶奶、爸爸妈妈、叔叔婶婶，都是这样。我们：我、你妈妈、叔叔婶婶、姑姑都在热烈地、殷切地盼望看你们结下幸福的果实，越多越好！三十多年前有一个电视剧叫阿信，电视剧的开头就是在日本的高速列车上，一个满头银发的老奶奶带她的孙子看她创造的产业帝国。我正殷切地盼望着这一天！'',
        '''', 2, '' 请选择 '', 4, '' ZZ '', '' 2019-06-18 '', '' 2019-06-18 '', null,
        '' 柳林结婚对我们全家来说毫无疑义是头等大事。我的主要任务是把今天的话要讲好，要把方方面面的意思都表达了，还要有点深刻的内容，以便于将来载入家庭史册。所以准备这个讲话还真是费神思的事。'', null, null, 0,
        0, null);
INSERT INTO artical (ID, AUTHOR, ORIGINAUTHOR, ORIGINURL, TITTLE, IMGPATH, CONTENT, TAGS, NAVID, TOPICID, CATEGORIES,
                     TYPE, CREATEDATE, UPDATEDATE, ARTICALURL, SUMMARY, LASTARTICALID, NEXTARTICALID, LIKENUMS,
                     DISSNUMS, INTOP)
VALUES (6, '' 老干部 '', '' 林清玄 '', '' https://toutiao.sanhao.com/m/news-detail-12620.html '', '' 百合花开 '',
        '' images/7.jpg '', ''　　在一个偏僻遥远的山谷里，有一处数千尺高的断崖。不知道什么时候，断崖边上长出了一株小小的百合。


          　　起初，百合长得和野草一模一样。但是，它心里知道自己不是一株野草。它的内心深处有这样一个念头：“我是一株百合，不是野草。唯一能证明我是百合的方法，就是开出美丽的花朵。”


          　　有了这个念头，百合努力地吸收水分和阳光，深深地扎根，直直地挺着胸膛。


          　　终于，在一个春天的清晨，百合的顶部结出了第一个花苞。


          　　百合的心里很高兴，附近的野草却很不屑，它们在私底下嘲笑百合：“这家伙明明是一株草，却偏偏说自己是一株花，我看它顶上结的根本不是花苞，而是长了一个疙瘩……”


          　　在公开场合，它们也嘲笑百合：“你不要做梦了！即使你真的会开花，在这荒郊野外，你的价值还不是跟我们一样。”


          　　偶尔有飞过的蜂蝶鸟雀，它们也会劝百合不用那么努力地开花：“在这断崖边上，纵然开出世界上最美的花，也不会有人来欣赏啊！”


          　　百合说：“我要开花，是因为我知道自己有美丽的花；我要开花，是为了完成作为一株花的庄严生命；我要开花，是由于自己喜欢以花来证明自己的存在。不管有没有人欣赏，不管你们怎么看我，我都要开花！”


          　　在野草和蜂蝶的鄙夷嘲笑下，百合努力地生长着。终于有一天，它开花了。


          　　百合花一朵一朵地盛开着，花朵上每天都有晶莹的水珠，野草们以为那是昨夜的露水；只有百合自己知道，那是极深沉的欢喜所结出的泪滴。它那透着灵性的洁白和秀挺的风姿，成了断崖上最美丽的一道景色。


          　　这时候，野草和蜂蝶再也不嘲笑它了。


          　　此后，年年春天，百合都努力地开花，结籽。它的种子随着风落在山谷、草地和悬崖边上，让那些地方到处都开满洁白的百合。


          　　几十年后，人们从城市，从乡村，千里迢迢赶来欣赏百合开花。孩子们跪下来，快乐地嗅着百合花的芬芳；情侣们手拉着手，许下“百年好合”的誓言……无数的人看到这从未见过的美丽，感动得直落泪。


          　　那里，被人称为“百合谷”。


          　　不管别人怎么欣赏，满山的百合花都谨记着第一株百合的教导：“我们要全心全意默默地开花，用花来证明自己的存在。”'', '''', 2, '' 请选择 '', 4, '' ZZ '', '' 2019-06-18 '',
        '' 2019-06-18 '', null,
        '' 在一个偏僻遥远的山谷里，有一处数千尺高的断崖。不知道什么时候，断崖边上长出了一株小小的百合。起初，百合长得和野草一模一样。但是，它心里知道自己不是一株野草。它的内心深处有这样一个念头：“我是一株百合，不是野草。唯一能证明我是百合的方法，就是开出美丽的花朵。”'',
        null, null, 0, 0, null);
INSERT INTO artical (ID, AUTHOR, ORIGINAUTHOR, ORIGINURL, TITTLE, IMGPATH, CONTENT, TAGS, NAVID, TOPICID, CATEGORIES,
                     TYPE, CREATEDATE, UPDATEDATE, ARTICALURL, SUMMARY, LASTARTICALID, NEXTARTICALID, LIKENUMS,
                     DISSNUMS, INTOP)
VALUES (7, '' 老干部 '', '' 朱自清 '', '' https://toutiao.sanhao.com/m/news-detail-14816.html '', '' 背影 '',
        '' images/2.jpg '', '' 我与父亲不相见已二年余了，我最不能忘记的是他的背影。那年冬天，祖母死了，父亲的差使也交卸了，正是祸不单行的日子，我从北京到徐州，打算跟着父亲奔丧回家。到徐州见着父亲，看见满院狼藉的东西，又想起祖母，不禁簌簌地流下眼泪。父亲说，“事已如此，不必难过，好在天无绝人之路！”

          　　回家变卖典质，父亲还了亏空；又借钱办了丧事。这些日子，家中光景很是惨淡，一半为了丧事，一半为了父亲赋闲。丧事完毕，父亲要到南京谋事，我也要回北京念书，我们便同行。

          　　到南京时，有朋友约去游逛，勾留了一日；第二日上午便须渡江到浦口，下午上车北去。父亲因为事忙，本已说定不送我，叫旅馆里一个熟识的茶房陪我同去。他再三嘱咐茶房，甚是仔细。但他终于不放心，怕茶房不妥帖；颇踌躇了一会。其实我那年已二十岁，北京已来往过两三次，是没有甚么要紧的了。他踌躇了一会，终于决定还是自己送我去。我两三回劝他不必去；他只说，“不要紧，他们去不好！”

          　　我们过了江，进了车站。我买票，他忙着照看行李。行李太多了，得向脚夫行些小费，才可过去。他便又忙着和他们讲价钱。我那时真是聪明过分，总觉他说话不大漂亮，非自己插嘴不可。但他终于讲定了价钱；就送我上车。他给我拣定了靠车门的一张椅子；我将他给我做的紫毛大衣铺好坐位。他嘱我路上小心，夜里警醒些，不要受凉。又嘱托茶房好好照应我。我心里暗笑他的迂；他们只认得钱，托他们直是白托！而且我这样大年纪的人，难道还不能料理自己么？唉，我现在想想，那时真是太聪明了！

          　　我说道，“爸爸，你走吧。”他望车外看了看，说，“我买几个橘子去。你就在此地，不要走动。”我看那边月台的栅栏外有几个卖东西的等着顾客。走到那边月台，须穿过铁道，须跳下去又爬上去。父亲是一个胖子，走过去自然要费事些。我本来要去的，他不肯，只好让他去。我看见他戴着黑布小帽，穿着黑布大马褂，深青布棉袍，蹒跚地走到铁道边，慢慢探身下去，尚不大难。可是他穿过铁道，要爬上那边月台，就不容易了。

          　　他用两手攀着上面，两脚再向上缩；他肥胖的身子向左微倾，显出努力的样子。这时我看见他的背影，我的泪很快地流下来了。我赶紧拭干了泪，怕他看见，也怕别人看见。我再向外看时，他已抱了朱红的橘子望回走了。过铁道时，他先将橘子散放在地上，自己慢慢爬下，再抱起橘子走。到这边时，我赶紧去搀他。他和我走到车上，将橘子一股脑儿放在我的皮大衣上。于是扑扑衣上的泥土，心里很轻松似的，过一会说，“我走了；到那边来信！”我望着他走出去。他走了几步，回过头看见我，说，“进去吧，里边没人。”等他的背影混入来来往往的人里，再找不着了，我便进来坐下，我的眼泪又来了。

          　　近几年来，父亲和我都是东奔西走，家中光景是一日不如一日。他少年出外谋生，独力支持，做了许多大事。那知老境却如此颓唐！他触目伤怀，自然情不能自已。情郁于中，自然要发之于外；家庭琐屑便往往触他之怒。他待我渐渐不同往日。

          　　但最近两年的不见，他终于忘却我的不好，只是惦记着我，惦记着我的儿子。我北来后，他写了一信给我，信中说道，“我身体平安，惟膀子疼痛利害，举箸提笔，诸多不便，大约大去之期不远矣。”我读到此处，在晶莹的泪光中，又看见那肥胖的，青布棉袍，黑布马褂的背影。唉！我不知何时再能与他相见！

          　　朗读者李亚鹏给女儿的信全文

          　　李亚鹏《致女儿李嫣》

          　　出差归来夜已深，嫣儿和母亲都已入睡，我蹑手蹑脚摸黑走到床前，慢慢地俯下身，凑上去想亲嫣儿一下。她突然一个转身，小手“啪”地搭在了我的脸颊上，我便被施了魔法似地定住了：嫣儿小时候我每次抱她，总是想让她的小手搂着我的脖子，可她总是不肯，她的两只小手要指挥着我的方向，要指着她感兴趣的东西，一刻也不肯停闲。现在好了，我终于如愿以偿，感受着小手的温度，享受着这份她对我的依恋，生怕动一下会让她的小手离我而去。眼睛逐渐适应了周围的黑暗，借着床头加湿器上桔红色指示灯的微弱光线，慢慢地能看见她的轮廓，渐渐地能听见她的呼吸，一天的疲惫瞬间不再，难得的一刻清静。

          　　我这些年相当一部分时间在为基金会和医院忙碌着，以致于友人问我怎么真是改行做慈善了，我也只能笑笑。其实无论从我的财富积累还是从我的人生阶段来讲，我都还没到那一步，一切只是因为我的女儿来到我的身边。在美国陪她做手术时，我写下了一句话：“上帝给了你这伤痕，我要让这伤痕成为你的荣耀。”随后便成立了嫣然天使基金。曾经有朋友问我李嫣长大了会不会让她也为基金会工作，我说这是我面对我人生问题时所做的选择，我并无意强加于她，我会非常乐意看到她的加入，我更乐意看到的是将来她敢于接受和面对生活给予她的一切，无论是成功或是失败，无论是鲜花或是鸡蛋。嫣儿，我希望你长大了可以成为这样的人。

          　　十年间，嫣然天使基金已经为一万一千多个儿童实施了全额免费手术。在和这些贫困家庭的接触和交谈中，我感受到了他们对这个社会的宽容和感恩。他们承受着某些不公平却也并没有去抱怨，而当他们得到一点点帮助的时候，他们的身体是颤抖的，他们的眼睛是湿润的，他们会给你深鞠一躬，甚至屈膝下跪。因为他们不善感激的言辞，他们有着人类最原始的韧性和最纯朴的情感。嫣儿，我希望你长大了可以成为这样的人。

          　　你带着上帝给予你的伤痕，出生在这样一个家庭，父母和家人为了你的健康成长，殚精竭虑、百般呵护。但是万万没想到，你用几段小小的视频，自信的笑容，以你自己特有的方式，向世界宣告了你的存在，甚至让我心里最后的一丝不安也完全消失了。你有得，你有失，嫣儿，我希望你长大了以后可以成为独一无二的你自己。

          　　每年新年都会带你登高爬山，你五岁那年一口气爬了七个半小时，十四公里的山路，全程独立完成。我跟在你的后面，心里会纠结着是不是在你背包里放的东西太多了……有时候想，我要对你好一点，有时候又想是不是也不能太好了，不然长大了万一碰不到像我如此对你的人，你会不会因为感觉不到别人的爱而降低了生活的幸福感，可我又想，如果我不给你足够的爱，你长大了又怎么有能力去爱你喜欢的人和这个我们存在的世界？我是不是像所有的父亲一样，想多了……

          　　她睡得如此香甜，是否知道这个自作多情的父亲对她有如此多的希望呢？望着嫣儿被加湿器指示灯笼上了一层桔红色光芒的脸庞，感受着她的小手的温度，享受着她对我的依恋，我也慢慢地合上了眼睛进入了属于我们的甜美梦乡……'',
        '''', 2, '' 请选择 '', 4, '' ZZ '', '' 2019-06-18 '', '' 2019-06-18 '', null,
        '' 我与父亲不相见已二年余了，我最不能忘记的是他的背影。那年冬天，祖母死了，父亲的差使也交卸了，正是祸不单行的日子，我从北京到徐州，打算跟着父亲奔丧回家。到徐州见着父亲，看见满院狼藉的东西，又想起祖母，不禁簌簌地流下眼泪。父亲说，“事已如此，不必难过，好在天无绝人之路！”'',
        null, null, 0, 0, null);
INSERT INTO artical (ID, AUTHOR, ORIGINAUTHOR, ORIGINURL, TITTLE, IMGPATH, CONTENT, TAGS, NAVID, TOPICID, CATEGORIES,
                     TYPE, CREATEDATE, UPDATEDATE, ARTICALURL, SUMMARY, LASTARTICALID, NEXTARTICALID, LIKENUMS,
                     DISSNUMS, INTOP)
VALUES (8, '' 老干部 '', '' 贾平凹 '', '' https://toutiao.sanhao.com/m/news-detail-14943.html '', '' 写给母亲 '',
        '' images/2.jpg '', '' 人活着的时候，只是事情多，不计较白天和黑夜。人一旦死了日子就堆起来：算一算，再有二十天，我妈就三周年了。


          　　三年里，我一直有个奇怪的想法，就是觉得我妈没有死，而且还觉得我妈自己也不以为她就死了。常说人死如睡，可睡的人是知道要睡去，睡在了床上，却并不知道在什么时候睡着的呀。


          　　我妈跟我在西安生活了十四年，大病后医生认定她的各个器官已在衰竭，我才送她回棣花老家维持治疗。每日在老家挂上液体了，她也清楚每一瓶液体完了，儿女们会换上另一瓶液体的，所以便放心地闭了眼躺着。


          　　到了第三天的晚上，她闭着的眼是再没有睁开，但她肯定还是认为她在挂液体了，没有意识到从此再不醒来，因为她躺下时还让我妹把给她擦脸的毛巾洗一洗，梳子放在了枕边，系在裤带上的钥匙没有解，也没有交代任何后事啊。


          　　三年以前我每打喷嚏，总要说一句：这是谁想我呀？我妈爱说笑，就接茬说：谁想哩，妈想哩！这三年里，我的喷嚏尤其多，往往错过吃饭时间，熬夜太久，就要打喷嚏，喷嚏一打，便想到我妈了，认定是我妈还在牵挂我哩。


          　　我妈在牵挂着我，她并不以为她已经死了，我更是觉得我妈还在，尤其我一个人静静地待在家里，这种感觉就十分强烈。我常在写作时，突然能听到我妈在叫我，叫得很真切，一听到叫声我便习惯地朝右边扭过头去。


          　　从前我妈坐在右边那个房间的床头上，我一伏案写作，她就不再走动，也不出声，却要一眼一眼看着我，看得时间久了，她要叫我一声，然后说：世上的字你能写完吗，出去转转么。现在，每听到我妈叫我，我就放下笔走进那个房间，心想我妈从棣花来西安了？


          　　当然是房间里什么也没有，却要立上半天，自言自语我妈是来了又出门去街上，给我买我爱吃的青辣子和萝卜了。或许，她在逗我，故意藏到挂在墙上的她那张照片里，我便给照片前的香炉里上香，要说上一句：我不累。


          　　整整三年了，我给别人写过十多篇文章，却始终没给我妈写过一个字，因为所有的母亲，儿女们都认为是伟大又善良，我不愿意重复这些词语。我妈是一位普通的妇女，缠过脚，没有文化，户籍还在乡下，但我妈对于我是那样的重要。


          　　已经很长时间了，虽然再不为她的病而提心吊胆了，可我出远门，再没有人啰啰嗦嗦地叮咛着这样叮咛着那样，我有了好吃的好喝的，也不知道该送给谁去。


          　　在西安的家里，我妈住过的那个房间，我没有动一件家具，一切摆设还原模原样，而我再没有看见过我妈的身影。我一次又一次难受着又给自己说，我妈没有死，她是住回乡下老家了。今年的夏天太湿太热，每晚被湿热醒来，恍惚里还想着该给我妈的房间换个新空调了。待清醒过来，又宽慰着我妈在乡下的新住处里，应该是清凉的吧。


          　　三周年的日子一天天临近，乡下的风俗是要办一场仪式的，我准备着香烛花果，回一趟棣花了。但一回棣花，就要去坟上，现实告诉着我，妈是死了，我在地上，她在地下，阴阳两隔，母子再也难以相见，顿时热泪肆流，长声哭泣啊。'',
        '''', 2, '' 请选择 '', 4, '' ZZ '', '' 2019-06-18 '', '' 2019-06-18 '', null,
        '' 人活着的时候，只是事情多，不计较白天和黑夜。人一旦死了日子就堆起来：算一算，再有二十天，我妈就三周年了。'', null, null, 0, 0, null);
INSERT INTO artical (ID, AUTHOR, ORIGINAUTHOR, ORIGINURL, TITTLE, IMGPATH, CONTENT, TAGS, NAVID, TOPICID, CATEGORIES,
                     TYPE, CREATEDATE, UPDATEDATE, ARTICALURL, SUMMARY, LASTARTICALID, NEXTARTICALID, LIKENUMS,
                     DISSNUMS, INTOP)
VALUES (9, '' 老干部 '', '' 鲁迅 '', '' https://toutiao.sanhao.com/m/news-detail-14998.html '', '' 阿长与山海经 '',
        '' images/4.jpg '', ''《阿长与山海经》作品原文及理解如下：

          1、作品原文
          长妈妈，已经说过，是一个一向带领着我的女工，说得阔气一点，就是我的保姆。我的母亲和许多别的人都这样称呼她，似乎略带些客气的意思。只有祖母叫她阿长。我平时叫她“阿妈”，连“长”字也不带；但到憎恶她的时候，——例如知道了谋死我那隐鼠的却是她的时候，就叫她阿长。
          我们那里没有姓长的；她生得黄胖而矮，“长”也不是形容词。又不是她的名字，记得她自己说过，她的名字是叫作什么姑娘的。什么姑娘，我现在已经忘却了，总之不是长姑娘；也终于不知道她姓什么。

          记得她也曾告诉过我这个名称的来历：先前的先前，我家有一个女工，身材生得很高大，这就是真阿长。后来她回去了，我那什么姑娘才来补她的缺，然而大家因为叫惯了，没有再改口，于是她从此也就成为长妈妈了。

          虽然背地里说人长短不是好事情，但倘使要我说句真心话，我可只得说：我实在不大佩服她。最讨厌的是常喜欢切切察察，向人们低声絮说4些什么事。还竖起第二个手指，在空中上下摇动，或者点着对手或自己的鼻尖。

          我的家里一有些小风波，不知怎的我总疑心和这“切切察察”有些关系。又不许我走动，拔一株草，翻一块石头，就说我顽皮，要告诉我的母亲去了。一到夏天，睡觉时她又伸开两脚两手，在床中间摆成一个“大”字，挤得我没有余地翻身，久睡在一角的席子上，又已经烤得那么热。推她呢，不动；叫她呢，也不闻。

          “长妈妈生得那么胖，一定很怕热罢？晚上的睡相，怕不见得很好罢？……”

          母亲听到我多回诉苦之后，曾经这样地问过她。我也知道这意思是要她多给我一些空席。她不开口。但到夜里，我热得醒来的时候，却仍然看见满床摆着一个“大”字，一条臂膊还搁在我的颈子上。我想，这实在是无法可想了。

          但是她懂得许多规矩；这些规矩，也大概是我所不耐烦的。一年中最高兴的时节，自然要数除夕了。

          辞岁之后，从长辈得到压岁钱，红纸包着，放在枕边，只要过一宵，便可以随意使用。睡在枕上，看着红包，想到明天买来的小鼓、刀枪、泥人、糖菩萨……。然而她进来，又将一个福橘放在床头了。

          “哥儿，你牢牢记住！”她极其郑重地说。“明天是正月初一，清早一睁开眼睛，第一句话就得对我说：‘阿妈，恭喜恭喜！’记得么？你要记着，这是一年的运气的事情。不许说别的话！说过之后，还得吃一点福橘。”她又拿起那橘子来在我的眼前摇了两摇，“那么，一年到头，顺顺流流……。”

          梦里也记得元旦的，第二天醒得特别早，一醒，就要坐起来。她却立刻伸出臂膊，一把将我按住。我惊异地看她时，只见她惶急地看着我。

          她又有所要求似的，摇着我的肩。我忽而记得了——

          “阿妈，恭喜……。”

          “恭喜恭喜！大家恭喜！真聪明！恭喜恭喜！”她于是十分欢喜似的，笑将起来，同时将一点冰冷的东西，塞在我的嘴里。我大吃一惊之后，也就忽而记得，这就是所谓福橘，元旦辟头的磨难，总算已经受完，可以下床玩耍去了。

          她教给我的道理还很多，例如说人死了，不该说死掉，必须说“老掉了”；死了人，生了孩子的屋子里，不应该走进去；饭粒落在地上，必须拣起来，最好是吃下去；晒裤子用的竹竿底下，是万不可钻过去的……。

          此外，现在大抵忘却了，只有元旦的古怪仪式记得最清楚。总之：都是些烦琐之至，至今想起来还觉得非常麻烦的事情。

          然而我有一时也对她发生过空前的敬意。她常常对我讲“长毛”。她之所谓“长毛” 者，不但洪秀全军，似乎连后来一切土匪强盗都在内，但除却革命党，因为那时还没有。她说得长毛非常可怕，他们的话就听不懂。

          她说先前长毛进城的时候，我家全都逃到海边去了，只留一个门房和年老的煮饭老妈子看家。后来长毛果然进门来了，那老妈子便叫他们“大王”，——据说对长毛就应该这样叫，——诉说自己的饥饿。

          长毛笑道：“那么，这东西就给你吃了罢！”将一个圆圆的东西掷了过来，还带着一条小辫子，正是那门房的头。煮饭老妈子从此就骇破了胆，后来一提起，还是立刻面如土色，自己轻轻地拍着胸脯道：“阿呀，骇死我了，骇死我了……。”

          我那时似乎倒并不怕，因为我觉得这些事和我毫不相干的，我不是一个门房。但她大概也即觉到了，说道：“像你似的小孩子，长毛也要掳的，掳去做小长毛。还有好看的姑娘，也要掳。”

          “那么，你是不要紧的。”我以为她一定最安全了，既不做门房，又不是小孩子，也生得不好看，况且颈子上还有许多炙疮疤。

          “那里的话？！”她严肃地说。“我们就没有用么？我们也要被掳去。城外有兵来攻的时候，长毛就叫我们脱下裤子，一排一排地站在城墙上，外面的大炮就放不出来；再要放，就炸了！”

          这实在是出于我意想之外的，不能不惊异。我一向只以为她满肚子是麻烦的礼节罢了，却不料她还有这样伟大的神力。从此对于她就有了特别的敬意，似乎实在深不可测；夜间的伸开手脚，占领全床，那当然是情有可原的了，倒应该我退让。

          这种敬意，虽然也逐渐淡薄起来，但完全消失，大概是在知道她谋害了我的隐鼠之后。那时就极严重地诘问，而且当面叫她阿长。我想我又不真做小长毛，不去攻城，也不放炮，更不怕炮炸，我惧惮她什么呢！

          但当我哀悼隐鼠，给它复仇的时候，一面又在渴慕着绘图的《山海经》了。这渴慕是从一个远房的叔祖惹起来的。他是一个胖胖的，和蔼的老人，爱种一点花木，如珠兰、茉莉之类，还有极其少见的，据说从北边带回去的马缨花。

          他的太太却正相反，什么也莫名其妙，曾将晒衣服的竹竿搁在珠兰的枝条上，枝折了，还要愤愤地咒骂道：“死尸！”这老人是个寂寞者，因为无人可谈，就很爱和孩子们往来，有时简直称我们为“小友”。

          在我们聚族而居的宅子里，只有他书多，而且特别。制艺和试帖诗，自然也是有的；但我却只在他的书斋里，看见过陆玑的《毛诗草木鸟兽虫鱼疏》，还有许多名目很生的书籍。我那时最爱看的是 《花镜》，上面有许多图。

          他说给我听，曾经有过一部绘图的《山海经》，画着人面的兽，九头的蛇，三脚的鸟，生着翅膀的人，没有头而以两乳当作眼睛的怪物，……可惜现在不知道放在那里了。

          我很愿意看看这样的图画，但不好意思力逼他去寻找，他是很疏懒的。问别人呢，谁也不肯真实地回答我。压岁钱还有几百文，买罢，又没有好机会。有书买的大街离我家远得很，我一年中只能在正月间去玩一趟，那时候，两家书店都紧紧地关着门。

          玩的时候倒是没有什么的，但一坐下，我就记得绘图的《山海经》。

          大概是太过于念念不忘了，连阿长也来问《山海经》是怎么一回事。这是我向来没有和她说过的，我知道她并非学者，说了也无益；但既然来问，也就都对她说了。

          过了十多天，或者一个月罢，我还记得，是她告假回家以后的四五天，她穿着新的蓝布衫回来了，一见面，就将一包书递给我，高兴地说道：

          “哥儿，有画儿的‘三哼经’，我给你买来了！”

          我似乎遇着了一个霹雳，全体都震悚起来；赶紧去接过来，打开纸包，是四本小小的书，略略一翻，人面的兽，九头的蛇，……果然都在内。

          这又使我发生新的敬意了，别人不肯做，或不能做的事，她却能够做成功。她确有伟大的神力。谋害隐鼠的怨恨，从此完全消灭了。

          这四本书，乃是我最初得到，最为心爱的宝书。

          书的模样，到现在还在眼前。可是从还在眼前的模样来说，却是一部刻印都十分粗拙的本子。纸张很黄；图像也很坏，甚至于几乎全用直线凑合，连动物的眼睛也都是长方形的。但那是我最为心爱的宝书，看起来，确是人面的兽；九头的蛇；一脚的牛；袋子似的帝江； 没有头而“以乳为目，以脐为口”，还要“执干戚而舞”的刑天。

          此后我就更其搜集绘图的书，于是有了石印的《尔雅音图》和《毛诗品物图考》，又有了《点石斋丛画》和《诗画舫》。《山海经》也另买了一部石印的，每卷都有图赞，绿色的画，字是红的，比那木刻的精致得多了。这一部直到前年还在，是缩印的郝懿行21疏。木刻的却已经记不清是什么时候失掉了。

          我的保姆，长妈妈即阿长，辞了这人世，大概也有了三十年了罢。我终于不知道她的姓名，她的经历，仅知道有一个过继的儿子，她大约是青年守寡的孤孀。

          仁厚黑暗的地母呵，愿在你怀里永安她的魂灵！'', ''#鲁迅#/#朗读者#'', 2, '' 请选择 '', 4, '' ZZ '', '' 2019-06-18 '', '' 2019-06-18 '', null,
        '' 长妈妈，已经说过，是一个一向带领着我的女工，说得阔气一点，就是我的保姆。我的母亲和许多别的人都这样称呼她，似乎略带些客气的意思。只有祖母叫她阿长。我平时叫她“阿妈”，连“长”字也不带；但到憎恶她的时候，——例如知道了谋死我那隐鼠的却是她的时候，就叫她阿长。'',
        null, null, 0, 0, null);
INSERT INTO artical (ID, AUTHOR, ORIGINAUTHOR, ORIGINURL, TITTLE, IMGPATH, CONTENT, TAGS, NAVID, TOPICID, CATEGORIES,
                     TYPE, CREATEDATE, UPDATEDATE, ARTICALURL, SUMMARY, LASTARTICALID, NEXTARTICALID, LIKENUMS,
                     DISSNUMS, INTOP)
VALUES (10, '' 老干部 '', '''', '''', '' 人生没有练习，留下的遗憾 '', '' images/4.jpg '', '' 自出生时起我们便不断的在岁月里描绘人生，完美的一幅画只是一种期望游走于梦镜，给我们鼓励，给我们勇气去努力争取人世间美好。面对未知的空白，一筹莫展如炊烟袅袅笼罩在心里，人生的绘笔有点找不到落笔点，往往回首时才发现已经落错了点，已经不能涂改。

  来时带一本空白画册，时光握住手在画册上描绘各自不同的人生。没有谁来时既是天资的绘画师，也没有一幅属于自己现成的画给予临摹。行走于生活的轨迹上，慢慢的学会了看风景，学会了模仿别人留下的一景一物，学会了想象属于自己的那一道风景。到了自己真正要落笔时，才发现重重困难埋伏于脚下，才发现茫茫雾雨迷离了视线，手持绘笔的手把该画的线画斜了或画短画长了。一次一次的缺憾烙印于心鞭策于己，追求完美是要渡过一段缺失的行程，冰冻三尺非一日之寒，一落笔怎能成就完美。那些错误不负期望的苦心，总在静下心自省时，降临于心田痴痴不倦的教导，在心间亮起了一盏启明灯，在往前行时免于陷入更深的错误。

  在为自己的画辗转反侧，或在疑惑中剪不断理还乱时，是亲友的暖言暖语如一场春雨在耳际滋润，让那心中等待的绿意破土而出，让那飘忽不定的心在他们经历过的港湾找到安息。一路上同行相伴，相互鼓励勇敢前行，相互借鉴挡住风风雨雨。在路上可怕的不是凄迷的眼前，而是在凄迷中不愿打开看向外面世界的窗口。在书海中大师级别的一言一行就是最明亮的指路光。打开一扇门让腹有诗书气质华的暗香住进心房，再迷茫的路只要有书的亮光照进来就是充满希望。破茧成蝶需要经历一段痛苦过程，最难的不是梦想有多高远，而是脱变的过程，只要达到了千磨万击还坚韧，那么就任尔东西南北风吧。

  过去的不管是遗憾还是美好都已变成了藏在记忆里的一幅画。不必揣着那些缺失黯然泪下，完整的人生本来就由完美与不完美组成，如果要细数它们的分量，那么完美只不过是终线，而不完美却是蜿蜒曲折的延绵过程。如果在听一首歌或一遍文章落泪了，那么故事中的人景必定有自己的影子，泪流的不是结局而是路上不屈不挠的前行，包括留下那些不完美。因为时光没有倒退，人生没有练习，难免不会有遗憾，或喜或悲都是独一无二的。当熟悉的声音在耳际荡漾，任自己的思绪放逐在过去的时光里遨游，让自己再一次重温旧梦感慨万千。

  时光牵着手在走在走，目睹了雪山融化绿草出，看过了波光粼粼潮涨潮落，听过了细声绵绵花语鸟歌，踏过了波澜起伏似锦年华。笔下的画景越来越清新，从不熟练的画手变得愈来愈炉火纯青，一幅完整的画是有缺憾也有完美，在夕阳倚山时，对自己的画微笑、感恩。'',
        '''', 1, '' 请选择 '', 5, '' YC '', '' 2019-06-18 '', null, null,
        '' 自出生时起我们便不断的在岁月里描绘人生，完美的一幅画只是一种期望游走于梦镜，给我们鼓励，给我们勇气去努力争取人世间美好。面对未知的空白，一筹莫展如炊烟袅袅笼罩在心里，人生的绘笔有点找不到落笔点，往往回首时才发现已经落错了点，已经不能涂改。'',
        null, null, 0, 0, null);
INSERT INTO artical (ID, AUTHOR, ORIGINAUTHOR, ORIGINURL, TITTLE, IMGPATH, CONTENT, TAGS, NAVID, TOPICID, CATEGORIES,
                     TYPE, CREATEDATE, UPDATEDATE, ARTICALURL, SUMMARY, LASTARTICALID, NEXTARTICALID, LIKENUMS,
                     DISSNUMS, INTOP)
VALUES (11, '' 老干部 '', '''', '''', '' 一纸流年，谁把青春碎了一地 '', '' images/2.jpg '', '' > 素月芳华，一纸流年，谁把青春碎了一地，谁又为天长地久买单，我们慌乱了青葱岁月，却期待着完美的出现。

  > 时间总在沉思，飘落了花，枯黄了叶，却还一如既往的执着，依旧恋恋不舍，余情未了，一往情深深几许?深山夕照深秋雨。奢望依然带着神秘的面纱，站在未尝涉足的路上，清浅一笑，过去和未来给不了现在满意答案，却把现在拉扯成悠远的幻想。

  > 拾一抹月明，独自浅酌，浅淡的忧伤活着心碎的文字跃然纸上，多愁善感变成家常便饭，每吃一口，都有丝丝泪痕，信手拈来多是些低头哀叹，不是生活不够精彩，而是你把忧愁装饰的太美，让我身处其中无力自拔。

  > 我憧憬中的一切似乎都需重新定义，可我忘了要以何种方式定格，完美亦或悲伤，忧愁赋予浪漫。轻悄的落日黄昏，别样的徒步旅行，走过的风景，我要用爱加以修饰，可我的言语似乎失去了该有的魅力。

  > 过去未必真的过去，存在的假象也过于完美，不愿意看清却模糊得明白，我苍白了青春岁月，无力挣扎，却只为你的流年静待岁月安好，这是我欠你的前世今生，恍惚中，残留的记忆被时间漂白了岁月的痕迹。'', '''', 1, '' 请选择 '',
        5, '' YC '', '' 2019-06-18 '', null, null,
        '' 素月芳华，一纸流年，谁把青春碎了一地，谁又为天长地久买单，我们慌乱了青葱岁月，却期待着完美的出现。时间总在沉思，飘落了花，枯黄了叶，却还一如既往的执着，依旧恋恋不舍，余情未了，一往情深深几许?深山夕照深秋雨。奢望依然带着神秘的面纱，站在未尝涉足的路上，清浅一笑，过去和未来给不了现在满意答案，却把现在拉扯成悠远的幻想。'',
        null, null, 0, 0, null);
INSERT INTO artical (ID, AUTHOR, ORIGINAUTHOR, ORIGINURL, TITTLE, IMGPATH, CONTENT, TAGS, NAVID, TOPICID, CATEGORIES,
                     TYPE, CREATEDATE, UPDATEDATE, ARTICALURL, SUMMARY, LASTARTICALID, NEXTARTICALID, LIKENUMS,
                     DISSNUMS, INTOP)
VALUES (12, '' 老干部 '', '''', '''', '' 家乡，我梦中的丁香姑娘 '', '' images/7.jpg '', '' 又到一年岁末，大家开始奔走在回家的路上。难免不让游子思念起远在天涯的家乡。

  /01/

  我的家乡龙潭桥，在湖南省邵阳市新宁县的一个小山村，位于湖南省西南边陲。龙潭桥其实不叫龙潭桥，本名叫新寨村。龙潭桥只是新寨村里，新寨河上的一座古桥。新寨河从天边的高山而来，去不到另一个天边的高山脚下，乡村被一分为二，成为两个村落，村落之间的往来、买卖，全靠这条龙潭桥，可见，它的重要性。因为它的存在，因为它在村民心中的分量，新寨村这个名字慢慢地被大家淡忘，龙潭桥取而代之。

  龙潭桥背靠威严的高山，前接广阔的田野，在两岸古柳树荫的簇拥下，架在深不见底的新寨河之上，像一条巨龙卧于河面之上。它始建于明代，有6个扇形石桥墩，雄壮威武，安静地竖立在清澈的河底。全木质的桥身，两端和中间部分为阁楼，中间的阁楼建筑成亭台的样式，故叫其中亭，中亭里面设有神龛，供村民朝拜。桥全封闭式，桥顶覆盖着黛瓦。桥的里面，两边的位置，用木材搭建很多座椅，供来赶集的村民们休息。随著时间的冲洗，流水的腐蚀，它显出古老的青色。桥身经几次翻修，有些许改变，但仍保留着原来的样貌。

  整个县城有大大小小，新新旧旧几十座桥，随著时间的冲洗，有些或没入洪流之中，有些或年久失修，仅有小部分的桥，像江口桥，飞仙桥，龙潭桥等存留下来。存留下来的桥中，大部分木质结构被破坏，亭台被拆除，被结构简单的石拱桥或者公路所替代，光秃秃的，呆呆的。远远看去，要不是桥下有条大河，完全然觉察不出来桥的存在。而龙潭桥正是存留下的少部分桥，而且是其中保存最完整的，最原生态的，最有特点的，最有名的一座。

  /02/

  龙潭桥的来历，有个传奇的神话故事。龙潭桥原是山脚下的一片平地，住着一对夫妻，两人却无恶不作，鱼肉乡里，村民们敢怒不敢言。于是，逢年过节，祭拜神灵的时候，吐露心声，希望神明帮助出去恶霸，庇佑村民。

  后来，他们孕有一个女儿，美丽又善良。有一天，小女孩在厨房，发现两个尖尖的小角，像地里冒出来的竹笋。恶霸父亲拿刀割掉它，结果第二天，又长出新的，父亲又割掉，第三天，又有新的长出来。这时，小女孩于心不忍，悄悄地拿木材、稻草掩盖起来，并且每天将淘米水倒至尖角上，不断滋养它，让它慢慢地在长大。

  村民们年年祭拜，有一年，终于显灵。一天，神灵幻化成一只小黄狗，叼走小女孩手中的铁锹。小女孩为了追回铁锹，一直跟在狗后面跑。不知不觉地跑出家外几里地，正当她准备往回走，一扭头，家的位置突然天崩地裂，一声巨响，变成汪洋大海，一条巨龙从她家的厨房的位置，正是尖尖小角的位置腾起，越入波涛滚滚的水里。她的家和恶霸父母随著洪水消失不见。洪水沿着山脚处，冲出一条大河。

  村民们为了感谢替他们报仇雪恨的巨龙，在河岸上修建起一座桥，取名为龙潭桥，并在中亭设有神龛，请有水龙王、关公、财神、土地神等神位，供百姓拜谒。过往的村民，总不忘买一束香，带一吊纸钱，一叩首，三跪拜，一来感谢神灵带来的幸福和安康，二来希望神灵继续保佑平安和富足。由此可见，龙潭桥在村民心中的分量。

  /03/

  在人们心中，龙潭桥的分量之重，还有另一个重要的原因，即与它所扮演的角色有很大的关联。它是一个重要的交通枢纽，联系大河两旁的各大乡镇，比如山这边的乡镇有金木十二个大队，山那边的有唐家村、水庙镇，石门镇等;
它是一个重要的埠头
，
水运上至麻林乡
，
石门镇
，
水庙镇
，
下至黄河村
，
飞仙桥乡等地;
它是一个重要的集贸市场
，
十乡八里的人需要的东西
，
小至菜米油盐
，
大至生老病死
，
这里都能买到
，
村民们自己生产的东西
，
鸡鸭鱼
，
白菜萝卜
，
稻谷麦子等东西
，
也都可以担来这里销售
。

外面世界一切新奇的
，
流行的事物
，
大都走过这座桥
，
步入人们的视野
。
因此
，
龙潭村在方圆十里算得上最赶时髦的
。
最早抛弃煤油灯
，
用起许多村民们从未见过的电灯;
村里有人办好事
，
请戏班子唱黄梅戏
、
花鼓戏
，
远远看着戏班子从龙潭桥的方向走过来;
村里开始流行起来的新发型
、
新衣服款式
，
指不定从这里的某个老板娘那里传开的
。
对于平穷的村民们
，
这里俨然就是一个繁华的大城市
。
龙潭桥里的一举一动
，
成了人们效仿的标杆
。

龙潭桥从明代开始
，
层层叠叠
，
叠叠层层
，
留下无数村民的脚步
。
有的人
，
带着对未来的美好希望
，
怀揣着梦想
，
大步流星地走出木桥
，
走在未来的康庄大道上;
也有的人
，
满眼血丝
，
无神
，
充满疲倦
，
带着对外面世界的失望
，
拖着绝望的步伐踏上木桥
，
朝着家的方向赶;
还有的人
，
满鬓白发
，
带着对家乡的眷恋
，
落叶归根的夙愿
，
手持拐杖
，
踏上木桥
，
颤颤悠悠地一步一挪
，
朝着已经不再是家的家的方向走
。
这些脚步其中
，
当然也有我的脚步
，
从小脚丫的蹒跚学步
，
到追着梦想的高视阔步
，
再到分别后重回家乡故地的闲庭信步
。

/
04/

我对它的记忆
，
喜爱
，
一半是我的乡愁
，
一半是它的韵味
。
乡愁不必说
，
缕也缕不顺
，
剪也剪不断
。
那么
，
它的韵味是什么呢
?
那还得从它周围的景致说起
。

龙潭桥的两旁生长着一排参天古树
，
厚厚的树皮一块一块地裂开
，
裂出一道道的宽大的口子
，
让人看着替它疼痛
。
树皮上长着厚厚的一层青苔
，
绿油油的
，
从我记事起
，
一直是绿色的树干
，
这个绿色几乎嵌入它的身体里
。
稍低的树干上
，
时不时地斜生出一些蕨类植物
，
绿油油的生机盎然
，
与沧桑的古树形成鲜明对比
，
点缀其中
，
恰到好处
。
两旁还错落有致地生长着杨柳树
，
一律是年代久远的
。
杨柳斜斜地立在岸旁
，
树根在岸上
，
树顶在河面上
，
柳枝垂钓下来
，
抚摸着水面
。
一切那么的沧桑
，
又那么的活力
。

河岸两边
，
古木苍天的大树簇拥着龙潭桥
，
龙潭桥显得更加有历史感
。
它像一位从历史里走来的老人
，
沧桑
，
有故事
。
光阴涂抹了她的脸庞
，
将它抹成灰里发黑的颜色;
光阴雕刻着它的身体
，
在桥身的树桩上雕出无数的细纹;
光影画花了她的模样
，
让她在衰败的环境里显得模糊
，
带些颓废
。
它是沧桑的
，
但它又是强健的
，
并没有衰老出一副老态龙钟
。
尽管大雨磅礴的时节
，
洪水滚滚而来
，
如千万猛兽啃食着桥墩
，
激起浪花
，
波涛汹涌
，
一浪更比一浪高
，
它就稳健地站立着
，
像一位身强体健的战士
，
挺拔站立
，
守护着来来往往的村民
。

龙潭桥有它刚强的一面
，
当然也有它柔情的一面
。
在烟雨朦胧的三月
，
两岸杨柳的掩映下
，
青砖黛瓦的水上楼台
，
氤氲在一片水雾之中
，
若隐若现
，
倒有一种江南水乡的韵致
。
或是在某个黄昏
，
酡红如醉的晚霞的映照下
，
西面河流的最近
，
一偏打渔的小舟
，
悠然自得
，
从天边缓缓驶来
，
孤帆一片日边来正是此意境
。
或是细雨纷纷的时节
，
天空里飘飘洒洒
，
一个穿着旗袍的姑娘
，
袅袅娉娉
，
撑住一把油纸伞
，
红色的高跟鞋敲打着青石板
，
从岸边的古宅里走出
，
风姿阔绰地步入楼台
，
她不就是戴望舒的雨巷姑娘
。

龙潭桥就像这位雨巷姑娘
，
有丁香一样的美丽
，
有丁香一样的芬芳
，
有丁香一样的忧伤
。
'',
'''',
1,
''
请选择
'',
5,
''
YC
'',
''
2019
-
06
-
18
'',
null,
null,
''
又到一年岁末
，
大家开始奔走在回家的路上
。
难免不让游子思念起远在天涯的家乡
。
我的家乡龙潭桥
，
在湖南省邵阳市新宁县的一个小山村
，
位于湖南省西南边陲
。
龙潭桥其实不叫龙潭桥
，
本名叫新寨村
。
龙潭桥只是新寨村里
，
新寨河上的一座古桥
。
新寨河从天边的高山而来
，
去不到另一个天边的高山脚下
，
乡村被一分为二
，
成为两个村落
，
村落之间的往来
、
买卖
，
全靠这条龙潭桥
，
可见
，
它的重要性
。
因为它的存在
，
因为它在村民心中的分量
，
新寨村这个名字慢慢地被大家淡忘
，
龙潭桥取而代之
。
'',
null,
null,
0,
0,
null
);
INSERT INTO artical (ID, AUTHOR, ORIGINAUTHOR, ORIGINURL, TITTLE, IMGPATH, CONTENT, TAGS, NAVID, TOPICID, CATEGORIES,
                     TYPE, CREATEDATE, UPDATEDATE, ARTICALURL, SUMMARY, LASTARTICALID, NEXTARTICALID, LIKENUMS,
                     DISSNUMS, INTOP)
VALUES (13, '' 老干部 '', '''', '''', '' 时光终将会给悲伤划上一个句点 '', '' images/7.jpg '', '' 匆忙而过的青春岁月，拥有了太多了回忆与悲伤，我们每个人都曾在青春岁月当中留下了些许的遗憾，些许的疯狂和些许的惆怅，每个人却也在青葱岁月当中慢慢的成长。

  高中，那个对于静来说不愿意回想的年代，那个在静的记忆当中永远不想被记忆的年代，可是，却也是在高中这个年代中，静遇到了他，也认识了他。 静老是说，在自己的人生当中分为两个阶段，分界点就是高中。高中以前的自己是个疯丫头，疯狂，外向，热烈，却也是充满了激情与斗志，乐观且骄傲;
高中之后的自己
，
内向
，
腼腆
，
不爱说话
，
只有悲伤的想法
，
不愿意接近别人
，
不愿意参加社交活动
，
只愿意活在自己小小的世界里
，
极度的自卑
。
而造成这一切无非是高中自己那一落千丈的成绩吧
。

在高中以前
，
静是佼佼者
，
是老师眼中的骄子
，
是父母眼中的瑰宝
，
是自信能考上重点大学的疯丫头;
可是
，
在高中
，
在经历一次又一次的滑铁卢之后
，
静是老师眼中高中三年毕业只能抱着几本破书回家的垃圾学生
，
是不敢问别人成绩只能默默哭泣的懦夫
。
那时候的静
，
只敢跟成绩不是特别好
，
大家都差不多的学生做朋友
，
也是从那时候
，
静认识了他
，
一个高瘦
、
长相干净的男生
，
峰
。
静从来都不知道原来自己在别人眼中读书很厉害
，
在静的世界里
，
那些很厉害的时光已经过去了
，
可是在峰的眼里
，
她却仍旧是那样的厉害
，
无论是虚荣心作祟
，
还是终于找到了心理安慰
，
静默默地交上了峰这个朋友
。

中午
，
他们会一起做作业
、
聊天
，
他们之间单纯得像只是朋友一样
。
可是静却也知道
，
自己喜欢这个男生
，
这个干净的男生
，
自己会去关注他的一点一滴
，
会在意他的行为举止
，
当老师批评他的时候
，
自己都会觉得伤心和不好意思
。
静也知道峰喜欢自己
，
他会在半夜不睡觉问自己的男闺蜜觉得自己怎么样
，
会在自己生日的时候送自己礼物
，
会默默的关注着自己
。
可是
，
他们谁也没有开口
，
都只是默默地保持着这种关系
。

在静的心中
，
早已经勾勒出在大学时期的样子
，
尽管自己的成绩很差
，
但是骨子里不服输的个性却是无法磨灭的
，
她已经绘画好了自己大学的蓝图
，
包括了自己跟峰的未来
，
一起去同一个城市
，
上同一所大学
。
可是
，
这些却从未跟峰说过
。

静一直以为
，
她的心意峰会懂
，
可是她却忘记了
，
两个完全不一样的人
，
不说出来谁会真正懂你呢
。
静忘记了
，
这个世界上最重要的是沟通
。
当静完全沉迷于自己勾勒的蓝图并且为之努力奋斗的时候
，
她跟峰之间的关系也渐渐的疏远了
，
可是
，
从未谈过恋爱的静却没有意识到这个问题
，
当传出峰跟自己的好朋友丽在一起的时候
，
静却不相信
，
她知道高中流言蜚语的厉害
，
在高中
，
那个大家都无聊的只能读书的年代
，
八卦无非是大家最喜欢做的事情
，
所以静不在意
，
如果不是她亲眼所见
，
相信她将终身不得知吧
。

那是去会考的一天
，
那天天下着很大的雨
，
从离上次与峰聊天
，
到现在已经很长时间了
，
静想刚好趁着今天坐车去考试的时候与峰好好聊聊
，
两个人一起好好努力
，
考上大学
。
可是静却在校车前等了很久也没等到峰的到来
，
没等到峰的静只好坐着最后一班校车前往考场
。
因为不在同一教室
，
静只能默默地忍受着自己的担心
，
担心峰睡过头没来考试
，
一下考场
，
静直奔校门口
，
等着峰的出现
。

可是她等来的却是从远处迎面走过来的两个人
，
峰跟丽
，
峰为丽撑着伞
，
两个人共同走过来
。
原来
，
峰早就出了考场
，
原来他是去往另外一所学校接丽
，
可笑的自己却是傻傻的等待着
。
两个人迎面走过来
，
微笑着跟静打招呼
，
问她要不要一起去吃饭
。

可笑的一幕
，
可怜的静只能默默的接受了来自于这一个可笑的结局
。
默默地忍受着这两个人对自己造成的伤害
。

谁说过
，
初恋是美好的呢
，
静的初恋却充满了可笑与可悲
，
从那以后
，
静开始默默地过着自己的生活
，
不愿意跟异性打交道
，
在大学时期的静也跟高中一样
，
默默地读书
。
不愿意恋爱
，
不愿意认识异性
，
即使静后来开始活泼开朗
，
但也没有恋爱的冲动
。

现在的她
，
仍然害怕伤害
，
那所高中
，
那里的老师同学
，
都是自己不愿意触碰的过往
，
也许将来的某一天
，
她会放下一切
，
努力爱吧
，
因为时间终将会给过往的伤害划上一个句点的
!
'',
'''',
1,
''
请选择
'',
5,
''
YC
'',
''
2019
-
06
-
18
'',
''
2019
-
06
-
18
'',
null,
''
匆忙而过的青春岁月
，
拥有了太多了回忆与悲伤
，
我们每个人都曾在青春岁月当中留下了些许的遗憾
，
些许的疯狂和些许的惆怅
，
每个人却也在青葱岁月当中慢慢的成长
。
'',
null,
null,
0,
0,
null
);
INSERT INTO artical (ID, AUTHOR, ORIGINAUTHOR, ORIGINURL, TITTLE, IMGPATH, CONTENT, TAGS, NAVID, TOPICID, CATEGORIES,
                     TYPE, CREATEDATE, UPDATEDATE, ARTICALURL, SUMMARY, LASTARTICALID, NEXTARTICALID, LIKENUMS,
                     DISSNUMS, INTOP)
VALUES (14, '' 老干部 '', '''', '''', '' 秋雨敲打着我的窗 '', '' images/4.jpg '', '' 秋天的雨，倏忽来，倏忽去。雨点挺大，敲打在厨房的窗上，乒乒乓，乒乒乓，像打击乐，更像心跳。

  一边听手机音乐，一边做我喜欢的茄饼。金黄的茄饼出锅的时候，下雨了。“秋雨不过沟，哪里下了哪里收。”这一阵秋雨下在了父母的田野里，应该是一个丰收的年成。敲打在我的玻璃窗上，也应该有一个美好的心情。

  喜欢听刀郎的歌，沧桑中包含深情，“今夜又下着小雨，小雨它一点一点滴滴”，这分明就不是下雨，而是在流泪。我们听到了一个男人对“去年那场相遇”的深深怀念。

  人生有很多相遇，但不是每一次相遇都刻骨铭心，而刻骨铭心的相遇又不是都能重复。“雨中的你是那样美丽，我问你是否喜欢和我一起，你笑着无语。”这种残缺的美丽，总会出现，这也许就是人生的常态。

  时间，是一把无形的扫帚，满地落红它能打扫得干干净净。终于，“今夜里我又站在雨里，任感情在小雨里飘来飘去，我问我自己是否还在爱着你，就这样轻易地放弃。”放弃，也是一种美丽。

  雨还在下着，将操场清刷得一片清新。绿色的草坪，红色的跑道，赏心悦目。响成一片的树叶，沙沙沙，哗哗哗，啪啪啪，别一样的天籁。

  茄子还是父亲给的，胖胖的，最适合烙茄饼。昨天，铰茄子的时候，老母亲不断提示：“找最大的。”是啊，爹妈总是把最好的给了儿女，把所有的痛苦都自己咽下。

  手机里又响起《天之大》，能把《天之大》演绎得感人肺腑的恐怕要数毛阿敏了。曾经听一个小男孩演唱《天之大》，的确是天籁之音，可是，明显没有时间的沉淀，缺少生活的厚重。恩情，是要经过发酵的，正所谓“养儿方知父母恩”。

  “妈妈，月光之下，静静地我想你了，静静淌在血里的牵挂。”是的，只有在离开妈妈的他乡，只有在宁静的月光之下，想妈的情感才是最纯正的。“儿行千里母担忧”，当我们牵挂千里之外的儿女时，才会真正把咱的爹妈揽在梦中，“幸福生于会痛的心田”，不是这样吗？

  老婆在看《父母爱情》，不时笑几声。郭涛和梅婷演绎的爱情，可以说有其特殊年代特殊性格的因素，我还是觉得，他们将几百年几千年乃至上万年的夫妻之情、亲子之情演绎到了极致。

  “不曾远去的那些爱的风雨，可在我的梦里，爱已慢慢的老去，那些岁月在心底，已渐渐凝聚。”能够沉淀的，能够凝聚的，都是值得珍惜的。就像这潇潇秋雨，滋润了田野，滋润了农人的心田。

  最后一锅茄饼飘香的时候，雨也停了，阳光穿过乌云，将操场映照得明媚可爱。

  手机里响起了《再度重相逢》：“你说人生如梦，我说人生如秀，那有什么不同，不都一样朦胧，朦胧中有你，有你跟我就已经足够，你就在我的世界，升起了彩虹。”

  这个世界上，至亲的人不多，至爱的人太少，至好的人少之又少，足够了，珍惜拥有的，是句老话，却是最有用的。'', '''', 1, '' 请选择 '', 5, '' YC '', '' 2019-06-18 '',
        '' 2019-06-18 '', null,
        '' 秋天的雨，倏忽来，倏忽去。雨点挺大，敲打在厨房的窗上，乒乒乓，乒乒乓，像打击乐，更像心跳。一边听手机音乐，一边做我喜欢的茄饼。金黄的茄饼出锅的时候，下雨了。“秋雨不过沟，哪里下了哪里收。”这一阵秋雨下在了父母的田野里，应该是一个丰收的年成。敲打在我的玻璃窗上，也应该有一个美好的心情。'',
        null, null, 0, 0, null);
INSERT INTO artical (ID, AUTHOR, ORIGINAUTHOR, ORIGINURL, TITTLE, IMGPATH, CONTENT, TAGS, NAVID, TOPICID, CATEGORIES,
                     TYPE, CREATEDATE, UPDATEDATE, ARTICALURL, SUMMARY, LASTARTICALID, NEXTARTICALID, LIKENUMS,
                     DISSNUMS, INTOP)
VALUES (15, '' 老干部 '', '' 落梅拂雪 '', '' https://www.duanwenxue.com/article/4829813.html '', '' 人生天地间，忽如远行客 '',
        '' images/2.jpg '', ''
          而缘分就是如此的奇妙，它如洪流，将尘世间的你我无情冲散，又总能将有缘之人牵系到一起，从万水千山赶赴这一场美丽的邀约。在这茫茫天地间，我们听从着命运的安排，将自己的真心交付出来，却从不曾知晓，究竟谁才是生命里的归人，谁又只是充当过客?

          也许人生天地间，忽如远行客。那些途经你生命的里的人，也许是偶然，也许是必然。无论是有所亏欠，还是有缘相见，都终须一别。只是有的缘分热情似火，熊熊燃烧，刻骨铭心，令人难忘。而有的缘分如细水长流，缓缓流淌，润泽彼此的心。

          可无论是谁，都无法逃脱岁月无情的捉弄，也许很多时候看似你生命中的归人，他却往往只能陪伴你走过一程山水，而后便是山长水阔，各自珍重。而有的人看似浪子，与你缘分浅薄，却偏偏注定是命里的归人。

          但凡相遇，终有离散。但凡缘起，必有缘尽之日。你我都无法改变其中的一切。也许这便是所谓的冥冥之中自有安排。遇见谁，钟情于谁，辜负了谁，与谁相守一生，这从来都不是我们所能说了算。而是由我们的心来决定，由心来掌握。

          也曾固执地认为，只要有所付出就一定能有所收获。可直到今日才发现，自己太过荒谬可笑。历经了红尘苦难磨练之后，才恍然明白，这世间不是所有付出都会有所收获;
并不是你付出真心就能得到别人的珍惜;
不是你所爱的人恰好也正爱着你
。

每个人存活于世
，
不都是负重前行吗
?
背负着沉重的行囊
，
一路不断地寻着自己所想要得到的东西
，
又不断断地失去珍贵的东西
，
乃至情感
。
到头来
，
蓦然回首
，
才知一切皆已似是而非
，
不复痕迹
。
而自己这一路患得患失
，
究竟又得到了多少
，
失去的又有多少
?
走过的岁月有多少是真
，
又有多少是假
，
而自己是否真正做到了无愧于心
，
不曾留有遗憾
。
也许这些问题的答案
，
就连我们也都未可得知
。

我曾以为
，
我的父母乃至最为恩爱和睦的伴侣
。
他们相伴走过二十余载岁月
，
可谓是患难与共
，
同甘共苦
，
不离不弃
。
原以为他们能一直彼此坦诚相待
，
携手到老
。
可直到去年
，
家中发生了莫大的变故
，
他们原本深挚的爱
，
却成了对彼此的怨恨
。
曾经的相互包容
、
相互理解
、
相互支持
，
却成了对彼此的猜忌
，
对彼此的疏远
。
曾无话不谈
，
而今却是无话可谈
。
尽管一切早已尘埃落定
，
可我仍陷在他们的感情破裂的泥潭之中
，
无法救赎
。

这半年来
，
我费尽心力
，
用尽无数方法
，
只为能改善他们彼此之间的关系
，
化解他们之间的心结
。
可在一次次的怀揣希望
，
到一次次的失望
，
再到遍体鳞伤
，
我才真正明白
，
这世间不是所有的爱
，
都能一直维系到白头
。

在外人的眼中
，
我们一家人无不是他们心中的向往
，
夫妻和睦
、
子女孝顺
，
家中美满幸福
。
可如今
，
多少的无话不谈都成了沉默不语
，
多少的真心都逃不过被岁月无情的蹂躏
。
直到尝尽了苦楚之后
，
我才明白
，
也许这世间
，
无论是夫妻之间
、
还是父母子女之间
、
又或是朋友之间
，
都存在着一定的距离
，
而这段距离
，
或近或远
，
看似近在咫尺
，
却是你永远都无法逾越的距离
。

唐朝女诗人李季兰有诗曾言
：
“
至近至远东西
，
至深至浅清浅
。
至高至明日月
，
至亲至疏夫妻
”
。
我想此诗句
，
正是到出了人与人之间
，
都是保持着一段距离的
。
情深不寿
，
慧极必伤
。
现实社会中
，
总有很多美好的人和事
，
只能远观
，
而不能尽赏
。
而往往真实的就是破碎的
，
与其如此
，
不如一直在远处观望
，
或许还可以保持那份迷离的美
。

很多时候
，
频频回首
，
都多么希望能见到在灯火阑珊处有那个自己所等候的人
。
可实际上所见到的
，
却往往是灯火阑珊
，
原地却早已空无一人
。
这一路过客匆匆
，
连我们自己都只是那过客中的一个
。
而我们
，
处于这茫茫天地间
，
忽如远行客
。
就似孤舟离蒲岸
，
渐行渐远渐陌生
。

与其耽溺于悲伤
，
莫不如
，
让聚散随缘吧
。
一切但求尽力而为
，
但求无愧于心
。
如此
，
足矣
。
'',
''
#人生#
'',
2,
''
请选择
'',
4,
''
ZZ
'',
''
2019
-
06
-
18
'',
''
2019
-
06
-
18
'',
null,
''
人生若拆开二字
，
一半是人本身
，
一半是生活
。
你的人生是平淡或是热烈
，
是碌碌无为还是精彩纷呈
，
全由乎自己的选择与掌握
。
自是有着不同的追求
，
才会有着不同的方向
，
所产生的情感不同
，
所发生的故事亦不同
。
'',
null,
null,
0,
0,
null
);
INSERT INTO artical (ID, AUTHOR, ORIGINAUTHOR, ORIGINURL, TITTLE, IMGPATH, CONTENT, TAGS, NAVID, TOPICID, CATEGORIES,
                     TYPE, CREATEDATE, UPDATEDATE, ARTICALURL, SUMMARY, LASTARTICALID, NEXTARTICALID, LIKENUMS,
                     DISSNUMS, INTOP)
VALUES (16, '' 老干部 '', '''', '''', '' eclipse搭建ssh2环境 '', '' images/8.jpg '', '' 如何在eclipse中搭建一个ssh2环境
  一、创建一个新的web工程
  新建一个ssh_demo项目，并修改编码格式为UTF-8，如下图：

  二、搭建Struts2的开发环境
  1. 将Struts2需要的jar包导入到/WEB-INF/lib文件夹下
  2. 创建一个action，代码如下：
  package com.lhr.action;
import
com
.
opensymphony
.
xwork2
.
ActionSupport;
@
SuppressWarnings
(
"serial"
)
public
class
SignOnAction
extends
ActionSupport
{
@
Override
public
String
execute
(
)
throws
Exception
{
return
SUCCESS;
}
}
3.
创建struts
.
xml文件
，
内容如下
：
<
?
xml
version
=
"1.0"
encoding
=
"UTF-8"
?
>
<
!
DOCTYPE
struts
PUBLIC
"-//Apache Software Foundation//DTD Struts Configuration 2.5//EN"
"http://struts.apache.org/dtds/struts-2.5.dtd"
>
<
struts
>
<
package
name
=
"default"
namespace
=
"/"
extends
=
"struts-default"
>

<
action
name
=
"signOn"
class
=
"com.lhr.action.SignOnAction"
>
<
result
name
=
"success"
>/
WEB
-
INF/
signOn
.
jsp
</
result
>
</
action
>
</
package
>
</
struts
>
4.
修改web
.
xml文件
，
添加struts2过滤器
<
filter
>
<
filter
-
name
>
struts2
</
filter
-
name
>
<
filter
-
class
>
org
.
apache
.
struts2
.
dispatcher
.
filter
.
StrutsPrepareAndExecuteFilter
</
filter
-
class
>
</
filter
>

<
filter
-
mapping
>
<
filter
-
name
>
struts2
</
filter
-
name
>
<
url
-
pattern
>/*</url-pattern>
	</filter-mapping>

5.	添加jsp页面，在WebContent下添加index.jsp页面，在WEB-INF下添加signOn.jsp页面
index.jsp页面信息如下：
<%@ page language="java" contentType="text/html; charset=UTF-8"
	pageEncoding="UTF-8"%>
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Insert title here</title>
</head>
<script type="text/javascript">
	function doLoad() {
		window.location.href = "signOn";
	}
</script>
<body onload="doLoad();">
</body>
</html>
signOn.jsp页面信息如下：
<%@ page language="java" contentType="text/html; charset=UTF-8"
    pageEncoding="UTF-8"%>
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Insert title here</title>
</head>
<body>
hello struts2
</body>
</html>
6.	启动服务器，访问localhost:8080/ssh_demo，出现如下结果：

至此，struts2的基本环境已经搭建完成；
三、搭建Hibernate的开发环境
1.	将Struts2需要的jar包导入到/WEB-INF/lib文件夹下:

2.	创建一个bean实体类（User.java）：
package com.hr.bean;
public class User {
	private Integer serno;
	private String username;
	private String password;
	private String address;
	public Integer getSerno() {return serno;}
	public void setSerno(Integer serno) {this.serno = serno;}
	public String getUsername() {return username;}
	public void setUsername(String username) {this.username = username;}
	public String getPassword() {return password;}
	public void setPassword(String password) {this.password = password;}
	public String getAddress() {return address;}
	public void setAddress(String address) {this.address = address;}
}

3.	创建User.java对应的映射文件User.hbm.xml:
<?xml version="1.0" encoding="utf-8"?>
<!-- ~ Hibernate, Relational Persistence for Idiomatic Java ~ ~ License:
	GNU Lesser General Public License (LGPL), version 2.1 or later. ~ See the
	lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>. -->
<!DOCTYPE hibernate-mapping PUBLIC
	"-//Hibernate/Hibernate Mapping DTD 3.0//EN"
	"http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd">
<hibernate-mapping>
	<class name="com.hr.bean.User" table="t_user">
		<id name="serno" type="java.lang.Integer">
			<!-- <column name="serno"/> -->
			<generator class="native" />
		</id>
		<property name="username" column="username" />
		<property name="password" column="password" />
		<property name="address" column="address" />
	</class>
</hibernate-mapping>
4.	创建hibernate核心配置文件hibernate.cfg.xml:
<!-- ~ Hibernate, Relational Persistence for Idiomatic Java ~ ~ License:
	GNU Lesser General Public License (LGPL), version 2.1 or later. ~ See the
	lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>. -->
<!DOCTYPE hibernate-configuration PUBLIC "-//Hibernate/Hibernate Configuration DTD 3.0//EN" "http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd">
<hibernate-configuration>
	<session-factory>
		<!-- DB连接四要素 -->
		<property name="hibernate.connection.driver_class">oracle.jdbc.driver.OracleDriver</property>
		<property name="hibernate.connection.url">jdbc:oracle:thin:@localhost:1521:ssh</property>
		<property name="hibernate.connection.username">sshuser</property>
		<property name="hibernate.connection.password">sshuser</property>
		<!-- 方言 -->
		<property name="hibernate.dialect">org.hibernate.dialect.OracleDialect</property>
		<!--C3P0 数据源(数据库连接池) -->
		<property name="hibernate.connection.provider_class">org.hibernate.c3p0.internal.C3P0ConnectionProvider</property>
		<!-- 当前Session上下文 -->
		<property name="hibernate.current_session_context_class">thread</property>
		<!-- 自动建表 -->
		<property name="hibernate.hbm2ddl.auto">update</property>
		<!-- 显示SQL -->
		<property name="hibernate.show_sql">true</property>
		<!-- 格式化SQL -->
		<property name="hibernate.format_sql">true</property>
		<!-- 注册映射文件 -->
		<mapping resource="com/hr/bean/User.hbm.xml" />
	</session-factory>
</hibernate-configuration>
四、搭建Spring的开发环境
1.	导入spring相关jar包到WEB-INF/lib文件夹下：

2.	指定配置文件的位置并配置spring的监听器到web.xml中
<!-- 启动监听Spring配置文件 -->
	<context-param>
		<param-name>contextConfigLocation</param-name>
		<param-value>classpath:applicationContext.xml</param-value>
	</context-param>
<!-- 添加spring监听器 -->
<listener>	<listener-class>org.springframework.web.context.ContextLoaderListener</listener-class>
</listener>
3.	创建数据访问层dao接口
package com.hr.dao;
import com.hr.bean.User;
public interface UserDao {
	public void insert(User user);// 新增用户
	public void update(User user);// 修改用户
	public User find(Integer serno);// 查询用户（通过主键）
	public void delete(Integer serno);// 删除用户（通过主键）
}
4.	创建数据访问层dao实现类
package com.hr.dao.impl;
import com.hr.bean.User;
import com.hr.dao.UserDao;
public class UserDaoImpl implements UserDao {
	public void insert(User user) {
		System.out.println("Dao......");
		System.out.println("Hello " + user.getUsername());
	}
	public void update(User user) {}
	public User find(Integer serno) {return null;}
	public void delete(Integer serno) {}
}

5.	创建业务逻辑层service接口
package com.hr.service;
import com.hr.bean.User;
public interface UserService {
	public void addUser(User user);
	public void updateUser(User user);
	public User findUser(Integer serno);
	public void deleteUser(Integer serno);
}
6.	创建业务逻辑层service实现类
package com.hr.service.impl;
import com.hr.bean.User;
import com.hr.dao.impl.UserDaoImpl;
import com.hr.service.UserService;
public class UserServiceImpl implements UserService {
	public void addUser(User user) {
		System.out.println("Service......");
		UserDaoImpl userDaoImpl = new UserDaoImpl();
		userDaoImpl.insert(user);
	}
	public void updateUser(User user) {}
	public User findUser(Integer serno) {return null;}
	public void deleteUser(Integer serno) {}
}

7.	创建spring核心配置文件：applicationContext.xml
<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="http://www.springframework.org/schema/beans
                        http://www.springframework.org/schema/beans/spring-beans.xsd">
	<bean id="userService" class="com.hr.service.impl.UserServiceImpl">
	</bean>
	<bean id="user" class="com.hr.bean.User">
		<property name="serno" value="1234"></property>
		<property name="username" value="Zhangsan"></property>
		<property name="password" value="******"></property>
		<property name="address" value="China.Xian"></property>
	</bean>
</beans>
8.	创建测试类
package com.hr.test;

import org.springframework.context.ApplicationContext;
import org.springframework.context.support.ClassPathXmlApplicationContext;

import com.hr.bean.User;
import com.hr.service.UserService;
public class UserProgram {
	public static void main(String[] args) {
		ApplicationContext context = new ClassPathXmlApplicationContext("applicationContext.xml");
		UserService userService = (UserService) context.getBean("userService");
		User user = (User) context.getBean("user");
		userService.addUser(user);

	}
}
执行结果如下，Spring环境搭建完成：
Service......
Dao......
Hello Zhangsan
五、Struts2整合Spring
1.	添加整合jar包到WEB-INF/lib下：

2.	将action类配置在spring中：
<bean id="signOnAction" class="com.hr.action.SignOnAction" scope="prototype" />
<bean id="userAction" class="com.hr.action.UserAction" scope="prototype"/>
3.	修改struts.xml配置文件，修改如下：
<action name="signOn" class="signOnAction">
	<result name="success">/WEB-INF/signOn.jsp</result>
</action>
4.	访问工程可以跳转到signOn.jsp页面，struts和spring整合完成。
六、Spring整合Hibernate
1.	将hibernate的配置信息交给spring来管理：删除hibernate.cfg.xml中的数据库连接和hibernate配置信息
<!-- DB连接四要素 已经交给spring来管理 -->
		<!--
		<property name="hibernate.connection.driver_class">oracle.jdbc.driver.OracleDriver</property>
		<property name="hibernate.connection.url">jdbc:oracle:thin:@36.33.227.211:1521:ssh</property>
		<property name="hibernate.connection.username">sshuser</property>
		<property name="hibernate.connection.password">sshuser</property>
		-->
		<!-- hibernate其他配置信息也交给spring来管理 -->
		<!-- 方言 -->
		<!-- <property name="hibernate.dialect">org.hibernate.dialect.OracleDialect</property> -->
		<!-- 当前Session上下文 -->
		<!-- <property name="hibernate.current_session_context_class">thread</property> -->
		<!-- 自动建表 -->
		<!-- <property name="hibernate.hbm2ddl.auto">update</property> -->
		<!-- 显示SQL -->
		<!-- <property name="hibernate.show_sql">true</property> -->
		<!-- 格式化SQL -->
		<!-- <property name="hibernate.format_sql">true</property> -->
2.	修改applicationContext.xml如下信息:
<!-- 加载数据库配置文件 -->
	<context:property-placeholder location="classpath:db.properties" />
	<!-- 配置c3p0连接池信息 -->
	<bean id="dataSource" class="com.mchange.v2.c3p0.ComboPooledDataSource">
		<property name="driverClass" value="${jdbc.driverClass}" />
		<property name="jdbcUrl" value="${jdbc.jdbcUrl}" />
		<property name="user" value="${jdbc.user}" />
		<property name="password" value="${jdbc.password}" />
	</bean>
	<!-- sessionFactory创建交给spring管理 -->
	<bean id="sessionFactory"
		class="org.springframework.orm.hibernate4.LocalSessionFactoryBean">
		<property name="dataSource" ref="dataSource" />
		<!-- 配置Hibernate的其他的属性 -->
		<property name="hibernateProperties">
			<props>
				<prop key="hibernate.dialect">org.hibernate.dialect.OracleDialect</prop>
				<prop key="hibernate.current_session_context_class">org.springframework.orm.hibernate4.SpringSessionContext</prop>
				<prop key="hibernate.hbm2ddl.auto">update</prop>
				<prop key="hibernate.show_sql">true</prop>
				<prop key="hibernate.format_sql">true</prop>
			</props>
		</property>
		<!-- 指定hibernate核心配置文件 -->
		<property name="configLocations" value="classpath:hibernate.cfg.xml" />
	</bean>
	<!-- 1.配置事务管理器 -->
	<bean id="transactionManager"
		class="org.springframework.orm.hibernate4.HibernateTransactionManager">
		<!-- 注入sessionFactory -->
		<property name="sessionFactory" ref="sessionFactory" />
	</bean>

	<!-- 创建hibernate模版对象 -->
	<bean id="hibernateTemplate" class="org.springframework.orm.hibernate4.HibernateTemplate">
		<!-- 注入sessionFactory -->
		<property name="sessionFactory" ref="sessionFactory" />
	</bean>
	<!-- 2.开启事务注解 -->
	<tx:annotation-driven transaction-manager="transactionManager" />
	<!-- 引入user.xml文件 -->
	<import resource="classpath:user.xml" />
db.properties配置如下：
jdbc.user=sshuser
jdbc.password=sshuser
jdbc.driverClass=oracle.jdbc.driver.OracleDriver
jdbc.jdbcUrl=jdbc:oracle:thin:@36.33.227.211:1521:ssh
3.	修改user.xml配置
<!-- 配置userAction对象 -->
	<bean id="userAction" class="com.hr.action.UserAction">
		<!-- 注入userService -->
		<property name="userService" ref="userService" />
	</bean>
	<!-- 创建userService -->
	<bean id="userService" class="com.hr.service.impl.UserServiceImpl">
		<!-- 注入userDao -->
		<property name="userDaoImpl" ref="userDaoImpl" />
	</bean>
	<!-- 创建userDao -->
	<bean id="userDaoImpl" class="com.hr.dao.impl.UserDaoImpl">
		<!-- 引入hibernate模版对象 -->
		<property name="hibernateTemplate" ref="hibernateTemplate" />
	</bean>

	<!-- 这里的Action类交给spring来管理 -->
	<bean id="signOnAction" class="com.hr.action.SignOnAction" scope="prototype" />
	<bean id="user" class="com.hr.bean.User">
		<property name="serno" value="1"></property>
		<property name="username" value="Zhangsan"></property>
		<property name="password" value="*********"></property>
		<property name="address" value="China.Xian"></property>
	</bean>
4.	启动项目后对应的数据库中出现配置的表信息，则整合Spring和Hibernate完成。

5.	dao类中实现注入HibernateTemplate
package com.hr.dao.impl;
import org.springframework.orm.hibernate4.HibernateTemplate;

import com.hr.bean.User;
import com.hr.dao.UserDao;

public class UserDaoImpl implements UserDao {
	private HibernateTemplate hibernateTemplate;


	public HibernateTemplate getHibernateTemplate() {
		return hibernateTemplate;
	}
	public void setHibernateTemplate(HibernateTemplate hibernateTemplate) {
		this.hibernateTemplate = hibernateTemplate;
	}
	public void insert(User user) {
		hibernateTemplate.save(user);
		System.out.println("Dao......");
		System.out.println("Hello " + user.getUsername());
	}
	public void update(User user) {}
	public User find(Integer serno) {return null;}
	public void delete(Integer serno) {}
}
6.	简化注入HibernateTemplate写法：
修改user.xml注入配置：
<bean id="userDaoImpl" class="com.hr.dao.impl.UserDaoImpl">
		<!-- 引入hibernate模版对象 -->
		<!-- <property name="hibernateTemplate" ref="hibernateTemplate" /> -->
		<property name="sessionFactory" ref="sessionFactory" />
</bean>
修改UserDaoImpl类，使之继承HibernateDaoSupport
package com.hr.dao.impl;
import org.hibernate.SessionFactory;
import org.springframework.orm.hibernate4.HibernateTemplate;
import org.springframework.orm.hibernate4.support.HibernateDaoSupport;

import com.hr.bean.User;
import com.hr.dao.UserDao;

public class UserDaoImpl extends HibernateDaoSupport implements UserDao {
	/*private HibernateTemplate hibernateTemplate;
	public HibernateTemplate getHibernateTemplate() {
		return hibernateTemplate;
	}
	public void setHibernateTemplate(HibernateTemplate hibernateTemplate) {
		this.hibernateTemplate = hibernateTemplate;
	}*/
	public void insert(User user) {
		//调用方法可以得到HibernateTemplate模版对象
		HibernateTemplate hibernateTemplate = this.getHibernateTemplate();
		hibernateTemplate.save(user);
		System.out.println("Dao......");
		System.out.println("Hello " + user.getUsername());
	}
	public void update(User user) {}
	public User find(Integer serno) {return null;}
	public void delete(Integer serno) {}
}
修改struts.xml，添加：
<action name="signOn1" class="userAction" method="save">
			<result name="success">/WEB-INF/signOn.jsp</result>
</action>
修改index.jsp页面：
<script type="text/javascript">
	function doLoad() {
		window.location.href = "signOn1";
	}
</script>
<body onload="doLoad();">
</body>
UserAction.java文件内容如下：

package com.hr.action;
import org.springframework.context.ApplicationContext;
import org.springframework.context.support.ClassPathXmlApplicationContext;
import com.hr.bean.User;
import com.hr.service.UserService;
import com.opensymphony.xwork2.ActionSupport;

public class UserAction extends ActionSupport {
	private static UserService userService;

	public String save(){
		ApplicationContext context = new ClassPathXmlApplicationContext("applicationContext.xml");
		userService =  (UserService) context.getBean("userService");
		User user = (User) context.getBean("user");
		userService.addUser(user);
		return SUCCESS;
	}

	public UserService getUserService() {
		return userService;
	}

	public void setUserService(UserService userService) {
		this.userService = userService;
	}
}
启动服务器，访问localhost:8080/ssh_demo，数据库中新增一条记录，整合完成。

七、添加Log4j2日志记录功能
1.	在src目录下添加log4j2.xml文件，并配置文件中输出和存储日志相关信息
<?xml version="1.0" encoding="UTF-8" ?>
<!--日志级别以及优先级排序: OFF > FATAL > ERROR > WARN > INFO > DEBUG > TRACE > ALL -->
<!--Configuration后面的status，这个用于设置log4j2自身内部的信息输出，可以不设置，当设置成trace时，你会看到log4j2内部各种详细输出 -->
<!--monitorInterval：Log4j能够自动检测修改配置 文件和重新配置本身，设置间隔秒数 -->
<configuration status="WARN" monitorInterval="30">
	<!--先定义所有的appender -->
	<appenders>
		<!--这个输出控制台的配置 -->
		<console name="Console" target="SYSTEM_OUT">
			<!--输出日志的格式 -->
			<PatternLayout pattern="[%d{yyyy-MM-dd HH:mm:ss}] [%p] - %l - %m%n" />
		</console>
		<!--文件会打印出所有信息，这个log每次运行程序会自动清空，由append属性决定，这个也挺有用的，适合临时测试用 -->
		<!-- ${sys:user.home}表示当前用户的目录，windows下为C:\Users\username，linux下为/home/username -->
		<File name="log" fileName="${sys:user.home}/logs/test.log" append="false">
			<PatternLayout
				pattern="%d{yyyy-MM-dd HH:mm:ss} %-5level %class{36} %L %M - %msg%xEx%n" />
		</File>
		<!-- 这个会打印出所有的info及以下级别的信息，每次大小超过size，则这size大小的日志会自动存入按年份-月份建立的文件夹下面并进行压缩，作为存档 -->
		<RollingFile name="RollingFileInfo" fileName="${sys:user.home}/logs/info.log"
			filePattern="${sys:user.home}/logs/$${date:yyyy-MM}/info-%d{yyyy-MM-dd}-%i.log">
			<!--控制台只输出level及以上级别的信息（onMatch），其他的直接拒绝（onMismatch） -->
			<ThresholdFilter level="info" onMatch="ACCEPT"
				onMismatch="DENY" />
			<PatternLayout pattern="[%d{yyyy-MM-dd HH:mm:ss}] [%p] - %l - %m%n" />
			<Policies>
				<TimeBasedTriggeringPolicy />
				<SizeBasedTriggeringPolicy size="10 MB" />
			</Policies>
		</RollingFile>
		<RollingFile name="RollingFileWarn" fileName="${sys:user.home}/logs/warn.log"
			filePattern="${sys:user.home}/logs/$${date:yyyy-MM}/warn-%d{yyyy-MM-dd}-%i.log">
			<ThresholdFilter level="warn" onMatch="ACCEPT"
				onMismatch="DENY" />
			<PatternLayout pattern="[%d{yyyy-MM-dd HH:mm:ss}] [%p] - %l - %m%n" />
			<Policies>
				<TimeBasedTriggeringPolicy />
				<SizeBasedTriggeringPolicy size="10 MB" />
			</Policies>
			<!-- DefaultRolloverStrategy属性如不设置，则默认为最多同一文件夹下7个文件，这里设置了10 -->
			<DefaultRolloverStrategy max="10" />
		</RollingFile>
		<RollingFile name="RollingFileError" fileName="${sys:user.home}/logs/error.log"
			filePattern="${sys:user.home}/logs/$${date:yyyy-MM}/error-%d{yyyy-MM-dd}-%i.log">
			<ThresholdFilter level="error" onMatch="ACCEPT"
				onMismatch="DENY" />
			<PatternLayout pattern="[%d{yyyy-MM-dd HH:mm:ss}] [%p] - %l - %m%n" />
			<Policies>
				<TimeBasedTriggeringPolicy />
				<SizeBasedTriggeringPolicy size="10 MB" />
			</Policies>
		</RollingFile>
	</appenders>
	<!--然后定义logger，只有定义了logger并引入的appender，appender才会生效 -->
	<loggers>
		<!--过滤掉spring的一些无用的DEBUG信息 -->
		<logger name="org.springframework" level="INFO"></logger>
		<root level="all">
			<appender-ref ref="Console" />
			<appender-ref ref="RollingFileInfo" />
			<appender-ref ref="RollingFileWarn" />
			<appender-ref ref="RollingFileError" />
		</root>
	</loggers>
</configuration>
2.	项目中添加日志示例代码：
Logger logger = LogManager.getLogger(LogManager.ROOT_LOGGER_NAME);
logger.trace("trace level");
logger.debug("debug level");
logger.info("info level");
logger.warn("warn level");
logger.error("error level");
logger.fatal("fatal level");







'', ''#ssh#/#技术#'', 5, ''1'', 2, ''YC'', ''2019-06-18'', ''2019-06-18'', null, ''如何在eclipse中搭建一个ssh2环境
一、创建一个新的web工程
新建一个ssh_demo项目，并修改编码格式为UTF-8，如下图：
二、搭建Struts2的开发环境
1.	将Struts2需要的jar包导入到/WEB-INF/lib文件夹下
 '', null, null, 0, 0, null);
INSERT INTO artical (ID, AUTHOR, ORIGINAUTHOR, ORIGINURL, TITTLE, IMGPATH, CONTENT, TAGS, NAVID, TOPICID, CATEGORIES, TYPE, CREATEDATE, UPDATEDATE, ARTICALURL, SUMMARY, LASTARTICALID, NEXTARTICALID, LIKENUMS, DISSNUMS, INTOP) VALUES (17, ''老干部'', '''', '''', ''Eclipse快捷键'', ''images/1.jpg'', ''1几个最重要的快捷键
代码助手:Ctrl+Space（简体中文操作系统是Alt+/）
快速修正：Ctrl+1
单词补全：Alt+/
打开外部Java文档：Shift+F2

显示搜索对话框：Ctrl+H
快速Outline：Ctrl+O
打开资源：Ctrl+Shift+R
打开类型：Ctrl+Shift+T
显示重构菜单：Alt+Shift+T
上一个/下一个光标的位置：Alt+Left/Right
上一个/下一个成员（成员对象或成员函数）：Ctrl+Shift+Up/Down
选中闭合元素：Alt+Shift+Up/Down/Left/Right
删除行：Ctrl+D
在当前行上插入一行：Ctrl+Shift+Enter
在当前行下插入一行： Shift+Enter
上下移动选中的行：Alt+Up/Down

组织导入：Ctrl+Shift+O
2 定位
2.1行内定位
行末/行首：End/Home
前一个/后一个单词：Ctrl+Right/Left
2.2文件内定位
跳到某行：Ctrl+L
上下滚屏：Ctrl+Up/Down
上一个/下一个成员（成员对象或成员函数）：Ctrl+Shift+Up/Down
快速Outline：Ctrl+O
2.3跨文件定位
打开声明：F3
打开资源：Ctrl+Shift+R
打开类型：Ctrl+Shift+T
在workspace中搜索选中元素的声明：Ctrl+G
在workspace中搜索选中的文本：Ctrl+Alt+G
在workspace中搜索选中元素的引用：Ctrl+Shift+G
打开调用层次结构：Ctrl+Alt+H
快速层次结构：Ctrl+T
反悔：Ctrl+Z
2.4其它
上一个/下一个光标所在位置：Alt+Left/Right
上一个编辑的位置：Ctrl+Q

3 选中
3.1行内选中
选中到行末/行首：Shift+End/Home
选中上一个/下一个单词：Ctrl+Shift+Left/Right
3.2文件内选中
选中闭合元素：Alt+Shift+Up
恢复到上一个选中：Alt+Shift+Down
选中下一个/上一个元素：Alt+Shift+Right/Left

4 定位/选中/操作同时
删除行：Ctrl+D
删除下一个/上一个单词：Ctrl+Delete/Backspace
删除到行末：Ctrl+Shift+Delete
在当前行上插入一行：Ctrl+Shift+Enter
在当前行下插入一行： Shift+Enter
上下移动选中的行：Alt+Up/Down
拷贝选中的行：Ctrl+Alt+Up/Down

5其它的代码编辑类快捷键
保存：Ctrl+S
保存所有：Ctrl+Shift+S
下一个命中的项（搜索之后）：Ctrl+.
注释：Ctrl+/
添加导入：Ctrl+Shift+M
显示快捷键帮助：Ctrl+Shift+L
变为大/小写：Ctrl+Shift+X/Y

6 重构
显示重构菜单：Alt+Shift+T
重构-改变方法签名：Alt+Shift+C
重构-移动：Alt+Shift+V
重构-重命名：Alt+Shift+R

7 编辑器、视图、透视图切换
下一个编辑器：Ctrl+F6
下一个视图：Ctrl+F7
下一个透视图：Ctrl+F8
最大化当前视图或编辑器：Ctrl+M
激活编辑器：F12

8 Debug
F5：Step Into（debug）
F6：Step over（debug）
F7：Step return（debug）
F8：Resume（debug）
F11：debug上一个应用（debug）

9 Up/Down/Right/Left类快捷键
Ctrl
前一个/后一个单词：Ctrl+Right/Left
上下滚屏：Ctrl+Up/Down
Alt
上一个/下一个光标的位置：Alt+Left/Right
上下移动选中的行：Alt+Up/Down
Shift
选中上一个/下一个字符：Shift+Left/Right
选中上一行/下一行（从当前光标位置开始）：Shift+Up/Down
Ctrl+Shift
上一个/下一个成员（成员对象或成员函数）：Ctrl+Shift+Up/Down
选中上一个/下一个单词：Ctrl+Shift+Left/Right
Alt+Shift
选中闭合元素：Alt+Shift+Up
恢复到上一个选中：Alt+Shift+Down
选中下一个/上一个元素：Alt+Shift+Right/Left
拷贝选中的行：Ctrl+Alt+Up/Down
Ctrl+Alt
拷贝选中的行：Ctrl+Alt+Up/Down

10 F类快捷键
F2：显示提示/重命名
F3：打开选中元素的声明
F4：打开选中元素的类型继承结构
F5：刷新
F5：Step Into（debug）
F6：Step over（debug）
F7：Step return（debug）
F8：Resume（debug）
F11：debug上一个应用（debug）
F12：激活编辑器

出处：http://www.cnblogs.com/ifaithu/archive/2013/02/19/2917263.html
================================================================================
Eclipse快捷键大全
Ctrl+1 快速修复(最经典的快捷键,就不用多说了)
Ctrl+D: 删除当前行
Ctrl+Alt+↓ 复制当前行到下一行(复制增加)
Ctrl+Alt+↑ 复制当前行到上一行(复制增加)
Alt+↓ 当前行和下面一行交互位置(特别实用,可以省去先剪切,再粘贴了)
Alt+↑ 当前行和上面一行交互位置(同上)
Alt+← 前一个编辑的页面
Alt+→ 下一个编辑的页面(当然是针对上面那条来说了)
Alt+Enter 显示当前选择资源(工程,or 文件 or文件)的属性
Shift+Enter 在当前行的下一行插入空行(这时鼠标可以在当前行的任一位置,不一定是最后)
Shift+Ctrl+Enter 在当前行插入空行(原理同上条)
Ctrl+Q 定位到最后编辑的地方
Ctrl+L 定位在某行 (对于程序超过100的人就有福音了)
Ctrl+M 最大化当前的Edit或View (再按则反之)
Ctrl+/ 注释当前行,再按则取消注释
Ctrl+O 快速显示 OutLine
Ctrl+T 快速显示当前类的继承结构
Ctrl+W 关闭当前Editer
Ctrl+K 参照选中的Word快速定位到下一个
Ctrl+E 快速显示当前Editer的下拉列表(如果当前页面没有显示的用黑体表示)
Ctrl+/(小键盘) 折叠当前类中的所有代码
Ctrl+×(小键盘) 展开当前类中的所有代码
Ctrl+Space 代码助手完成一些代码的插入(但一般和输入法有冲突,可以修改输入法的热键,也可以暂用Alt+/来代替)
Ctrl+Shift+E 显示管理当前打开的所有的View的管理器(可以选择关闭,激活等操作)
Ctrl+J 正向增量查找(按下Ctrl+J后,你所输入的每个字母编辑器都提供快速匹配定位到某个单词,如果没有,则在stutes line中显示没有找到了,查一个单词时,特别实用,这个功能Idea两年前就有了)
Ctrl+Shift+J 反向增量查找(和上条相同,只不过是从后往前查)
Ctrl+Shift+F4 关闭所有打开的Editer
Ctrl+Shift+X 把当前选中的文本全部变味小写
Ctrl+Shift+Y 把当前选中的文本全部变为小写
Ctrl+Shift+F 格式化当前代码
Ctrl+Shift+P 定位到对于的匹配符(譬如{}) (从前面定位后面时,光标要在匹配符里面,后面到前面,则反之)

下面的快捷键是重构里面常用的,本人就自己喜欢且常用的整理一下(注:一般重构的快捷键都是Alt+Shift开头的了)
Alt+Shift+R 重命名 (是我自己最爱用的一个了,尤其是变量和类的Rename,比手工方法能节省很多劳动力)
Alt+Shift+M 抽取方法 (这是重构里面最常用的方法之一了,尤其是对一大堆泥团代码有用)
Alt+Shift+C 修改函数结构(比较实用,有N个函数调用了这个方法,修改一次搞定)
Alt+Shift+L 抽取本地变量( 可以直接把一些魔法数字和字符串抽取成一个变量,尤其是多处调用的时候)
Alt+Shift+F 把Class中的local变量变为field变量 (比较实用的功能)
Alt+Shift+I 合并变量(可能这样说有点不妥Inline)
Alt+Shift+V 移动函数和变量(不怎么常用)
Alt+Shift+Z 重构的后悔药(Undo)

编辑
作用域 功能 快捷键
全局 查找并替换 Ctrl+F
文本编辑器 查找上一个 Ctrl+Shift+K
文本编辑器 查找下一个 Ctrl+K
全局 撤销 Ctrl+Z
全局 复制 Ctrl+C
全局 恢复上一个选择 Alt+Shift+↓
全局 剪切 Ctrl+X
全局 快速修正 Ctrl1+1
全局 内容辅助 Alt+/
全局 全部选中 Ctrl+A
全局 删除 Delete
全局 上下文信息 Alt+？
Alt+Shift+?
Ctrl+Shift+Space
Java编辑器 显示工具提示描述 F2
Java编辑器 选择封装元素 Alt+Shift+↑
Java编辑器 选择上一个元素 Alt+Shift+←
Java编辑器 选择下一个元素 Alt+Shift+→
文本编辑器 增量查找 Ctrl+J
文本编辑器 增量逆向查找 Ctrl+Shift+J
全局 粘贴 Ctrl+V
全局 重做 Ctrl+Y


查看
作用域 功能 快捷键
全局 放大 Ctrl+=
全局 缩小 Ctrl+-


窗口
作用域 功能 快捷键
全局 激活编辑器 F12
全局 切换编辑器 Ctrl+Shift+W
全局 上一个编辑器 Ctrl+Shift+F6
全局 上一个视图 Ctrl+Shift+F7
全局 上一个透视图 Ctrl+Shift+F8
全局 下一个编辑器 Ctrl+F6
全局 下一个视图 Ctrl+F7
全局 下一个透视图 Ctrl+F8
文本编辑器 显示标尺上下文菜单 Ctrl+W
全局 显示视图菜单 Ctrl+F10
全局 显示系统菜单 Alt+-


导航
作用域 功能 快捷键
Java编辑器 打开结构 Ctrl+F3
全局 打开类型 Ctrl+Shift+T
全局 打开类型层次结构 F4
全局 打开声明 F3
全局 打开外部javadoc Shift+F2
全局 打开资源 Ctrl+Shift+R
全局 后退历史记录 Alt+←
全局 前进历史记录 Alt+→
全局 上一个 Ctrl+,
全局 下一个 Ctrl+.
Java编辑器 显示大纲 Ctrl+O
全局 在层次结构中打开类型 Ctrl+Shift+H
全局 转至匹配的括号 Ctrl+Shift+P
全局 转至上一个编辑位置 Ctrl+Q
Java编辑器 转至上一个成员 Ctrl+Shift+↑
Java编辑器 转至下一个成员 Ctrl+Shift+↓
文本编辑器 转至行 Ctrl+L


搜索
作用域 功能 快捷键
全局 出现在文件中 Ctrl+Shift+U
全局 打开搜索对话框 Ctrl+H
全局 工作区中的声明 Ctrl+G
全局 工作区中的引用 Ctrl+Shift+G


文本编辑
作用域 功能 快捷键
文本编辑器 改写切换 Insert
文本编辑器 上滚行 Ctrl+↑
文本编辑器 下滚行 Ctrl+↓


文件
作用域 功能 快捷键
全局 保存 Ctrl+X
Ctrl+S
全局 打印 Ctrl+P
全局 关闭 Ctrl+F4
全局 全部保存 Ctrl+Shift+S
全局 全部关闭 Ctrl+Shift+F4
全局 属性 Alt+Enter
全局 新建 Ctrl+N


项目
作用域 功能 快捷键
全局 全部构建 Ctrl+B


源代码
作用域 功能 快捷键
Java编辑器 格式化 Ctrl+Shift+F
Java编辑器 取消注释 Ctrl+\
Java编辑器 注释 Ctrl+/
Java编辑器 添加导入 Ctrl+Shift+M
Java编辑器 组织导入 Ctrl+Shift+O
Java编辑器 使用try/catch块来包围 未设置，太常用了，所以在这里列出,建议自己设置。
也可以使用Ctrl+1自动修正。


运行
作用域 功能 快捷键
全局 单步返回 F7
全局 单步跳过 F6
全局 单步跳入 F5
全局 单步跳入选择 Ctrl+F5
全局 调试上次启动 F11
全局 继续 F8
全局 使用过滤器单步执行 Shift+F5
全局 添加/去除断点 Ctrl+Shift+B
全局 显示 Ctrl+D
全局 运行上次启动 Ctrl+F11
全局 运行至行 Ctrl+R
全局 执行 Ctrl+U


重构
作用域 功能 快捷键
全局 撤销重构 Alt+Shift+Z
全局 抽取方法 Alt+Shift+M
全局 抽取局部变量 Alt+Shift+L
全局 内联 Alt+Shift+I
全局 移动 Alt+Shift+V
全局 重命名 Alt+Shift+R
全局 重做 Alt+Shift+Y

出处：http://www.blogjava.net/action/articles/17339.html
================================================================================
eclipse快捷键以及使用技巧大全
1. 打开MyEclipse 6.0.1,然后“window”→“Preferences”
2. 选择“java”,展开,“Editor”,选择“Content Assist”。
3. 选择“Content Assist”,然后看到右边,右边的“Auto-Activation”下面的“AutoActivation triggers for java”这个选项。其实就是指触发代码提示的就是“.”这个符号。
4.“Auto Activation triggers for java”这个选项,在“.”后加abc字母,方便后面的查找修改。然后“apply”,点击“OK”。
5. 然后,“File”→“Export”,在弹出的窗口中选择“Perferences”,点击“下一步”。
6. 选择导出文件路径,本人导出到桌面,输入“test”作为文件名,点击“保存”。
7. 在桌面找到刚在保存的文件“test.epf”,右键选择“用记事本打开”。
8. 可以看到很多配置MyEclipse 6.0.1的信息
9. 按“ctrl + F”快捷键,输入“.abc”,点击“查找下一个”。
10. 查找到“.abc”的配置信息如下:
11. 把“.abc”改成“.abcdefghijklmnopqrstuvwxyz(,”,保存,关闭“test.epf”。
12. 回到MyEclipse 6.0.1界面,“File”→“Import”,在弹出的窗口中选择“Perferences”,点击“下一步”,选择刚在已经修改的“test.epf”文件,点击“打 开”,点击“Finish”。该步骤和上面的导出步骤类似。
13. 最后当然是进行代码测试了。随便新建一个工程,新建一个类。在代码输入switch,foreach等进行测试。你立即会发现,果然出了提示,而且无论是敲哪个字母都会有很多相关的提示了,很流畅,很方便。
总结:
“Auto Activation triggers for java”这个选项就是指触发代码提示的的选项,把“.”改成
“.abcdefghijklmnopqrstuvwxyz(,”的意思,就是指遇到26个字母和.,(这些符号就触发代码提示功能了。
顺便说一下,修改类名,接口名等以不同颜色高亮的,可以这样配置在“java”→“enditor”→“syntac”,右边展开“java”→“classes”,勾上“Enable”这个选项,选择自己喜欢的颜色即可。
当然还有其他相关的颜色配置。具体就不说啦。其实,在“Preferences”这个东西,有很多可以配置的东西,使得MyEclipse 优化的,具体的就要各个人根据自己个人喜好去配置了。

Eclipse 常用快捷键
Eclipse的编辑功能非常强大，掌握了Eclipse快捷键功能，能够大大提高开发效率。Eclipse中有如下一些和编辑相关的快捷键。
1. 【ALT+/】
此快捷键为用户编辑的好帮手，能为用户提供内容的辅助，不要为记不全方法和属性名称犯愁，当记不全类、方法和属性的名字时，多体验一下【ALT+/】快捷键带来的好处吧。
2. 【Ctrl+O】
显示类中方法和属性的大纲，能快速定位类的方法和属性，在查找Bug时非常有用。
3. 【Ctrl+/】
快速添加注释，能为光标所在行或所选定行快速添加注释或取消注释，在调试的时候可能总会需要注释一些东西或取消注释，现在好了，不需要每行进行重复的注释。
4. 【Ctrl+D】
删除当前行，这也是笔者的最爱之一，不用为删除一行而按那么多次的删除键。
5. 【Ctrl+M】
窗口最大化和还原，用户在窗口中进行操作时，总会觉得当前窗口小（尤其在编写代码时），现在好了，试试【Ctrl+M】快捷键。
查看和定位快捷键
在程序中，迅速定位代码的位置，快速找到Bug的所在，是非常不容易的事，Eclipse提供了强大的查找功能，可以利用如下的快捷键帮助完成查找定位的工作。
1. 【Ctrl+K】、【Ctrl++Shift+K】
快速向下和向上查找选定的内容，从此不再需要用鼠标单击查找对话框了。
2. 【Ctrl+Shift+T】
查找工作空间（Workspace）构建路径中的可找到Java类文件，不要为找不到类而痛苦，而且可以使用“*”、“？”等通配符。
3. 【Ctrl+Shift+R】
和【Ctrl+Shift+T】对应，查找工作空间（Workspace）中的所有文件（包括Java文件），也可以使用通配符。
4. 【Ctrl+Shift+G】
查找类、方法和属性的引用。这是一个非常实用的快捷键，例如要修改引用某个方法的代码，可以通过【Ctrl+Shift+G】快捷键迅速定位所有引用此方法的位置。
5. 【Ctrl+Shift+O】
快速生成import，当从网上拷贝一段程序后，不知道如何import进所调用的类，试试【Ctrl+Shift+O】快捷键，一定会有惊喜。
6. 【Ctrl+Shift+F】
格式化代码，书写格式规范的代码是每一个程序员的必修之课，当看见某段代码极不顺眼时，选定后按【Ctrl+Shift+F】快捷键可以格式化这段代码，如果不选定代码则默认格式化当前文件（Java文件）。
7. 【ALT+Shift+W】
查找当前文件所在项目中的路径，可以快速定位浏览器视图的位置，如果想查找某个文件所在的包时，此快捷键非常有用（特别在比较大的项目中）。
8. 【Ctrl+L】
定位到当前编辑器的某一行，对非Java文件也有效。
9. 【Alt+←】、【Alt+→】
后退历史记录和前进历史记录，在跟踪代码时非常有用，用户可能查找了几个有关联的地方，但可能记不清楚了，可以通过这两个快捷键定位查找的顺序。
10. 【F3】
快速定位光标位置的某个类、方法和属性。
11. 【F4】
显示类的继承关系，并打开类继承视图。
调试快捷键
Eclipse中有如下一些和运行调试相关的快捷键。
1. 【Ctrl+Shift+B】：在当前行设置断点或取消设置的断点。
2. 【F11】：调试最后一次执行的程序。
3. 【Ctrl+F11】：运行最后一次执行的程序。
4. 【F5】：跟踪到方法中，当程序执行到某方法时，可以按【F5】键跟踪到方法中。
5. 【F6】：单步执行程序。
6. 【F7】：执行完方法，返回到调用此方法的后一条语句。
7. 【F8】：继续执行，到下一个断点或程序结束。
常用编辑器快捷键
通常文本编辑器都提供了一些和编辑相关的快捷键，在Eclipse中也可以通过这些快捷键进行文本编辑。
1. 【Ctrl+C】：复制。
2. 【Ctrl+X】：剪切。
3. 【Ctrl+V】：粘贴。
4. 【Ctrl+S】：保存文件。
5. 【Ctrl+Z】：撤销。
6. 【Ctrl+Y】：重复。
7. 【Ctrl+F】：查找。
其他快捷键
Eclipse中还有很多快捷键，无法一一列举，用户可以通过帮助文档找到它们的使用方式，另外还有几个常用的快捷键如下。
1. 【Ctrl+F6】：切换到下一个编辑器。
2. 【Ctrl+Shift+F6】：切换到上一个编辑器。
3. 【Ctrl+F7】：切换到下一个视图。
4. 【Ctrl+Shift+F7】：切换到上一个视图。
5. 【Ctrl+F8】：切换到下一个透视图。
6. 【Ctrl+Shift+F8】：切换到上一个透视图。

Eclipse中快捷键比较多，可以通过帮助文档找到所有快捷键的使用，但要掌握所有快捷键的使用是不可能的，也没有必要，如果花点时间熟悉本节列举的快捷键，必将会事半功倍
1. edit->content Assist - > add Alt+/ 代码关联
2. Window -> Next Editor -> add Ctrl+Tab 切换窗口
3. Run/Debug Toggle Line Breakpoint -> add Ctrl+` 在调试的时候 增删断点
4. Source-> Surround with try/catch Block -> Ctrl+Shift+v 增加try catch 框框
5. Source -> Generate Getters and Setters -> Ctrl+Shift+. 增加get set 方法
-----------有用的快捷键-----------
Alt+/ 代码助手完成一些代码的插入(但一般和输入法有冲突,可以修改输入法的热键,也可以暂用Alt+/来代替)
Ctrl+1:光标停在某变量上，按Ctrl+1键，可以提供快速重构方案。选中若干行，按Ctrl+1键可将此段代码放入for、while、if、do或try等代码块中。
双击左括号（小括号、中括号、大括号），将选择括号内的所有内容。
Alt+Enter 显示当前选择资源(工程,or 文件 or文件)的属性
-----------Ctrl系列-----------
Ctrl+K:将光标停留在变量上，按Ctrl+K键可以查找到下一个同样的变量
Ctrl+Shift+K:和Ctrl+K查找的方向相反
Ctrl+E 快速显示当前Editer的下拉列表(如果当前页面没有显示的用黑体表示)
Ctrl+Shift+E 显示管理当前打开的所有的View的管理器(可以选择关闭,激活等操作)
Ctrl+Q 定位到最后编辑的地方
Ctrl+L 定位在某行 (对于程序超过100的人就有福音了)
Ctrl+M 最大化当前的Edit或View (再按则反之)
Ctrl+/ 注释当前行,再按则取消注释
Ctrl+T 快速显示当前类的继承结构
Ctrl+Shift-T: 打开类型（Open type）。如果你不是有意磨洋工，还是忘记通过源码树（source tree）打开的方式吧。
Ctrl+O:在代码中打开类似大纲视图的小窗口
Ctrl+鼠标停留:可以显示类和方法的源码
Ctrl+H:打开搜索窗口
Ctrl+/(小键盘) 折叠当前类中的所有代码
Ctrl+×(小键盘) 展开当前类中的所有代码
-----------Ctrl+Shift 系列-----------
Ctrl+Shift+F 格式化当前代码
Ctrl+Shift+X 把当前选中的文本全部变味小写
Ctrl+Shift+Y 把当前选中的文本全部变为小写
Ctrl+Shift+O:快速地导入import
Ctrl+Shift+R:打开资源 open Resource
-----------F快捷键 系列-----------
F3:打开声明该引用的文件
F4:打开类型层次结构
F5:单步跳入
F6:单步跳过
F7:单步跳出
F8:继续，如果后面没有断点，程序将运行完
-----------行编辑用-----------
Ctrl+D: 删除当前行
Ctrl+Alt+↓ 复制当前行到下一行(复制增加)
Ctrl+Alt+↑ 复制当前行到上一行(复制增加)
Alt+↓ 当前行和下面一行交互位置(特别实用,可以省去先剪切,再粘贴了)
Alt+↑ 当前行和上面一行交互位置(同上)
Shift+Enter 在当前行的下一行插入空行(这时鼠标可以在当前行的任一位置,不一定是最后)
Ctrl+Shift+Enter 在当前行插入空行(原理同上条)
-----------不常用的-----------
Alt+← 前一个编辑的页面
Alt+→ 下一个编辑的页面(当然是针对上面那条来说了)
Ctrl+Shift+S:保存全部
Ctrl+W 关闭当前Editer
Ctrl+Shift+F4 关闭所有打开的Editer
Ctrl+Shift+G: 在workspace中搜索引用
Ctrl+Shift+P 定位到对于的匹配符(譬如{}) (从前面定位后面时,光标要在匹配符里面,后面到前面,则反之)
-----------不明白-----------
Ctrl+J 正向增量查找(按下Ctrl+J后,你所输入的每个字母编辑器都提供快速匹配定位到某个单词,如果没有,则在stutes line中显示没有找到了,查一个单词时,特别实用,这个功能Idea两年前就有了)
Ctrl+Shift+J 反向增量查找(和上条相同,只不过是从后往前查)

出处：http://jingyan.baidu.com/article/2a1383285ed0d5074a134ff0.html
================================================================================
最常用的 Eclipse 快捷键总结
阅读目录
•	1. ctrl+shift+r：打开资源
•	2. ctrl+o：快速outline
•	3. ctrl+e：快速转换编辑器
•	4. ctrl+2，L：为本地变量赋值
•	5. alt+shift+r：重命名
•	6. alt+shift+l以及alt+shift+m：提取本地变量及方法
•	7. shift+enter及ctrl+shift+enter
•	8. Alt+方向键
•	9. ctrl+m
•	10. ctrl+.及ctrl+1：下一个错误及快速修改
•	其他的Eclipse窍门
•	Ctrl+Alt+H
本文是一些最实用、最齐全、最省时间的 Eclipse 快捷键总结，这些快捷键可以让帮助你完成工作中的任何一个操作。欢迎参考。
1. ctrl+shift+r：打开资源
这可能是所有快捷键组合中最省时间的了。这组快捷键可以让你打开你的工作区中任何一个文件，而你只需要按下文件名或mask名中的前几个字母，比如applic*.xml。美中不足的是这组快捷键并非在所有视图下都能用。

回到顶部
2. ctrl+o：快速outline
如果想要查看当前类的方法或某个特定方法，但又不想把代码拉上拉下，也不想使用查找功能的话，就用ctrl+o吧。它可以列出当前类中的所有方法及属性，你只需输入你想要查询的方法名，点击enter就能够直接跳转至你想去的位置。

回到顶部
3. ctrl+e：快速转换编辑器
这组快捷键将帮助你在打开的编辑器之间浏览。使用ctrl+page down或ctrl+page up可以浏览前后的选项卡，但是在很多文件打开的状态下，ctrl+e会更加有效率。

回到顶部
4. ctrl+2，L：为本地变量赋值
开发过程中，我常常先编写方法，如Calendar.getInstance()，然后通过ctrl+2快捷键将方法的计算结果赋值于一个本地变量 之上。 这样我节省了输入类名，变量名以及导入声明的时间。Ctrl+F的效果类似，不过效果是把方法的计算结果赋值于类中的域。
回到顶部
5. alt+shift+r：重命名
重命名属性及方法在几年前还是个很麻烦的事，需要大量使用搜索及替换，以至于代码变得零零散散的。今天的Java IDE提供源码处理功能，Eclipse也是一样。现在，变量和方法的重命名变得十分简单，你会习惯于在每次出现更好替代名称的时候都做一次重命名。要使 用这个功能，将鼠标移动至属性名或方法名上，按下alt+shift+r，输入新名称并点击回车。就此完成。如果你重命名的是类中的一个属性，你可以点击alt+shift+r两次，这会呼叫出源码处理对话框，可以实现get及set方法的自动重命名。
回到顶部
6. alt+shift+l以及alt+shift+m：提取本地变量及方法
源码处理还包括从大块的代码中提取变量和方法的功能。比如，要从一个string创建一个常量，那么就选定文本并按下alt+shift+l即可。 如果同 一个string在同一类中的别处出现，它会被自动替换。方法提取也是个非常方便的功能。将大方法分解成较小的、充分定义的方法会极大的减少复杂度，并提 升代码的可测试性。
回到顶部
7. shift+enter及ctrl+shift+enter
Shift+enter在当前行之下创建一个空白行，与光标是否在行末无关。Ctrl+shift+enter则在当前行之前插入空白行。
回到顶部
8. Alt+方向键
这也是个节省时间的法宝。这个组合将当前行的内容往上或下移动。在try/catch部分，这个快捷方式尤其好使。
回到顶部
9. ctrl+m
大显示屏幕能够提高工作效率是大家都知道的。Ctrl+m是编辑器窗口最大化的快捷键。
回到顶部
10. ctrl+.及ctrl+1：下一个错误及快速修改
ctrl+.将光标移动至当前文件中的下一个报错处或警告处。这组快捷键我一般与ctrl+1一并使用，即修改建议的快捷键。新版Eclipse的 修改建 议做的很不错，可以帮你解决很多问题，如方法中的缺失参数，throw/catch exception，未执行的方法等等。

更多快捷键组合可在Eclipse按下ctrl+shift+L查看。
让我们按照使用频率来看看我最爱用的一些热键组合。（注：以下内容在Eclipse3.02及一上版本通过测试）
1. Control-Shift-T: 打开类型（Open type）。如果你不是有意磨洋工，还是忘记通过源码树（source tree）打开的方式吧。用eclipse很容易打开接口的实现类的，按ctrl+t会列出接口的实现类列表
2. Control-Shift-R: 打开资源（不只是用来寻找Java文件）。小提示：利用Navigator视图的黄色双向箭头按钮让你的编辑窗口和导航器相关联。这会让你打开的文件对应显示在导航器的层级结构中，这样便于组织信息。如果这影响了速度，就关掉它。
3. F3: 打开申明（Open declaration）。或者，利用Declaration Tab（在Java视图模式下，选择Windows –> Show View — > Declaration）。当你选中代码中的一个方法，然后按这个按键，它会把整个方法在申明方框里显示出来。
4. Alt-left arrow: 在导航历史记录（Navigation History）中后退。就像Web浏览器的后退按钮一样，在利用F3跳转之后，特别有用。（用来返回原先编译的地方）
5. Alt-right arrow: 导航历史记录中向前。
6. Control-Q: 回到最后一次编辑的地方。这个快捷键也是当你在代码中跳转后用的。特别是当你钻的过深，忘记你最初在做什么的时候。
7. Control-Shift-G: 在workspace中搜索引用（reference）。这 是重构的前提。对于方法，这个热键的作用和F3恰好相反。它使你在方法的栈中，向上找出一个方法的所有调用者。一个与此相关的功能是开启“标记”功能 （occurrence marking） 。选择Windows->Preferences->Java-> Editor-> Mark Occurrences，勾选选项。这时，当你单击一个元素的时候，代码中所有该元素存在的地方都会被高亮显示。我个人只使用“标记本地变量”（Mark Local Variables）。注意：太多的高亮显示会拖慢Eclipse。
8. Control-Shift-F: CodeàJavaàPreferencesà根据代码风格设定重新格式化代码。我 们的团队有统一的代码格式，我们把它放在我们的wiki上。要这么做，我们打开Eclipse，选择Window Style，然后设置Code Formatter，Code Style和Organize Imports。利用导出（Export）功能来生成配置文件。我们把这些配置文件放在wiki上，然后团队里的每个人都导入到自己的Eclipse中。
9. Control-O: 快速概要(quick outline)。通过这个快捷键，你可以迅速的跳到一个方法或者属性，只需要输入名字的头几个字母。
10. Control-/: 对一行注释或取消注释。对于多行也同样适用。
11. Control-Alt-down arrow: 复制高亮显示的一行或多行。
12. Alt-down arrow: 将一行或多行向下移动。Alt-up arrow会向上移动。
其他的热键在菜单里有。你可以通过按下Control-Shift-L（从3.1版本开始）， 看到所有快捷键的列表。按下Control-Shift-L两次，会显示热键对话框（Keys Preferences dialog），你可以在这里自己设置热键。我欢迎你在Talkback部分发表你的Eclipse提示。
回到顶部
其他的Eclipse窍门
我总结了几个相关的小窍门：
锁定命令行窗口：在命令行视图中（Window ->Show View ->Other ->Basic ->Console），试试看用滚动锁定按钮来锁定控制台输出不要滚屏。
使用Ant视图： 在我的Java或Debug模式下，我喜欢显示出Ant视图，这样我就可以迅速的运行Ant任务。通过Window Ant可以找到该视图。把Ant视图放在屏幕的一角， 通过“添加编译文件（Addà Other à Show View à Buildfiles）”按钮来添加build.xml文件。在3.1版本中，甚至支持Ant调试脚本语言。
自动遍历一个集合：for + Control-Space: 如果你还不知道，那么你应该记住Control-Space是自动完成功能。在Eclipse中，你还可以自动完成结构。在一个数组或集合范围内，试试看 输入“for”然后按下Control-Space键。Eclipse会问你你想要遍历哪一个集合然后自动完成循环代码。
使用分级布局： 在包浏览视图（Package Explorer view）中默认的布局（扁平式）方式让我困惑，它把包的全名显示在导航树（navigation tree）中。我更喜欢我源码的包和文件系统视图，在Eclipse中叫做分级布局（Hierarchical Layout）。要切换到这种模式，点击包浏览视图中向下的按钮，选择布局（Layout），然后选择分级（Hierarchial）。
一次显示多个文件：你可以一次浏览多个文件。把不在激活状态的编辑窗口拖到激活窗口的底部或侧边的滚动条上，就可以打开该编辑窗口。这是我能描述该窍门的最好方式了。
同时打开两个Eclipse： 要将改动从一个CVS分支上合并到另外一个上，我喜欢通过同时打开两个工作目录（Workspace）不同Eclipse来实现。这样我可以通过比较 CVS上的最新版本看到所有的变化（右键单击工程，然后选择Compare Lastest from HEAD）然后把每一个变化都合并到另外一个CVS分支上。启动多个Eclipse的最简单的方法是利用Eclipseàwith Launcher。
Implementors插件：安装一个能够跳到一个接口的实现的插件。如果你是个dependency injection 粉丝，或者正在基于编写优良的接口工作，那么你需要一个这样的插件来加速代码导航。 你可以在SourceForge找到这个插件。
回到顶部
Ctrl+Alt+H
如果你想知道一个类的方法到底被那些其他的类调用，那么请选中这个方法名，然后按“Ctrl+Alt+H”，
Eclipse就会显示出这个方法被哪些方法调用，最终产生一个调用关系树。
1. Ctrl+左键
这个是大多数人经常用到的，用来查看变量、方法、类的定义
2. Ctrl+O
查看一个类的纲要，列出其方法和成员变量。提示：再多按一次Ctrl+O，可以列出该类继承的方法和变量。
助记：”O”—>”Outline”—>”纲要”
3. Ctrl+T
查看一个类的继承关系树，是自顶向下的，再多按一次Ctrl+T, 会换成自底向上的显示结构。
提示：选中一个方法名，按Ctrl+T，可以查看到有这个同名方法的父类、子类、接口。
助记：”T”——->”Tree”—–>”层次树”
4.Alt+左右方向键
我们经常会遇到看代码时Ctrl+左键，层层跟踪，然后迷失在代码中的情况，这时只需要按“Alt+左方向键”就可以退回到上次阅读的位置，同理，按“Alt+右方向键”会前进到刚才退回的阅读位置，就像浏览器的前进和后退按钮一样。
导入包：Ctrl+Shift+O
编辑
作用域 功能 快捷键
全局 查找并替换 Ctrl+F
文本编辑器 查找上一个 Ctrl+Shift+K
文本编辑器 查找下一个 Ctrl+K
全局 撤销 Ctrl+Z
全局 复制 Ctrl+C
全局 恢复上一个选择 Alt+Shift+↓
全局 剪切 Ctrl+X
全局 快速修正 Ctrl1+1
全局 内容辅助 Alt+/
全局 全部选中 Ctrl+A
全局 删除 Delete
全局 上下文信息 Alt+？
Alt+Shift+?
Ctrl+Shift+Space
Java编辑器 显示工具提示描述 F2
Java编辑器 选择封装元素 Alt+Shift+↑
Java编辑器 选择上一个元素 Alt+Shift+←
Java编辑器 选择下一个元素 Alt+Shift+→
文本编辑器 增量查找 Ctrl+J
文本编辑器 增量逆向查找 Ctrl+Shift+J
全局 粘贴 Ctrl+V
全局 重做 Ctrl+Y
查看
作用域 功能 快捷键
全局 放大 Ctrl+=
全局 缩小 Ctrl+-
窗口
作用域 功能 快捷键
全局 激活编辑器 F12
全局 切换编辑器 Ctrl+Shift+W
全局 上一个编辑器 Ctrl+Shift+F6
全局 上一个视图 Ctrl+Shift+F7
全局 上一个透视图 Ctrl+Shift+F8
全局 下一个编辑器 Ctrl+F6
全局 下一个视图 Ctrl+F7
全局 下一个透视图 Ctrl+F8
文本编辑器 显示标尺上下文菜单 Ctrl+W
全局 显示视图菜单 Ctrl+F10
全局 显示系统菜单 Alt+-
导航
作用域 功能 快捷键
Java编辑器 打开结构 Ctrl+F3
全局 打开类型 Ctrl+Shift+T
全局 打开类型层次结构 F4
全局 打开声明 F3
全局 打开外部javadoc Shift+F2
全局 打开资源 Ctrl+Shift+R
全局 后退历史记录 Alt+←
全局 前进历史记录 Alt+→
全局 上一个 Ctrl+,
全局 下一个 Ctrl+.
Java编辑器 显示大纲 Ctrl+O
全局 在层次结构中打开类型 Ctrl+Shift+H
全局 转至匹配的括号 Ctrl+Shift+P
全局 转至上一个编辑位置 Ctrl+Q
Java编辑器 转至上一个成员 Ctrl+Shift+↑
Java编辑器 转至下一个成员 Ctrl+Shift+↓
文本编辑器 转至行 Ctrl+L
搜索
作用域 功能 快捷键
全局 出现在文件中 Ctrl+Shift+U
全局 打开搜索对话框 Ctrl+H
全局 工作区中的声明 Ctrl+G
全局 工作区中的引用 Ctrl+Shift+G
文本编辑
作用域 功能 快捷键
文本编辑器 改写切换 Insert
文本编辑器 上滚行 Ctrl+↑
文本编辑器 下滚行 Ctrl+↓
文件
作用域 功能 快捷键
全局 保存 Ctrl+X Ctrl+S
全局 打印 Ctrl+P
全局 关闭 Ctrl+F4
全局 全部保存 Ctrl+Shift+S
全局 全部关闭 Ctrl+Shift+F4
全局 属性 Alt+Enter
全局 新建 Ctrl+N
项目
作用域 功能 快捷键
全局 全部构建 Ctrl+B
源代码
作用域 功能 快捷键
Java编辑器 格式化 Ctrl+Shift+F
Java编辑器 取消注释 Ctrl+/
Java编辑器 注释 Ctrl+/
Java编辑器 添加单个import Ctrl+Shift+M
Java编辑器 组织多个import Ctrl+Shift+O
Java编辑器 使用try/catch块来包围 未设置，太常用了，所以在这里列出,建议自己设置。也可以使用Ctrl+1自动修正。
调试/运行
作用域 功能 快捷键
全局 单步返回 F7
全局 单步跳过 F6
全局 单步跳入 F5
全局 单步跳入选择 Ctrl+F5
全局 调试上次启动 F11
全局 继续 F8
全局 使用过滤器单步执行 Shift+F5
全局 添加/去除断点 Ctrl+Shift+B
全局 显示 Ctrl+D
全局 运行上次启动 Ctrl+F11
全局 运行至行 Ctrl+R
全局 执行 Ctrl+U
重构
作用域 功能 快捷键
全局 撤销重构 Alt+Shift+Z
全局 抽取方法 Alt+Shift+M
全局 抽取局部变量 Alt+Shift+L
全局 内联 Alt+Shift+I
全局 移动 Alt+Shift+V
全局 重命名 Alt+Shift+R
全局 重做 Alt+Shift+Y
（1）Ctrl+M切换窗口的大小
（2）Ctrl+Q跳到最后一次的编辑处
（3）F2当鼠标放在一个标记处出现Tooltip时候按F2则把鼠标移开时Tooltip还会显示即Show Tooltip Description。
F3跳到声明或定义的地方。
F5单步调试进入函数内部。
F6单步调试不进入函数内部，如果装了金山词霸2006则要把“取词开关”的快捷键改成其他的。
F7由函数内部返回到调用处。
F8一直执行到下一个断点。
（4）Ctrl+Pg~对于XML文件是切换代码和图示窗口
（5）Ctrl+Alt+I看Java文件中变量的相关信息
（6）Ctrl+PgUp对于代码窗口是打开“Show List”下拉框，在此下拉框里显示有最近曾打开的文件
（7）Ctrl+/ 在代码窗口中是这种//~注释。Ctrl+Shift+/ 在代码窗口中是这种/*~*/注释，在JSP文件窗口中是〈!–~–〉。
（8）Alt+Shift+O(或点击工具栏中的Toggle Mark Occurrences按钮) 当点击某个标记时可使本页面中其他地方的此标记黄色凸显，并且窗口的右边框会出现白色的方块，点击此方块会跳到此标记处。
（9）右击窗口的左边框即加断点的地方选Show Line Numbers可以加行号。
（10）Ctrl+I格式化激活的元素Format Active Elements。Ctrl+Shift+F格式化文件Format Document。
（11）Ctrl+S保存当前文件。Ctrl+Shift+S保存所有未保存的文件。
（12）Ctrl+Shift+M(先把光标放在需导入包的类名上) 作用是加Import语句。Ctrl+Shift+O作用是缺少的Import语句被加入，多余的Import语句被删除。
（13）Ctrl+Space提示键入内容即Content Assist，此时要将输入法中Chinese(Simplified)IME-Ime/Nonlme Toggle的快捷键（用于切换英文和其他文字）改成其他的。Ctrl+Shift+Space提示信息即Context Information。
（14）双击窗口的左边框可以加断点。
（15）Ctrl+D删除当前行。
Eclipse快捷键大全
Ctrl+1 快速修复(最经典的快捷键,就不用多说了)
Ctrl+D: 删除当前行
Ctrl+Alt+↓ 复制当前行到下一行(复制增加)
Ctrl+Alt+↑ 复制当前行到上一行(复制增加)
Alt+↓ 当前行和下面一行交互位置(特别实用,可以省去先剪切,再粘贴了)
Alt+↑ 当前行和上面一行交互位置(同上)
Alt+← 前一个编辑的页面
Alt+→ 下一个编辑的页面(当然是针对上面那条来说了)
Alt+Enter 显示当前选择资源(工程,or 文件 or文件)的属性
Shift+Enter 在当前行的下一行插入空行(这时鼠标可以在当前行的任一位置,不一定是最后)
Shift+Ctrl+Enter 在当前行插入空行(原理同上条)
Ctrl+Q 定位到最后编辑的地方
Ctrl+L 定位在某行 (对于程序超过100的人就有福音了)
Ctrl+M 最大化当前的Edit或View (再按则反之)
Ctrl+/ 注释当前行,再按则取消注释
Ctrl+O 快速显示 OutLine
Ctrl+T 快速显示当前类的继承结构
Ctrl+W 关闭当前Editer
Ctrl+K 参照选中的Word快速定位到下一个
Ctrl+E 快速显示当前Editer的下拉列表(如果当前页面没有显示的用黑体表示)
Ctrl+/(小键盘) 折叠当前类中的所有代码
Ctrl+×(小键盘) 展开当前类中的所有代码
Ctrl+Space 代码助手完成一些代码的插入(但一般和输入法有冲突,可以修改输入法的热键,也可以暂用Alt+/来代替)
Ctrl+Shift+E 显示管理当前打开的所有的View的管理器(可以选择关闭,激活等操作)
Ctrl+J 正向增量查找(按下Ctrl+J后,你所输入的每个字母编辑器都提供快速匹配定位到某个单词,如果没有,则在stutes line中显示没有找到了,查一个单词时,特别实用,这个功能Idea两年前就有了)
Ctrl+Shift+J 反向增量查找(和上条相同,只不过是从后往前查)
Ctrl+Shift+F4 关闭所有打开的Editer
Ctrl+Shift+X 把当前选中的文本全部变味小写
Ctrl+Shift+Y 把当前选中的文本全部变为小写
Ctrl+Shift+F 格式化当前代码
Ctrl+Shift+P 定位到对于的匹配符(譬如{}) (从前面定位后面时,光标要在匹配符里面,后面到前面,则反之)
下面的快捷键是重构里面常用的,本人就自己喜欢且常用的整理一下(注:一般重构的快捷键都是Alt+Shift开头的了)
Alt+Shift+R 重命名 (是我自己最爱用的一个了,尤其是变量和类的Rename,比手工方法能节省很多劳动力)
Alt+Shift+M 抽取方法 (这是重构里面最常用的方法之一了,尤其是对一大堆泥团代码有用)
Alt+Shift+C 修改函数结构(比较实用,有N个函数调用了这个方法,修改一次搞定)
Alt+Shift+L 抽取本地变量( 可以直接把一些魔法数字和字符串抽取成一个变量,尤其是多处调用的时候)
Alt+Shift+F 把Class中的local变量变为field变量 (比较实用的功能)
Alt+Shift+I 合并变量(可能这样说有点不妥Inline)
Alt+Shift+V 移动函数和变量(不怎么常用)
Alt+Shift+Z 重构的后悔药(Undo)

'', ''#eclipse#'', 5, ''请选择'', 2, ''YC'', ''2019-06-18'', ''2019-06-18'', null, ''1几个最重要的快捷键
代码助手:Ctrl+Space（简体中文操作系统是Alt+/）
快速修正：Ctrl+1
单词补全：Alt+/
打开外部Java文档：Shift+F2
'', null, null, 0, 0, null);
INSERT INTO artical (ID, AUTHOR, ORIGINAUTHOR, ORIGINURL, TITTLE, IMGPATH, CONTENT, TAGS, NAVID, TOPICID, CATEGORIES, TYPE, CREATEDATE, UPDATEDATE, ARTICALURL, SUMMARY, LASTARTICALID, NEXTARTICALID, LIKENUMS, DISSNUMS, INTOP) VALUES (18, ''老干部'', '''', '''', ''Eclipse中tomcat无法访问localhost8080解决方法'', ''images/8.jpg'', ''症状：
tomcat在eclipse里面能正常启动，而在浏览器中访问http://localhost:8080/不能访问，且报404错误。同时其他项目页面也不能访问。
关闭eclipse里面的tomcat，在tomcat安装目录下双击startup.bat手动启动tomcat服务器。访问htt://localhost:8080/能正常访问tomcat管理页面。
症状原因：
       eclipse将tomcat的项目发布目录（tomcat 目录中的webapp）重定向了,所以你会发现在tomcat安装目录下的webapp目录里面找不到你的项目文件。
解决办法：
重新配置下tomcat服务器：
在eclipse中的server页面，双击tomcat服务，会看到如图所示的配置页面：


可以看到红圈中选择的是 Use workspace metadata(does not modify Tomcat installion)
如果该tomcat中部署了项目的话，这红圈中的选项会灰掉不能修改，要修改必须得先把tomcat中的部署的服务都移除。
如图：


通过右键单击tomcat服务器选择 Add and Remove，在弹出的对话框中移除已部署的项目。移除完确定后，将看到上面的选项面板部分可编辑了。
选择Use tomcat installation(Task control of Tomcat installation) 即选择tomcat的安装目录来作为项目的发布目录。
然后,下来四行,看到"Deploy Path"了没?它后面的值默认是"wtpwebapps",把它改成"webapps",也就是 tomcat
中发布项目所在的文件夹名字。
修改后关掉该页面，保存配置。这样就将项目部署到了tomcat安装目录下的webapp
重启tomcat服务器，访问http://localhost:8080则能正常访问了，自己部署的项目也能正常访问了。

'', '''', 5, ''请选择'', 2, ''YC'', ''2019-06-18'', ''2019-06-18'', null, ''tomcat在eclipse里面能正常启动，而在浏览器中访问http://localhost:8080/不能访问，且报404错误。同时其他项目页面也不能访问。关闭eclipse里面的tomcat，在tomcat安装目录下双击startup.bat手动启动tomcat服务器。访问htt://localhost:8080/能正常访问tomcat管理页面。'', null, null, 0, 0, null);
INSERT INTO artical (ID, AUTHOR, ORIGINAUTHOR, ORIGINURL, TITTLE, IMGPATH, CONTENT, TAGS, NAVID, TOPICID, CATEGORIES, TYPE, CREATEDATE, UPDATEDATE, ARTICALURL, SUMMARY, LASTARTICALID, NEXTARTICALID, LIKENUMS, DISSNUMS, INTOP) VALUES (19, ''老干部'', '''', '''', ''JavaSE大纲'', ''images/4.jpg'', ''Javase复习大纲
第一部分：基础知识
第二部分：面向对象
1.封装
类：对一类事物抽象所得到的概念；
对象：一个具体的事物；
构造函数：
不能有返回值；
方法名与类名相同 ；
可以有多个 ；
默认生成无参方法体无返回值的构造函数 ；
自己一旦定义，编译器就不会自动生成默认的构造函数 ；
生成一个类对象时能且只能调用其中的一个构造函数；
static：
凡是static修饰的成员都是静态成员；
静态成员都是属于类；
非静态的可以访问静态的；
而静态的不能访问静态的；
通过类名只能访问里面的非私有(private)成员里面的static静态成员；
私有静态成员也不可以通过对象名访问；

this：
非静态方法默认都含有一个this指针；
this代表正在调用该方法的对象；

final：
修饰类：表示该类不能被继承；
修饰方法：该方法可以被继承但是不能被重写；
修饰属性：表示该属性能且只能被赋一次值，赋值的方法有两种
1.定义的同时显示初始化；
2.构造函数中初始化；
重载函数
同名不同参数；
返回值不能作为是否为构成重载函数的依据；
2.继承
定义：子类继承了父类的成员；
注意的问题：
私有成员不可以被继承(非私有成员才可以被子类继承)；
重写：
重写方法必须和被重写方法具有相同的方法名称，参数列表，返回值名称；
重写方法的访问权限不能小于被重写方法；
3.多态
定义：
一个父类的引用可以指向父类对象，也可以指向子类对象，它可以根据当前时	刻的指向的不同，自动调用不同对象的方法；
同一代码可以随上下文的不同而执行不同的操作，俗称多态；
注意事项：
通过父类的引用只能访问子类从父类继承过来的成员；
只有在父类在父类的引用指向的就是一个子类对象时，我们才可以把父类引用	强制转化为子类引用；
相关知识：
抽象类：
一个抽象类一般都含有抽象方法；
只重写了抽象类部分抽象方法的类也必须定义为abstract；
不可以定义抽象类对象，但是抽象类可以实现多态；
接口：
接口中方法都是public abstract；
不可以定义接口对象，但接口可以实现多态；
重写接口方法时，public不能省略，举例：
线程的创建
事件的处理
容器的组织方式
Serializable接口
第三部分：高级部分
1.异常
定义：运行时的错误
分类：
无法处理的错误；
可以处理的异常：
必须处理的异常：是Exception的子类但是不是RuntimeException的子类
可处理可不处理的异常：是RuntimeException的子类
注意问题：
finally(...)一定会执行
先捕获子类异常，然后再捕获父类异常，顺序不可颠倒；
重写方法抛出异常的范围不能大于被重写方法抛出异常的范围；
假设f()方法抛出了A异常，有两种方法处理异常：
1.throws A
2.try{}catch{}
2.线程
定义：一个程序运行时的不同执行路径；
创建线程的方式：
1.继承了(extends)Thread类；
2.实现了Runnable接口；
线程的同步：
多个线程操作同一资源并且要求这些操作中的若干个操作不能被中断，这时就	需要考虑线程同步的问题；
线程同步是通过synchronized来实现；
synchronized可以修饰两种：
代码块：默认锁定this
示例：卖票
线程的通信：
有时多个线程只有彼此相互协作才能完成某个功能，这就需要线程通信；
实现方法：
wait和notify() / notifyAll()
示例：生产和消费
3.包
包的生成与运行：
package语句必须是第一条语句
类名是包名和类名的组合；
只有在整个包的最上层才可以运行；
同包的相互访问：
不同包的相互访问:
Jar包的生成和使用：
普通jar包的生成：jar -cvf 要生成的jar包的名字.Jar *；
可运行jar包的生成：jar cvfm 要生成jar包的名字.Jar  1.txt;
4.GUI
容器和组建的关系：容器是组建，但组建不一定是容器；
常见的布局管理器：
BroderLayout --Frame
FlowLayout --Pannel
GridLayout --
事件模型：
必须明白哪些操作是编译器自动完成，哪些是程序员手动处理完成的；
程序员只需要做两件事：
告诉事件源可以产生哪些事件；
设计好这些可以处理事件的事件监听器；
内部类：
在一个类内部定义的类叫做内部类；
内部类的方法可以访问外部类的所有成员；
外部类的方法不可以直接访问内部类的任何成员；
一定要明白产生内部类的原因：
如果一个类A要使用B类的所有成员，并且A类不需要被除B以外
的其他类访问，则可以把A定义为B的内部类；
因此几乎不存在直接生成内部类对象的问题；
因此几乎不存在外部类需要访问内部类的问题；
匿名类：
匿名类是内部类的一种极端表现形式；
匿名类可以访问外部类中的所有成员和包裹本方法中的final类型的局部；
变量；
5.IO
定义：
如果一个类是用来完成程序和设备之间的数据传输，则这个类有一个特殊的称
谓叫做流；
流和类的关系：流一定是类，但类不一定是流；
分类：
输入流 输出流
字符流 字节流
原始流 包裹流
常用流的介绍：
四大基本抽象流：
InputStream	OutputStream
Reader	Writer
字符流和字节流的区别：
字节流可以处理所有格式的文件；
字符流只能处理文本格式的文件；
文件流：
FileInputStream	FileOutputStream
FileReader	FileWriter
缓冲流：
BufferedInputStream	BufferedOutputStream
BufferedReader	BufferedWriter
转换流：
OutputStreamReader	OutputStreamWriter
例子：如何将键盘上的字符组成字符串赋给String对象；
  编程实现把用户从键盘输入的字符保存到一个String对象中；
数据流：
DataInputStream	DataOutputStream
数据流可以把基本类型数据的二进制直接读入或写出；
例子：编程实现将long类型数据写入byte数组
  然后再从byte中读取该数据；
Print流：
PrintStream	FileWriter
Print流可以把基本类型数据转化为字符串输出；
例子：编程实现把键盘输入的数据写入A文件，如果输入有误，则把出		  错信息写入B文件；
Object流：
ObjectInputStream		ObjectOutputStream
Object流可以把一个对象直接写入或读出
6.容器
定义：
如果一个类是专门用来存放其他类对象的，则这个类有另外一个特殊的词叫
做容器；
容器和类的关系：容器一定是类，但类不一定是容器；
Collection接口：
Set接口：
无序，不允许重复；
实现类：
TreeSet	HashSet
List接口：
有序，允许重复；
ArrayList		LinkedList
Map接口;
定义：既保存数据本身，也保存主键的一种接口；
实现类：
HashMap		TreeMap
hashCode()和equals()：重写hashCode和equals方法；
Collection类：
该类提供了对Collection接口实现类的排序，倒置，查找等功能；
Comparable接口：
通过该接口的方法可以制定出对象之间比较的标准；
凡是需要进行对象的比较排序的场合均可以考虑实现该接口；
Iterator接口：
利用该接口提供的方法我们可以遍历所有容器中的元素；


'', '''', 5, ''1'', 2, ''YC'', ''2019-06-18'', ''2019-06-18'', null, ''Javase复习大纲
第一部分：基础知识第二部分：面向对象
1.封装
类：对一类事物抽象所得到的概念；
对象：一个具体的事物；构造函数：不能有返回值；方法名与类名相同 ；可以有多个 ；
'', null, null, 0, 0, null);
INSERT INTO artical (ID, AUTHOR, ORIGINAUTHOR, ORIGINURL, TITTLE, IMGPATH, CONTENT, TAGS, NAVID, TOPICID, CATEGORIES, TYPE, CREATEDATE, UPDATEDATE, ARTICALURL, SUMMARY, LASTARTICALID, NEXTARTICALID, LIKENUMS, DISSNUMS, INTOP) VALUES (20, ''老干部'', '''', '''', ''linux下安装mysql'', ''images/5.jpg'', ''linux下卸载mysql方法
a. 查找已安装的myslq 版本：
#rpm - qa | grep mysql（注意大小写，如果mysql不行就换MySQL）
[root@localhost ~]# rpm  -qa | grep  mysql
复制代码
在屏幕上将显示已安装的mysql包名如：mysql-5.0.77-4.el5_4.2 ;
将搜索出的包名卸载：
#rpm -e -nodeps mysql-5.0.77-4.el5_4.2  （nodeps表示强制删除） Linux查看mysql 安装路径
一、查看文件安装路径
由于软件安装的地方不止一个地方，所有先说查看文件安装的所有路径(地址)。
这里以mysql为例。比如说我安装了mysql,但是不知道文件都安装在哪些地方、放在哪些文件夹里，可以用下面的命令查看所有的文件路径
在终端输入：
whereis mysql
回车，如果你安装好了mysql，就会显示文件安装的地址，例如我的显示(安装地址可能会不同)
[root@localhost ~]# whereis mysql
mysql: /usr/bin/mysql /usr/lib/mysql /usr/share/mysql /usr/share/man/man1/mysql.1.gz
linux下使用yum安装mysql

1、安装
查看有没有安装过：
yum list installed mysql*
rpm -qa | grep mysql*

查看有没有安装包：
yum list mysql*
安装mysql客户端：
yum install mysql

安装mysql 服务器端：
          yum install mysql-server
          yum install mysql-devel
  www.2cto.com
2、启动&&停止

数据库字符集设置
          mysql配置文件/etc/my.cnf中加入default-character-set=utf8

启动mysql服务：
          service mysqld start或者/etc/init.d/mysqld start
开机启动：
          chkconfig -add mysqld，查看开机启动设置是否成功chkconfig --list | grep mysql*

          mysqld   0:关闭    1:关闭    2:启用    3:启用    4:启用    5:启用    6:关闭
停止：
          service mysqld stop
2、登录

创建root管理员：
          mysqladmin -u root password 123456
  www.2cto.com
登录：
          mysql -u root -p输入密码即可。
忘记密码：
          service mysqld stop

          mysqld_safe --user=root --skip-grant-tables

          mysql -u root

          use mysql

          update user set password=password("new_pass") where user="root";

          flush privileges;

3、远程访问

开放防火墙的端口号
mysql增加权限：mysql库中的user表新增一条记录host为“%”，user为“root”。
4、Linux MySQL的几个重要目录
  www.2cto.com
数据库目录
         /var/lib/mysql/
配置文件
         /usr/share /mysql（mysql.server命令及配置文件）
相关命令
         /usr/bin（mysqladmin mysqldump等命令）
启动脚本
         /etc/rc.d/init.d/（启动脚本文件mysql的目录）


常见操作动MySQL的命令及相关知识
一、总结一下：
1.Linux系统下启动MySQL的命令：
/ect/init.d/mysql start (前面为mysql的安装路径)
2.linux下重启mysql的命令：
/ect/init.d/mysql restart (前面为mysql的安装路径)
3.linux下关闭mysql的命令：
/ect/init.d/mysql   shutdown (前面为mysql的安装路径)
4.连接本机上的mysql：
进入目录mysql\bin，再键入命令mysql -uroot -p， 回车后提示输入密码。
退出mysql命令：exit（回车）
mysql -uroot --password=""（注意在root用户下）
5.修改mysql密码：
mysqladmin -u用户名 -p旧密码 password 新密码
或进入mysql命令行SET PASSWORD FOR root=PASSWORD("root");
6.增加新用户。（注意：mysql环境中的命令后面都带一个分号作为命令结束符）
grant select on 数据库.* to 用户名@登录主机 identified by "密码"
如增加一个用户test密码为123，让他可以在任何主机上登录，并对所有数据库有查询、插入、修改、删除的权限。首先用以root用户连入mysql，然后键入以下命令：
grant select,insert,update,delete on *.* to " Identified by "123";
二、有关MySQL数据库方面的操作
必须首先登录到mysql中，有关操作都是在mysql的提示符下进行，而且每个命令以分号结束
1、显示数据库列表。
show databases;
2、显示库中的数据表：
use mysql； ／／打开库
show tables;
3、显示数据表的结构：
describe 表名;
4、建库：
create database 库名;
5、建表：
use 库名；
create table 表名(字段设定列表)；
6、删库和删表:
drop database 库名;
drop table 表名；
7、将表中记录清空：
delete from 表名;
8、显示表中的记录：
select * from 表名;
9、编码的修改
如果要改变整个mysql的编码格式：
启动mysql的时候，mysqld_safe命令行加入
--default-character-set=gbk
如果要改变某个库的编码格式：在mysql提示符后输入命令
alter database db_name default character set gbk;
三、数据的导入导出
1、文本数据转到数据库中
文本数据应符合的格式：字段数据之间用tab键隔开，null值用来代替。例：
1 name duty 2006-11-23
数据传入命令 load data local infile "文件名" into table 表名;
2、导出数据库和表
mysqldump --opt news > news.sql（将数据库news中的所有表备份到news.sql文件，news.sql是一个文本文件，文件名任取。）
mysqldump --opt news author article > author.article.sql（将数据库news中的author表和article表备份到author.article.sql文件， author.article.sql是一个文本文件，文件名任取。）
mysqldump --databases db1 db2 > news.sql（将数据库dbl和db2备份到news.sql文件，news.sql是一个文本文件，文件名任取。）
mysqldump -h host -u user -p pass --databases dbname > file.dump
就是把host上的以名字user，口令pass的数据库dbname导入到文件file.dump中
mysqldump --all-databases > all-databases.sql（将所有数据库备份到all-databases.sql文件，all-databases.sql是一个文本文件，文件名任取。）
3、导入数据
mysql source news.sql;（在mysql命令下执行，可导入表）

'', ''#linux#/#mysql#'', 5, ''请选择'', 2, ''YC'', ''2019-06-18'', ''2019-06-18'', null, ''linux下卸载mysql方法
a. 查找已安装的myslq 版本：
#rpm - qa | grep mysql（注意大小写，如果mysql不行就换MySQL）
[root@localhost ~]# rpm  -qa | grep  mysql
复制代码
在屏幕上将显示已安装的mysql包名如：mysql-5.0.77-4.el5_4.2 ;
'', null, null, 0, 0, null);
INSERT INTO artical (ID, AUTHOR, ORIGINAUTHOR, ORIGINURL, TITTLE, IMGPATH, CONTENT, TAGS, NAVID, TOPICID, CATEGORIES, TYPE, CREATEDATE, UPDATEDATE, ARTICALURL, SUMMARY, LASTARTICALID, NEXTARTICALID, LIKENUMS, DISSNUMS, INTOP) VALUES (21, ''老干部'', '''', '''', ''Windows7下配置java环境变量'', ''images/1.jpg'', ''win7（windows7）下java环境变量配置方法

   windows7下java环境变量配置方法：
   1.用鼠标右击“计算机”->属性

选择左边导航的“高级系统设置”选项

   继续选择右下角的“环境变量”选项
   2.进行win7下Java环境变量配置


在"系统变量"下进行如下配置：
(1)新建->变量名：JAVA_HOME 变量值：C:\Program Files\Java\jdk1.6.0_45
(这只是我的JDK安装路径)

(2)新建->变量名：CLASSPATH 变量值：.;%JAVA_HOME%/lib;%JAVA_HOME%/lib/dt.jar;%JAVA_HOME%/lib/tools.jar
(3)编辑->变量名：Path 在变量值的最前面加上：%JAVA_HOME%/bin;%JAVA_HOME%/jre/bin;
注意：当设置的变量在末尾时，不要加上“;”。

  3.测试下环境变量是否设置成功
    在左下角的搜索框中键入cmd 或者按下“WIN+R”键,“WIN”键分别输入java，javac，java -version 命令
   如果出现如下信息：


   4.你的Java环境变量配置成功！
   注意:
   若出现
   ''''javac'''' 不是内部或外部命令，也不是可运行的程序
   或批处理文件。
   说明此次Java环境变量配置出错了，仔细检查下吧！
'', '''', 5, ''请选择'', 8, ''YC'', ''2019-06-18'', ''2019-06-18'', null, ''win7（windows7）下java环境变量配置方法windows7下java环境变量配置方法：1.用鼠标右击“计算机”->属性   选择左边导航的“高级系统设置”选项继续选择右下角的“环境变量”选项2.进行win7下Java环境变量配置
   '', null, null, 0, 0, null);
INSERT INTO artical (ID, AUTHOR, ORIGINAUTHOR, ORIGINURL, TITTLE, IMGPATH, CONTENT, TAGS, NAVID, TOPICID, CATEGORIES, TYPE, CREATEDATE, UPDATEDATE, ARTICALURL, SUMMARY, LASTARTICALID, NEXTARTICALID, LIKENUMS, DISSNUMS, INTOP) VALUES (22, ''老干部'', '''', '''', ''常用数据库连接语句'', ''images/1.jpg'', ''MySQL:
Driver:com.mysql.jdbc.Driver
URL:jdbc:mysql://localhost:3306/db_name
Class.forName(Driver);
Connection con = DriverManager.getConnection(URL,Username,Password);

Microsoft SQL Server
Driver:com.microsoft.jdbc.sqlserver.SQLServerDriver
URL:jdbc:microsoft:sqlserver://localhost:1433;DatabaseName=db_name


SysBase:
Driver:com.sybase.jdbc.SybDriver
URL:jdbc:Sysbase://localhost:5007/db_name


Oracle:
Driver:oracle.jdbc.driver.OracleDriver
URL:jdbc:oracle:thin@localhost:1521:orcl

DB2:
Driver:com.ibm.db2.jdbc.app.DB2.Driver  (这是连接具有DB2客户端的Provider)
Driver:com.ibm.db2.jdbc.net.DB2.Driver  (这是连接不具有DB2客户端的Provider)
URL:jdbc:db2://localhost:5000/db_name

'', '''', 5, ''请选择'', 10, ''YC'', ''2019-06-18'', null, null, ''MySQL:
Driver:com.mysql.jdbc.Driver
URL:jdbc:mysql://localhost:3306/db_name
Class.forName(Driver);
Connection con = DriverManager.getConnection(URL,Username,Password);'', null, null, 0, 0, null);
INSERT INTO artical (ID, AUTHOR, ORIGINAUTHOR, ORIGINURL, TITTLE, IMGPATH, CONTENT, TAGS, NAVID, TOPICID, CATEGORIES, TYPE, CREATEDATE, UPDATEDATE, ARTICALURL, SUMMARY, LASTARTICALID, NEXTARTICALID, LIKENUMS, DISSNUMS, INTOP) VALUES (23, ''老干部'', '''', '''', ''程序员应该了解的关于内存的知识'', ''images/4.jpg'', ''1 简介
早期计算机比现在更为简单。系统的各种组件例如CPU，内存，大容量存储器和网口，由于被共同开发因而有非常均衡的表现。例如，内存和网口并不比CPU在提供数据的时候更（特别的）快。
曾今计算机稳定的基本结构悄然改变，硬件开发人员开始致力于优化单个子系统。于是电脑一些组件的性能大大的落后因而成为了瓶颈。由于开销的原因，大容量存储器和内存子系统相对于其他组件来说改善得更为缓慢。
大容量存储的性能问题往往靠软件来改善: 操作系统将常用(且最有可能被用)的数据放在主存中，因为后者的速度要快上几个数量级。或者将缓存加入存储设备中，这样就可以在不修改操作系统的前提下提 升性能。{然而，为了在使用缓存时保证数据的完整性，仍然要作出一些修改。}这些内容不在本文的谈论范围之内，就不作赘述了。
而解决内存的瓶颈更为困难，它与大容量存储不同，几乎每种方案都需要对硬件作出修改。目前，这些变更主要有以下这些方式:
•	RAM的硬件设计(速度与并发度)
•	内存控制器的设计
•	CPU缓存
•	设备的直接内存访问(DMA)
本文主要关心的是CPU缓存和内存控制器的设计。在讨论这些主题的过程中，我们还会研究DMA。不过，我们首先会从当今商用硬件的设计谈起。这有助 于我们理解目前在使用内存子系统时可能遇到的问题和限制。我们还会详细介绍RAM的分类，说明为什么会存在这么多不同类型的内存。
本文不会包括所有内容，也不会包括最终性质的内容。我们的讨论范围仅止于商用硬件，而且只限于其中的一小部分。另外，本文中的许多论题，我们只会点到为止，以达到本文目标为标准。对于这些论题，大家可以阅读其它文档，获得更详细的说明。
当本文提到操作系统特定的细节和解决方案时，针对的都是Linux。无论何时都不会包含别的操作系统的任何信息，作者无意讨论其他操作系统的情况。如果读者认为他/她不得不使用别的操作系统，那么必须去要求供应商提供其操作系统类似于本文的文档。
在开始之前最后的一点说明，本文包含大量出现的术语“经常”和别的类似的限定词。这里讨论的技术在现实中存在于很多不同的实现，所以本文只阐述使用得最广泛最主流的版本。在阐述中很少有地方能用到绝对的限定词。
1.1文档结构
这个文档主要视为软件开发者而写的。本文不会涉及太多硬件细节，所以喜欢硬件的读者也许不会觉得有用。但是在我们讨论一些有用的细节之前，我们先要描述足够多的背景。
在这个基础上，本文的第二部分将描述RAM（随机寄存器）。懂得这个部分的内容很好，但是此部分的内容并不是懂得其后内容必须部分。我们会在之后引用不少之前的部分，所以心急的读者可以跳过任何章节来读他们认为有用的部分。
第三部分会谈到不少关于CPU缓存行为模式的内容。我们会列出一些图标，这样你们不至于觉得太枯燥。第三部分对于理解整个文章非常重要。第四部分将简短的描述虚拟内存是怎么被实现的。这也是你们需要理解全文其他部分的背景知识之一。
第五部分会提到许多关于Non Uniform Memory Access (NUMA)系统。
第六部分是本文的中心部分。在这个部分里面，我们将回顾其他许多部分中的信息，并且我们将给阅读本文的程序员许多在各种情况下的编程建议。如果你真的很心急，那么你可以直接阅读第六部分，并且我们建议你在必要的时候回到之前的章节回顾一下必要的背景知识。
本文的第七部分将介绍一些能够帮助程序员更好的完成任务的工具。即便在彻底理解了某一项技术的情况下，距离彻底理解在非测试环境下的程序还是很遥远的。我们需要借助一些工具。
第八部分，我们将展望一些在未来我们可能认为好用的科技。
1.2 反馈问题
作者会不定期更新本文档。这些更新既包括伴随技术进步而来的更新也包含更改错误。非常欢迎有志于反馈问题的读者发送电子邮件。
1.3 致谢
我首先需要感谢Johnray Fuller尤其是Jonathan Corbet，感谢他们将作者的英语转化成为更为规范的形式。Markus Armbruster提供大量本文中对于问题和缩写有价值的建议。
1.4 关于本文
本文题目对David Goldberg的经典文献《What Every Computer Scientist Should Know About Floating-Point Arithmetic》[goldberg]表示致敬。Goldberg的论文虽然不普及，但是对于任何有志于严格编程的人都会是一个先决条件。
2 商用硬件现状
鉴于目前专业硬件正在逐渐淡出，理解商用硬件的现状变得十分重要。现如今，人们更多的采用水平扩展，也就是说，用大量小型、互联的商用计算机代替巨 大、超快(但超贵)的系统。原因在于，快速而廉价的网络硬件已经崛起。那些大型的专用系统仍然有一席之地，但已被商用硬件后来居上。2007年，Red Hat认为，未来构成数据中心的“积木”将会是拥有最多4个插槽的计算机，每个插槽插入一个四核CPU，这些CPU都是超线程的。{超线程使单个处理器核 心能同时处理两个以上的任务，只需加入一点点额外硬件}。也就是说，这些数据中心中的标准系统拥有最多64个虚拟处理器。当然可以支持更大的系统，但人们 认为4插槽、4核CPU是最佳配置，绝大多数的优化都针对这样的配置。
在不同商用计算机之间，也存在着巨大的差异。不过，我们关注在主要的差异上，可以涵盖到超过90%以上的硬件。需要注意的是，这些技术上的细节往往日新月异，变化极快，因此大家在阅读的时候也需要注意本文的写作时间。
这么多年来，个人计算机和小型服务器被标准化到了一个芯片组上，它由两部分组成: 北桥和南桥，见图2.1。

图2.1 北桥和南桥组成的结构
CPU通过一条通用总线(前端总线，FSB)连接到北桥。北桥主要包括内存控制器和其它一些组件，内存控制器决定了RAM芯片的类型。不同的类型，包括DRAM、Rambus和SDRAM等等，要求不同的内存控制器。
为了连通其它系统设备，北桥需要与南桥通信。南桥又叫I/O桥，通过多条不同总线与设备们通信。目前，比较重要的总线有PCI、PCI Express、SATA和USB总线，除此以外，南桥还支持PATA、IEEE 1394、串行口和并行口等。比较老的系统上有连接北桥的AGP槽。那是由于南北桥间缺乏高速连接而采取的措施。现在的PCI-E都是直接连到南桥的。
这种结构有一些需要注意的地方:
•	从某个CPU到另一个CPU的数据需要走它与北桥通信的同一条总线。
•	与RAM的通信需要经过北桥
•	RAM只有一个端口。{本文不会介绍多端口RAM，因为商用硬件不采用这种内存，至少程序员无法访问到。这种内存一般在路由器等专用硬件中采用。}
•	CPU与南桥设备间的通信需要经过北桥
在上面这种设计中，瓶颈马上出现了。第一个瓶颈与设备对RAM的访问有关。早期，所有设备之间的通信都需要经过CPU，结果严重影响了整个系统的性 能。为了解决这个问题，有些设备加入了直接内存访问(DMA)的能力。DMA允许设备在北桥的帮助下，无需CPU的干涉，直接读写RAM。到了今天，所有 高性能的设备都可以使用DMA。虽然DMA大大降低了CPU的负担，却占用了北桥的带宽，与CPU形成了争用。
第二个瓶颈来自北桥与RAM间的总线。总线的具体情况与内存的类型有关。在早期的系统上，只有一条总线，因此不能实现并行访问。近期的RAM需要两 条独立总线(或者说通道，DDR2就是这么叫的，见图2.8)，可以实现带宽加倍。北桥将内存访问交错地分配到两个通道上。更新的内存技术(如FB- DRAM)甚至加入了更多的通道。
由于带宽有限，我们需要以一种使延迟最小化的方式来对内存访问进行调度。我们将会看到，处理器的速度比内存要快得多，需要等待内存。如果有多个超线程核心或CPU同时访问内存，等待时间则会更长。对于DMA也是同样。
除了并发以外，访问模式也会极大地影响内存子系统、特别是多通道内存子系统的性能。关于访问模式，可参见2.2节。
在一些比较昂贵的系统上，北桥自己不含内存控制器，而是连接到外部的多个内存控制器上(在下例中，共有4个)。

图2.2 拥有外部控制器的北桥
这种架构的好处在于，多条内存总线的存在，使得总带宽也随之增加了。而且也可以支持更多的内存。通过同时访问不同内存区，还可以降低延时。对于像图 2.2中这种多处理器直连北桥的设计来说，尤其有效。而这种架构的局限在于北桥的内部带宽，非常巨大(来自Intel)。{出于完整性的考虑，还需要补充 一下，这样的内存控制器布局还可以用于其它用途，比如说「内存RAID」，它可以与热插拔技术一起使用。}
使用外部内存控制器并不是唯一的办法，另一个最近比较流行的方法是将控制器集成到CPU内部，将内存直连到每个CPU。这种架构的走红归功于基于 AMD Opteron处理器的SMP系统。图2.3展示了这种架构。Intel则会从Nehalem处理器开始支持通用系统接口(CSI)，基本上也是类似的思 路——集成内存控制器，为每个处理器提供本地内存。

图2.3 集成的内存控制器
通过采用这样的架构，系统里有几个处理器，就可以有几个内存库(memory bank)。比如，在4 CPU的计算机上，不需要一个拥有巨大带宽的复杂北桥，就可以实现4倍的内存带宽。另外，将内存控制器集成到CPU内部还有其它一些优点，这里就不赘述了。
同样也有缺点。首先，系统仍然要让所有内存能被所有处理器所访问，导致内存不再是统一的资源(NUMA即得名于此)。处理器能以正常的速度访问本地 内存(连接到该处理器的内存)。但它访问其它处理器的内存时，却需要使用处理器之间的互联通道。比如说，CPU 1如果要访问CPU 2的内存，则需要使用它们之间的互联通道。如果它需要访问CPU 4的内存，那么需要跨越两条互联通道。
使用互联通道是有代价的。在讨论访问远端内存的代价时，我们用「NUMA因子」这个词。在图2.3中，每个CPU有两个层级: 相邻的CPU，以及两个互联通道外的CPU。在更加复杂的系统中，层级也更多。甚至有些机器有不止一种连接，比如说IBM的x445和SGI的Altix 系列。CPU被归入节点，节点内的内存访问时间是一致的，或者只有很小的NUMA因子。而在节点之间的连接代价很大，而且有巨大的NUMA因子。
目前，已经有商用的NUMA计算机，而且它们在未来应该会扮演更加重要的角色。人们预计，从2008年底开始，每台SMP机器都会使用NUMA。每 个在NUMA上运行的程序都应该认识到NUMA的代价。在第5节中，我们将讨论更多的架构，以及Linux内核为这些程序提供的一些技术。
除了本节中所介绍的技术之外，还有其它一些影响RAM性能的因素。它们无法被软件所左右，所以没有放在这里。如果大家有兴趣，可以在第2.1节中看一下。介绍这些技术，仅仅是因为它们能让我们绘制的RAM技术全图更为完整，或者是可能在大家购买计算机时能够提供一些帮助。
以下的两节主要介绍一些入门级的硬件知识，同时讨论内存控制器与DRAM芯片间的访问协议。这些知识解释了内存访问的原理，程序员可能会得到一些启发。不过，这部分并不是必读的，心急的读者可以直接跳到第2.2.5节。
2.1 RAM类型
这些年来，出现了许多不同类型的RAM，各有差异，有些甚至有非常巨大的不同。那些很古老的类型已经乏人问津，我们就不仔细研究了。我们主要专注于几类现代RAM，剖开它们的表面，研究一下内核和应用开发人员们可以看到的一些细节。
第一个有趣的细节是，为什么在同一台机器中有不同的RAM？或者说得更详细一点，为什么既有静态RAM(SRAM {SRAM还可以表示「同步内存」。})，又有动态RAM(DRAM)。功能相同，前者更快。那么，为什么不全部使用SRAM？答案是，代价。无论在生产 还是在使用上，SRAM都比DRAM要贵得多。生产和使用，这两个代价因子都很重要，后者则是越来越重要。为了理解这一点，我们分别看一下SRAM和 DRAM一个位的存储的实现过程。
在本节的余下部分，我们将讨论RAM实现的底层细节。我们将尽量控制细节的层面，比如，在「逻辑的层面」讨论信号，而不是硬件设计师那种层面，因为那毫无必要。
2.1.1 静态RAM

图2.6 6-T静态RAM
图2.4展示了6晶体管SRAM的一个单元。核心是4个晶体管M1-M4，它们组成两个交叉耦合的反相器。它们有两个稳定的状态，分别代表0和1。只要保持Vdd有电，状态就是稳定的。
当需要访问单元的状态时，升起字访问线WL。BL和BL上就可以读取状态。如果需要覆盖状态，先将BL和BL设置为期望的值，然后升起WL。由于外部的驱动强于内部的4个晶体管，所以旧状态会被覆盖。
更多详情，可以参考[sramwiki]。为了下文的讨论，需要注意以下问题:
一个单元需要6个晶体管。也有采用4个晶体管的SRAM，但有缺陷。
维持状态需要恒定的电源。
升起WL后立即可以读取状态。信号与其它晶体管控制的信号一样，是直角的(快速在两个状态间变化)。
状态稳定，不需要刷新循环。
SRAM也有其它形式，不那么费电，但比较慢。由于我们需要的是快速RAM，因此不在关注范围内。这些较慢的SRAM的主要优点在于接口简单，比动态RAM更容易使用。
2.1.2 动态RAM
动态RAM比静态RAM要简单得多。图2.5展示了一种普通DRAM的结构。它只含有一个晶体管和一个电容器。显然，这种复杂性上的巨大差异意味着功能上的迥异。

图2.5 1-T动态RAM
动态RAM的状态是保持在电容器C中。晶体管M用来控制访问。如果要读取状态，升起访问线AL，这时，可能会有电流流到数据线DL上，也可能没有，取决于电容器是否有电。如果要写入状态，先设置DL，然后升起AL一段时间，直到电容器充电或放电完毕。
动态RAM的设计有几个复杂的地方。由于读取状态时需要对电容器放电，所以这一过程不能无限重复，不得不在某个点上对它重新充电。
更糟糕的是，为了容纳大量单元(现在一般在单个芯片上容纳10的9次方以上的RAM单元)，电容器的容量必须很小(0.000000000000001法拉以下)。这样，完整充电后大约持有几万个电子。即使电容器的电阻很大(若干兆欧姆)，仍然只需很短的时间就会耗光电荷，称为「泄漏」。
这种泄露就是现在的大部分DRAM芯片每隔64ms就必须进行一次刷新的原因。在刷新期间，对于该芯片的访问是不可能的，这甚至会造成半数任务的延宕。（相关内容请察看【highperfdram】一章）
这个问题的另一个后果就是无法直接读取芯片单元中的信息，而必须通过信号放大器将0和1两种信号间的电势差增大。
最后一个问题在于电容器的冲放电是需要时间的，这就导致了信号放大器读取的信号并不是典型的矩形信号。所以当放大器输出信号的时候就需要一个小小的延宕，相关公式如下

这就意味着需要一些时间（时间长短取决于电容C和电阻R）来对电容进行冲放电。另一个负面作用是，信号放大器的输出电流不能立即就作为信号载体使用。图2.6显示了冲放电的曲线，x轴表示的是单位时间下的R*C

与静态RAM可以即刻读取数据不同的是，当要读取动态RAM的时候，必须花一点时间来等待电容的冲放电完全。这一点点的时间最终限制了DRAM的速度。
当然了，这种读取方式也是有好处的。最大的好处在于缩小了规模。一个动态RAM的尺寸是小于静态RAM的。这种规模的减小不单单建立在动态RAM的简单结构之上，也是由于减少了静态RAM的各个单元独立的供电部分。以上也同时导致了动态RAM模具的简单化。
综上所述，由于不可思议的成本差异，除了一些特殊的硬件（包括路由器什么的）之外，我们的硬件大多是使用DRAM的。这一点深深的影响了咱们这些程序员，后文将会对此进行讨论。在此之前，我们还是先了解下DRAM的更多细节。
2.1.3 DRAM 访问
一个程序选择了一个内存位置使用到了一个虚拟地址。处理器转换这个到物理地址最后将内存控制选择RAM芯片匹配了那个地址。在RAM芯片去选择单个内存单元，部分的物理地址以许多地址行的形式被传递。
它单独地去处理来自于内存控制器的内存位置将完全不切实际：4G的RAM将需要 232 地址行。地址传递DRAM芯片的这种方式首先必须被路由器解析。一个路由器的N多地址行将有2N 输出行。这些输出行能被使用到选择内存单元。使用这个直接方法对于小容量芯片不再是个大问题
但如果许多的单元生成这种方法不在适合。一个1G的芯片容量（我反感那些SI前缀，对于我一个giga-bit将总是230 而不是109字节）将需要30地址行和230 选 项行。一个路由器的大小及许多的输入行以指数方式递增当速度不被牺牲时。一个30地址行路由器需要一大堆芯片的真实身份另外路由器也就复杂起来了。更重要 的是，传递30脉冲在地址行同步要比仅仅传递15脉冲困难的多。较少列能精确布局相同长度或恰当的时机（现代DRAM类型像DDR3能自动调整时序但这个 限制能让他什么都能忍受）

图2.7展示了一个很高级别的一个DRAM芯片，DRAM被组织在行和列里。他们能在一行中对奇但DRAM芯片需要一个大的路由器。通过阵列方法设 计能被一个路由器和一个半的multiplexer获得{多路复用器（multiplexer）和路由器是一样的，这的multiplexer需要以路由 器身份工作当写数据时候。那么从现在开始我们开始讨论其区别.}这在所有方面会是一个大的存储。例如地址linesa0和a1通过行地址选择路由器来选择整个行的芯片的地址列，当读的时候，所有的芯片目录能使其纵列选择路由器可用，依据地址linesa2和a3一个纵列的目录用于数据DRAM芯片的接口类型。这发生了许多次在许多DRAM芯片产生一个总记录数的字节匹配给一个宽范围的数据总线。
对于写操作，内存单元的数据新值被放到了数据总线，当使用RAS和CAS方式选中内存单元时，数据是存放在内存单元内的。这是一个相当直观的设计， 在现实中——很显然——会复杂得多，对于读，需要规范从发出信号到数据在数据总线上变得可读的时延。电容不会像前面章节里面描述的那样立刻自动放电，从内 存单元发出的信号是如此这微弱以至于它需要被放大。对于写，必须规范从数据RAS和CAS操作完成后到数据成功的被写入内存单元的时延（当然，电容不会立 刻自动充电和放电）。这些时间常量对于DRAM芯片的性能是至关重要的，我们将在下章讨论它。
另一个关于伸缩性的问题是，用30根地址线连接到每一个RAM芯片是行不通的。芯片的针脚是非常珍贵的资源，以至数据必 须能并行传输就并行传输（比如：64位为一组）。内存控制器必须有能力解析每一个RAM模块（RAM芯片集合）。如果因为性能的原因要求并发行访问多个 RAM模块并且每个RAM模块需要自己独占的30或多个地址线，那么对于8个RAM模块，仅仅是解析地址，内存控制器就需要240+之多的针脚。
在很长一段时间里，地址线被复用以解决DRAM芯片的这些次要的可扩展性问题。这意味着地址被转换成两部分。第一部分由地址位a0和a1选择行（如 图2.7）。这个选择保持有效直到撤销。然后是第二部分，地址位a2和a3选择列。关键差别在于：只需要两根外部地址线。需要一些很少的线指明RAS和 CAS信号有效，但是把地址线的数目减半所付出的代价更小。可是地址复用也带来自身的一些问题。我们将在2.2章中提到。
2.1.4 总结
如果这章节的内容有些难以应付，不用担心。纵观这章节的重点，有：
•	为什么不是所有的存储器都是SRAM的原因
•	存储单元需要单独选择来使用
•	地址线数目直接负责存储控制器，主板，DRAM模块和DRAM芯片的成本
•	在读或写操作结果之前需要占用一段时间是可行的
接下来的章节会涉及更多的有关访问DRAM存储器的实际操作的细节。我们不会提到更多有关访问SRAM的具体内容，它通常是直接寻址。这里是由于速 度和有限的SRAM存储器的尺寸。SRAM现在应用在CPU的高速缓存和芯片，它们的连接件很小而且完全能在CPU设计师的掌控之下。我们以后会讨论到 CPU高速缓存这个主题，但我们所需要知道的是SRAM存储单元是有确定的最大速度，这取决于花在SRAM上的艰难的尝试。这速度与CPU核心相比略慢一 到两个数量级。
2.2 DRAM访问细节
在上文介绍DRAM的时候，我们已经看到DRAM芯片为了节约资源，对地址进行了复用。而且，访问DRAM单元是需要一些时间的，因为电容器的放电 并不是瞬时的。此外，我们还看到，DRAM需要不停地刷新。在这一节里，我们将把这些因素拼合起来，看看它们是如何决定DRAM的访问过程。
我们将主要关注在当前的科技上，不会再去讨论异步DRAM以及它的各种变体。如果对它感兴趣，可以去参考[highperfdram]及 [arstechtwo]。我们也不会讨论Rambus DRAM(RDRAM)，虽然它并不过时，但在系统内存领域应用不广。我们将主要介绍同步DRAM(SDRAM)及其后继者双倍速DRAM(DDR)。
同步DRAM，顾名思义，是参照一个时间源工作的。由内存控制器提供一个时钟，时钟的频率决定了前端总线(FSB)的速度。FSB是内存控制器提供 给DRAM芯片的接口。在我写作本文的时候，FSB已经达到800MHz、1066MHz，甚至1333MHz，并且下一代的1600MHz也已经宣布。 但这并不表示时钟频率有这么高。实际上，目前的总线都是双倍或四倍传输的，每个周期传输2次或4次数据。报的越高，卖的越好，所以这些厂商们喜欢把四倍传 输的200MHz总线宣传为“有效的”800MHz总线。
以今天的SDRAM为例，每次数据传输包含64位，即8字节。所以FSB的传输速率应该是有效总线频率乘于8字节(对于4倍传输200MHz总线而 言，传输速率为6.4GB/s)。听起来很高，但要知道这只是峰值速率，实际上无法达到的最高速率。我们将会看到，与RAM模块交流的协议有大量时间是处 于非工作状态，不进行数据传输。我们必须对这些非工作时间有所了解，并尽量缩短它们，才能获得最佳的性能。
2.2.1 读访问协议

图2.8: SDRAM读访问的时序
图2.8展示了某个DRAM模块一些连接器上的活动，可分为三个阶段，图上以不同颜色表示。按惯例，时间为从左向右流逝。这里忽略了许多细节，我们 只关注时钟频率、RAS与CAS信号、地址总线和数据总线。首先，内存控制器将行地址放在地址总线上，并降低RAS信号，读周期开始。所有信号都在时钟 (CLK)的上升沿读取，因此，只要信号在读取的时间点上保持稳定，就算不是标准的方波也没有关系。设置行地址会促使RAM芯片锁住指定的行。
CAS信号在tRCD(RAS到CAS时延)个时钟周期后发出。内存控制器将列地址放在地址总线上，降低CAS线。这里我们可以看到，地址的两个组成部分是怎么通过同一条总线传输的。
至此，寻址结束，是时候传输数据了。但RAM芯片任然需要一些准备时间，这个时间称为CAS时延(CL)。在图2.8中CL为2。这个值可大可小， 它取决于内存控制器、主板和DRAM模块的质量。CL还可能是半周期。假设CL为2.5，那么数据将在蓝色区域内的第一个下降沿准备就绪。
既然数据的传输需要这么多的准备工作，仅仅传输一个字显然是太浪费了。因此，DRAM模块允许内存控制指定本次传输多少数据。可以是2、4或8个 字。这样，就可以一次填满高速缓存的整条线，而不需要额外的RAS/CAS序列。另外，内存控制器还可以在不重置行选择的前提下发送新的CAS信号。这 样，读取或写入连续的地址就可以变得非常快，因为不需要发送RAS信号，也不需要把行置为非激活状态(见下文)。是否要将行保持为“打开”状态是内存控制 器判断的事情。让它一直保持打开的话，对真正的应用会有不好的影响(参见[highperfdram])。CAS信号的发送仅与RAM模块的命令速率 (Command Rate)有关(常常记为Tx，其中x为1或2，高性能的DRAM模块一般为1，表示在每个周期都可以接收新命令)。
在上图中，SDRAM的每个周期输出一个字的数据。这是第一代的SDRAM。而DDR可以在一个周期中输出两个字。这种做法可以减少传输时间，但无 法降低时延。DDR2尽管看上去不同，但在本质上也是相同的做法。对于DDR2，不需要再深入介绍了，我们只需要知道DDR2更快、更便宜、更可靠、更节 能(参见[ddrtwo])就足够了。
2.2.2 预充电与激活
图2.8并不完整，它只画出了访问DRAM的完整循环的一部分。在发送RAS信号之前，必须先把当前锁住的行置为非激活状态，并对新行进行预充电。 在这里，我们主要讨论由于显式发送指令而触发以上行为的情况。协议本身作了一些改进，在某些情况下是可以省略这个步骤的，但预充电带来的时延还是会影响整 个操作。

图2.9: SDRAM的预充电与激活
图2.9显示的是两次CAS信号的时序图。第一次的数据在CL周期后准备就绪。图中的例子里，是在SDRAM上，用两个周期传输了两个字的数据。如果换成DDR的话，则可以传输4个字。
即使是在一个命令速率为1的DRAM模块上，也无法立即发出预充电命令，而要等数据传输完成。在上图中，即为两个周期。刚好与CL相同，但只是巧合 而已。预充电信号并没有专用线，某些实现是用同时降低写使能(WE)线和RAS线的方式来触发。这一组合方式本身没有特殊的意义(参见 [micronddr])。
发出预充电信命令后，还需等待tRP(行预充电时间)个周期之后才能使行被选中。在图2.9中，这个时间(紫色部分)大部分与内存传输的时间(淡蓝色部分)重合。不错。但tRP大于传输时间，因此下一个RAS信号只能等待一个周期。
如果我们补充完整上图中的时间线，最后会发现下一次数据传输发生在前一次的5个周期之后。这意味着，数据总线的7个周期中只有2个周期才是真正在用 的。再用它乘于FSB速度，结果就是，800MHz总线的理论速率6.4GB/s降到了1.8GB/s。真是太糟了。第6节将介绍一些技术，可以帮助我们 提高总线有效速率。程序员们也需要尽自己的努力。
SDRAM还有一些定时值，我们并没有谈到。在图2.9中，预充电命令仅受制于数据传输时间。除此之外，SDRAM模块在RAS信号之后，需要经过一段时间，才能进行预充电(记为tRAS)。它的值很大，一般达到tRP的2到3倍。如果在某个RAS信号之后，只有一个CAS信号，而且数据只传输很少几个周期，那么就有问题了。假设在图2.9中，第一个CAS信号是直接跟在一个RAS信号后免的，而tRAS为8个周期。那么预充电命令还需要被推迟一个周期，因为tRCD、CL和tRP加起来才7个周期。
DDR模块往往用w-z-y-z-T来表示。例如，2-3-2-8-T1，意思是：
w 2 CAS时延(CL)
x 3 RAS-to-CAS时延(t RCD)
y 2 RAS预充电时间(t RP)
z 8 激活到预充电时间(t RAS)
T T1 命令速率
当然，除以上的参数外，还有许多其它参数影响命令的发送与处理。但以上5个参数已经足以确定模块的性能。
在解读计算机性能参数时，这些信息可能会派上用场。而在购买计算机时，这些信息就更有用了，因为它们与FSB/SDRAM速度一起，都是决定计算机速度的关键因素。
喜欢冒险的读者们还可以利用它们来调优系统。有些计算机的BIOS可以让你修改这些参数。SDRAM模块有一些可编程寄存器，可供设置参数。 BIOS一般会挑选最佳值。如果RAM模块的质量足够好，我们可以在保持系统稳定的前提下将减小以上某个时延参数。互联网上有大量超频网站提供了相关的文 档。不过，这是有风险的，需要大家自己承担，可别怪我没有事先提醒哟。
2.2.3 重充电
谈到DRAM的访问时，重充电是常常被忽略的一个主题。在2.1.2中曾经介绍，DRAM必须保持刷新。……行在充电时是无法访问的。[highperfdram]的研究发现，“令人吃惊，DRAM刷新对性能有着巨大的影响”。
根据JEDEC规范，DRAM单元必须保持每64ms刷新一次。对于8192行的DRAM，这意味着内存控制器平均每7.8125µs就需要发出一 个刷新命令(在实际情况下，由于刷新命令可以纳入队列，因此这个时间间隔可以更大一些)。刷新命令的调度由内存控制器负责。DRAM模块会记录上一次刷新 行的地址，然后在下次刷新请求时自动对这个地址进行递增。
对于刷新及发出刷新命令的时间点，程序员无法施加影响。但我们在解读性能参数时有必要知道，它也是DRAM生命周期的一个部分。如果系统需要读取某个重要的字，而刚好它所在的行正在刷新，那么处理器将会被延迟很长一段时间。刷新的具体耗时取决于DRAM模块本身。
2.2.4 内存类型
我们有必要花一些时间来了解一下目前流行的内存，以及那些即将流行的内存。首先从SDR(单倍速)SDRAM开始，因为它们是DDR(双倍速)SDRAM的基础。SDR非常简单，内存单元和数据传输率是相等的。

图2.10: SDR SDRAM的操作
在图2.10中，DRAM单元阵列能以等同于内存总线的速率输出内容。假设DRAM单元阵列工作在100MHz上，那么总线的数据传输率可以达到100Mb/s。所有组件的频率f保持相同。由于提高频率会导致耗电量增加，所以提高吞吐量需要付出很高的的代价。如果是很大规模的内存阵列，代价会非常巨大。{功率 = 动态电容 x 电压2 x 频率}。而且，提高频率还需要在保持系统稳定的情况下提高电压，这更是一个问题。因此，就有了DDR SDRAM(现在叫DDR1)，它可以在不提高频率的前提下提高吞吐量。

图2.11 DDR1 SDRAM的操作
我们从图2.11上可以看出DDR1与SDR的不同之处，也可以从DDR1的名字里猜到那么几分，DDR1的每个周期可以传输两倍的数据，它的上升 沿和下降沿都传输数据。有时又被称为“双泵(double-pumped)”总线。为了在不提升频率的前提下实现双倍传输，DDR引入了一个缓冲区。缓冲 区的每条数据线都持有两位。它要求内存单元阵列的数据总线包含两条线。实现的方式很简单，用同一个列地址同时访问两个DRAM单元。对单元阵列的修改也很 小。
SDR DRAM是以频率来命名的(例如，对应于100MHz的称为PC100)。为了让DDR1听上去更好听，营销人员们不得不想了一种新的命名方案。这种新方案中含有DDR模块可支持的传输速率(DDR拥有64位总线):
100MHz x 64位 x 2 = 1600MB/s
于是，100MHz频率的DDR模块就被称为PC1600。由于1600 > 100，营销方面的需求得到了满足，听起来非常棒，但实际上仅仅只是提升了两倍而已。{我接受两倍这个事实，但不喜欢类似的数字膨胀戏法。}

图2.12: DDR2 SDRAM的操作
为了更进一步，DDR2有了更多的创新。在图2.12中，最明显的变化是，总线的频率加倍了。频率的加倍意味着带宽的加倍。如果对单元阵列的频率加 倍，显然是不经济的，因此DDR2要求I/O缓冲区在每个时钟周期读取4位。也就是说，DDR2的变化仅在于使I/O缓冲区运行在更高的速度上。这是可行 的，而且耗电也不会显著增加。DDR2的命名与DDR1相仿，只是将因子2替换成4(四泵总线)。图2.13显示了目前常用的一些模块的名称。
阵列频率	总线频率	数据率	名称(速率)	名称
(FSB)
133MHz	266MHz	4,256MB/s	PC2-4200	DDR2-533
166MHz	333MHz	5,312MB/s	PC2-5300	DDR2-667
200MHz	400MHz	6,400MB/s	PC2-6400	DDR2-800
250MHz	500MHz	8,000MB/s	PC2-8000	DDR2-1000
266MHz	533MHz	8,512MB/s	PC2-8500	DDR2-1066

图2.13: DDR2模块名

在命名方面还有一个拧巴的地方。FSB速度是用有效频率来标记的，即把上升、下降沿均传输数据的因素考虑进去，因此数字被撑大了。所以，拥有266MHz总线的133MHz模块有着533MHz的FSB“频率”。
DDR3要求更多的改变(这里指真正的DDR3，而不是图形卡中假冒的GDDR3)。电压从1.8V下降到1.5V。由于耗电是与电压的平方成正 比，因此可以节约30%的电力。加上管芯(die)的缩小和电气方面的其它进展，DDR3可以在保持相同频率的情况下，降低一半的电力消耗。或者，在保持 相同耗电的情况下，达到更高的频率。又或者，在保持相同热量排放的情况下，实现容量的翻番。
DDR3模块的单元阵列将运行在内部总线的四分之一速度上，DDR3的I/O缓冲区从DDR2的4位提升到8位。见图2.14。

图2.14: DDR3 SDRAM的操作
一开始，DDR3可能会有较高的CAS时延，因为DDR2的技术相比之下更为成熟。由于这个原因，DDR3可能只会用于DDR2无法达到的高频率 下，而且带宽比时延更重要的场景。此前，已经有讨论指出，1.3V的DDR3可以达到与DDR2相同的CAS时延。无论如何，更高速度带来的价值都会超过 时延增加带来的影响。
DDR3可能会有一个问题，即在1600Mb/s或更高速率下，每个通道的模块数可能会限制为1。在早期版本中，这一要求是针对所有频率的。我们希望这个要求可以提高一些，否则系统容量将会受到严重的限制。
图2.15显示了我们预计中各DDR3模块的名称。JEDEC目前同意了前四种。由于Intel的45nm处理器是1600Mb/s的FSB，1866Mb/s可以用于超频市场。随着DDR3的发展，可能会有更多类型加入。
阵列频率	总线频率	数据速率	名称(速率)	名称
(FSB)
100MHz	400MHz	6,400MB/s	PC3-6400	DDR3-800
133MHz	533MHz	8,512MB/s	PC3-8500	DDR3-1066
166MHz	667MHz	10,667MB/s	PC3-10667	DDR3-1333
200MHz	800MHz	12,800MB/s	PC3-12800	DDR3-1600
233MHz	933MHz	14,933MB/s	PC3-14900	DDR3-1866


图2.15: DDR3模块名
所有的DDR内存都有一个问题：不断增加的频率使得建立并行数据总线变得十分困难。一个DDR2模块有240根引脚。所有到地址和数据引脚的连线必 须被布置得差不多一样长。更大的问题是，如果多于一个DDR模块通过菊花链连接在同一个总线上，每个模块所接收到的信号随着模块的增加会变得越来越扭曲。 DDR2规范允许每条总线（又称通道）连接最多两个模块，DDR3在高频率下只允许每个通道连接一个模块。每条总线多达240根引脚使得单个北桥无法以合 理的方式驱动两个通道。替代方案是增加外部内存控制器（如图2.2），但这会提高成本。
这意味着商品主板所搭载的DDR2或DDR3模块数将被限制在最多四条，这严重限制了系统的最大内存容量。即使是老旧的32位IA-32处理器也可以使用64GB内存。即使是家庭对内存的需求也在不断增长，所以，某些事必须开始做了。
一种解法是，在处理器中加入内存控制器，我们在第2节中曾经介绍过。AMD的Opteron系列和Intel的CSI技术就是采用这种方法。只要我 们能把处理器要求的内存连接到处理器上，这种解法就是有效的。如果不能，按照这种思路就会引入NUMA架构，当然同时也会引入它的缺点。而在有些情况下， 我们需要其它解法。
Intel针对大型服务器方面的解法(至少在未来几年)，是被称为全缓冲DRAM(FB-DRAM)的技术。FB-DRAM采用与DDR2相同的器 件，因此造价低廉。不同之处在于它们与内存控制器的连接方式。FB-DRAM没有用并行总线，而用了串行总线(Rambus DRAM had this back when, too, 而SATA是PATA的继任者，就像PCI Express是PCI/AGP的继承人一样)。串行总线可以达到更高的频率，串行化的负面影响，甚至可以增加带宽。使用串行总线后
1	每个通道可以使用更多的模块。
2	每个北桥/内存控制器可以使用更多的通道。
串行总线是全双工的(两条线)。
FB-DRAM只有69个脚。通过菊花链方式连接多个FB-DRAM也很简单。FB-DRAM规范允许每个通道连接最多8个模块。
在对比下双通道北桥的连接性，采用FB-DRAM后，北桥可以驱动6个通道，而且脚数更少——6x69对比2x240。每个通道的布线也更为简单，有助于降低主板的成本。
全双工的并行总线过于昂贵。而换成串行线后，这不再是一个问题，因此串行总线按全双工来设计的，这也意味着，在某些情况下，仅靠这一特性， 总线的理论带宽已经翻了一倍。还不止于此。由于FB-DRAM控制器可同时连接6个通道，因此可以利用它来增加某些小内存系统的带宽。对于一个双通道、4 模块的DDR2系统，我们可以用一个普通FB-DRAM控制器，用4通道来实现相同的容量。串行总线的实际带宽取决于在FB-DRAM模块中所使用的 DDR2(或DDR3)芯片的类型。
我们可以像这样总结这些优势：
3	DDR2 FB-DRAM

 	DDR2	FB-DRAM
脚	240	69
通道	2	6
每通道DIMM数	2	8
最大内存	16GB	192GB
吞吐量	~10GB/s	~40GB/s
如果在单个通道上使用多个DIMM，会有一些问题。信号在每个DIMM上都会有延迟(尽管很小)，也就是说，延迟是递增的。不过，如果在相同频率和相同容 量上进行比较，FB-DRAM总是能快过DDR2及DDR3，因为FB-DRAM只需要在每个通道上使用一个DIMM即可。而如果说到大型内存系统，那么 DDR更是没有商用组件的解决方案。
2.2.5 结论
通过本节，大家应该了解到访问DRAM的过程并不是一个快速的过程。至少与处理器的速度相比，或与处理器访问寄存器及缓存的速度相 比，DRAM的访问不算快。大家还需要记住CPU和内存的频率是不同的。Intel Core 2处理器运行在2.933GHz，而1.066GHz FSB有11:1的时钟比率(注: 1.066GHz的总线为四泵总线)。那么，内存总线上延迟一个周期意味着处理器延迟11个周期。绝大多数机器使用的DRAM更慢，因此延迟更大。在后续 的章节中，我们需要讨论延迟这个问题时，请把以上的数字记在心里。
前文中读命令的时序图表明，DRAM模块可以支持高速数据传输。每个完整行可以被毫无延迟地传输。数据总线可以100%被占。对DDR而言，意味着每个周期传输2个64位字。对于DDR2-800模块和双通道而言，意味着12.8GB/s的速率。
但是，除非是特殊设计，DRAM的访问并不总是串行的。访问不连续的内存区意味着需要预充电和RAS信号。于是，各种速度开始慢下来，DRAM模块急需帮助。预充电的时间越短，数据传输所受的惩罚越小。
硬件和软件的预取(参见第6.3节)可以在时序中制造更多的重叠区，降低延迟。预取还可以转移内存操作的时间，从而减少争用。我们常常遇到的问题是，在这一轮中生成的数据需要被存储，而下一轮的数据需要被读出来。通过转移读取的时间，读和写就不需要同时发出了。
2.3 主存的其它用户
除了CPU外，系统中还有其它一些组件也可以访问主存。高性能网卡或大规模存储控制器是无法承受通过CPU来传输数据的，它们一般直接对内 存进行读写(直接内存访问，DMA)。在图2.1中可以看到，它们可以通过南桥和北桥直接访问内存。另外，其它总线，比如USB等也需要FSB带宽，即使 它们并不使用DMA，但南桥仍要通过FSB连接到北桥。
DMA当然有很大的优点，但也意味着FSB带宽会有更多的竞争。在有大量DMA流量的情况下，CPU在访问内存时必然会有更大的延迟。我们 可以用一些硬件来解决这个问题。例如，通过图2.3中的架构，我们可以挑选不受DMA影响的节点，让它们的内存为我们的计算服务。还可以在每个节点上连接 一个南桥，将FSB的负荷均匀地分担到每个节点上。除此以外，还有许多其它方法。我们将在第6节中介绍一些技术和编程接口，它们能够帮助我们通过软件的方 式改善这个问题。

最后，还需要提一下某些廉价系统，它们的图形系统没有专用的显存，而是采用主存的一部分作为显存。由于对显存的访问非常频繁(例如，对于 1024x768、16bpp、60Hz的显示设置来说，需要95MB/s的数据速率)，而主存并不像显卡上的显存，并没有两个端口，因此这种配置会对系 统性能、尤其是时延造成一定的影响。如果大家对系统性能要求比较高，最好不要采用这种配置。这种系统带来的问题超过了本身的价值。人们在购买它们时已经做 好了性能不佳的心理准备。

'', '''', 5, ''请选择'', 2, ''YC'', ''2019-06-18'', ''2019-06-18'', null, ''1 简介
早期计算机比现在更为简单。系统的各种组件例如CPU，内存，大容量存储器和网口，由于被共同开发因而有非常均衡的表现。例如，内存和网口并不比CPU在提供数据的时候更（特别的）快。
曾今计算机稳定的基本结构悄然改变，硬件开发人员开始致力于优化单个子系统。于是电脑一些组件的性能大大的落后因而成为了瓶颈。由于开销的原因，大容量存储器和内存子系统相对于其他组件来说改善得更为缓慢。'', null, null, 0, 0, null);
INSERT INTO artical (ID, AUTHOR, ORIGINAUTHOR, ORIGINURL, TITTLE, IMGPATH, CONTENT, TAGS, NAVID, TOPICID, CATEGORIES, TYPE, CREATEDATE, UPDATEDATE, ARTICALURL, SUMMARY, LASTARTICALID, NEXTARTICALID, LIKENUMS, DISSNUMS, INTOP) VALUES (24, ''老干部'', '''', '''', ''数据结构笔记'', ''images/5.jpg'', ''windows8安装密钥：2N8G7-9GF9V-P9XB2-9QKKK-FRDG7
数据结构总结
数据结构概述

 定义：如何把现实生活中大量而复杂的问题以特定的数据类型和
       特定的存储结构保存到主存储器（内存）中，以及在此基
       础上实现某个功能而执行的相应操作，这个相应的操作也
       叫做算法。

       数据结构=个体+个体的关系

       算法=对存储数据的操作

 算法：解题的方法和步骤

  衡量算法的标准
	1.时间复杂度：大概程序要执行的次数，而非执行的时间。
	2.空间复杂度：算法执行过程中大概占用的最大内存
	3.难易程度
	4.健壮性

  数据结构的地位
	数据结构是软件中最核心的课程。
	程序=数据的存储+数据的操作+可被执行的计算机语言

预备知识

    指针
	指针的重要性：指针是C语言的灵魂
	定义：
内存单元的编号 从0开始的非负数
32位的系统有32根总线，最大的可控制内存为4G；
	指针就是地址，地址就是指针
	指针变量是存放内存单元地址的变量
	指针的本质是一个操作受限制的非负整数


    结构体
	为什么会出现结构体：为了表示一些复杂的数据，而普通的基本无法满足要求

	什么叫做结构体：用户根据自己的需要而定义的一个复合数据类型

	如何使用结构体
	 两种方式：
		struct Student st = {100，"张三"，20};
		struct Student *pst = &st ;
		1. st.sid
		2. pst->sid	pst所指向的结构体变量中的sid这个成员
typedef用法：
typedef struct Student{
int idl
char name[20];
int age ;
}ST;

	注意事项
	 结构体变量不能加减乘除，但是可以相互赋值
	 普通结构体变量和结构体指针变量作为函数的传参的问题

    动态内存的分配和释放
	malloc分配的空间需要手动释放（free）

 模块一：线性结构：把所有的结点用一根直线串起来

	 连续存储[数组]
	   1.什么叫做数组：元素类型相同，大小相等
	   2.数组的优缺点：
	 离散存储[链表]
		定义：n个节点离散分配，彼此通过指针相连，每个节点只有一个前驱节点，每个节点只有一个后继节点，首节点没有前驱节点，尾节点没有后继节点
		专业术语：
			 首节点：存放第一个有效数据的节点，

			 尾节点：存放最后一个有效数据的节点，

			 头结点：头结点的数据类型和首节点类型一样。首节点前面的节点，里面没有存放有效数据，也没有存放有效数据的个数，头结点是为了便于操作链表。

			 头指针：指向头结点的指针变量

			 尾指针：指向尾节点的指针变量

		确定一个链表需要几个参数：只需要一个参数，就是头指针，因为通过头指针可以推算出链表的其他参数。
		分类：
			单链表
 			双链表：每一个节点有两个指针域
			循环链表 ：能通过任何一个节点找到其他所有的结点
			非循环链表
		算法：
			遍历
			查找
			清空
			销毁
			求长度
			排序
			删除节点
			插入节点
		优点：
		缺点：
线性结构的两种常见应用之一 栈
定义：一种可以实现数据“先进后出”的数据存储方式
类似于一个箱子，先放入箱子中的东西后取出来，后放进去的东西先取出来。
分类：
静态栈
动态栈
算法：
出栈
压栈（入栈）
应用：
函数调用
中断
表达式求值
线性结构的两种常见结构之二 队列
定义：一种可以实现先进先出的存储方式；
分类：
链式队列------用链表实现的
静态队列------用数组实现的
静态队列通常都必须是循环队列
循环队列：
1.静态队列为什么都是循环队列

2.循环队列需要几个参数来确定
需要2个参数来确定
Front——队头
Rear——队尾

3.循环队列的各个参数的含义

1〉队列初始化
Front 和rear的值都为零
2〉队列非空
Front代表队列的第一个元素
Rear代表最后一个有效元素的下一个元素
3〉队列空
Rear和front指向相同元素
4.循环队列的入队伪算法讲解

5.循环队列的出队伪算法讲解
两部完成：
1.将值存入r所代表的位置
2.R=（r+1）%数组的长度
6.如何判断一个循环队列已满
Front = （front+1）%数组长度
	 专题：递归
定义:一个函数自己直接或间接调用自己
递归要满足的几个条件:
1.必须有一个明确的终止条件
2.该函数所处理的函数的规模必须是在递减
3.这个转化必须是可解的
		1.1+2+3+...100的和
		2.求阶乘
		3.汉诺塔
		4.走迷宫

 模块二：非线性结构：
	树

	图

 模块三：查找和排序
	折半查找
	排序：
	 冒泡
	 插入
	 选择
	 快速排序
	 归并排序

Java中容器和数据结构相关知识
 Iterator接口
 Map
	哈希表
书签：20
'', '''', 5, ''请选择'', 2, ''YC'', ''2019-06-18'', ''2019-06-18'', null, ''windows8安装密钥：2N8G7-9GF9V-P9XB2-9QKKK-FRDG7
数据结构总结
数据结构概述
 定义：如何把现实生活中大量而复杂的问题以特定的数据类型和
       特定的存储结构保存到主存储器（内存）中，以及在此基
       础上实现某个功能而执行的相应操作，这个相应的操作也
       叫做算法。
'', null, null, 0, 0, null);
INSERT INTO artical (ID, AUTHOR, ORIGINAUTHOR, ORIGINURL, TITTLE, IMGPATH, CONTENT, TAGS, NAVID, TOPICID, CATEGORIES, TYPE, CREATEDATE, UPDATEDATE, ARTICALURL, SUMMARY, LASTARTICALID, NEXTARTICALID, LIKENUMS, DISSNUMS, INTOP) VALUES (25, ''老干部'', '''', '''', ''Linux下安装Oracle 11g详细过程'', ''images/2.jpg'', '''', '''', 3, ''1'', 8, ''YC'', ''2019-06-18'', ''2019-06-18'', null, ''Linux环境配置
1.	OS:OpenSuse12.2(事实证明适合CentOS,Redat，fedora等linux操作系统，ubuntu不适用)
2.	DB:Oracle 11gR2
3.	将Oracle安装到home/oracle_11目录
配置过程：本文来自Oracle官方文档+网上资料+自己总结
Oracle官方文档：http://www.oracle.com/pls/db112/homepage
1. 以root用户登录到OpenSUSE
2. 检查机器硬件要求
'', null, null, 0, 0, null);
INSERT INTO artical (ID, AUTHOR, ORIGINAUTHOR, ORIGINURL, TITTLE, IMGPATH, CONTENT, TAGS, NAVID, TOPICID, CATEGORIES, TYPE, CREATEDATE, UPDATEDATE, ARTICALURL, SUMMARY, LASTARTICALID, NEXTARTICALID, LIKENUMS, DISSNUMS, INTOP) VALUES (26, ''老干部'', '''', '''', ''NFS server和client安装在RHEL/CENTOS7'', ''images/1.jpg'', ''NFS server和client安装在RHEL/CENTOS7
Server RHEL7：server1.example.com and IP as 192.168.0.100
Client RHEL7：client1.example.com and IP as  192.168.0.101
Server：
安装：
yum install nfs-utils
配置：
mkdir /var/nfsshare
chmod -R 777 /var/nfsshare/
	*：这里使用/var/nfsshare作为共享目录，如果使用其他比如/home作为共享目录，请不要更改权限，会造成权限问题和破坏系统层次结构。
启动服务并加到启动目录：
systemctl enable rpcbind
systemctl enable nfs-server
systemctl enable nfs-lock
systemctl enable nfs-idmap
systemctl start rpcbind
systemctl start nfs-server
systemctl start nfs-lock
systemctl start nfs-idmap
修改配置文件共享/var/nfsshare和/home：
Vi /etc/exports
写入：
/var/nfsshare    192.168.0.101(rw,sync,no_root_squash,no_all_squash)
/home            192.168.0.101(rw,sync,no_root_squash,no_all_squash)
如果任何人都能访问，将192.168.0.101改成“*”。
重启nfs服务：
systemctl restart nfs-server
防火墙：
firewall-cmd --permanent --zone=public --add-service=nfs
firewall-cmd –reload


Client：
安装：
yum install nfs-utils
创建挂载目录：
mkdir -p /mnt/nfs/home
mkdir -p /mnt/nfs/var/nfsshare
启动服务：systemctl enable rpcbind
systemctl enable nfs-server
systemctl enable nfs-lock
systemctl start rpcbind
systemctl start nfs-lock
最后挂载：
mount -t nfs 192.168.0.100:/home /mnt/nfs/home/
mount -t nfs 192.168.0.100:/var/nfsshare /mnt/nfs/var/nfsshare/
无错：
df –kh
[root@client1 ~]# df -kh
Filesystem                    Size  Used Avail Use% Mounted on
/dev/mapper/centos-root        39G  1.1G   38G   3% /
devtmpfs                      488M     0  488M   0% /dev
tmpfs                         494M     0  494M   0% /dev/shm
tmpfs                         494M  6.7M  487M   2% /run
tmpfs                         494M     0  494M   0% /sys/fs/cgroup
/dev/mapper/centos-home        19G   33M   19G   1% /home
/dev/sda1                     497M  126M  372M  26% /boot
192.168.0.100:/var/nfsshare   39G  980M   38G   3% /mnt/nfs/var/nfsshare
192.168.0.100:/home           19G   33M   19G   1% /mnt/nfs/home
[root@client1 ~]#
测试一下：
touch /mnt/nfs/var/nfsshare/test_nfs
OK！！！！！！！！
PS：
开机挂载:
Vi /etc/fstab
Add:
192.168.0.100:/home    /mnt/nfs/home   nfs defaults 0 0
192.168.0.100:/var/nfsshare    /mnt/nfs/var/nfsshare   nfs defaults 0 0

'', '''', 3, ''请选择'', 8, ''YC'', ''2019-06-18'', ''2019-06-18'', null, ''Server RHEL7：server1.example.com and IP as 192.168.0.100
Client RHEL7：client1.example.com and IP as  192.168.0.101
Server：
安装：
yum install nfs-utils
配置：
mkdir /var/nfsshare
chmod -R 777 /var/nfsshare/
	*：这里使用/var/nfsshare作为共享目录，如果使用其他比如/home作为共享目录，请不要更改权限，会造成权限问题和破坏系统层次结构。
'', null, null, 0, 0, null);
INSERT INTO artical (ID, AUTHOR, ORIGINAUTHOR, ORIGINURL, TITTLE, IMGPATH, CONTENT, TAGS, NAVID, TOPICID, CATEGORIES, TYPE, CREATEDATE, UPDATEDATE, ARTICALURL, SUMMARY, LASTARTICALID, NEXTARTICALID, LIKENUMS, DISSNUMS, INTOP) VALUES (27, ''老干部'', '''', '''', ''Nginx 的 TCP 负载均衡介绍'', ''images/6.jpg'', ''Nginx 的 TCP 负载均衡介绍
安装：解压
./configure --with-stream
Make
Make install
模块内容：
stream {
    # 添加socket转发的代理
    upstream bss_num_socket {
        hash $remote_addr consistent;
        # 转发的目的地址和端口
        server 130.51.11.33:19001 weight=5 max_fails=3 fail_timeout=30s;
    }

    # 提供转发的服务，即访问localhost:30001，会跳转至代理bss_num_socket指定的转发地址
    server {
       listen 30001;
       proxy_connect_timeout 1s;
       proxy_timeout 3s;
       proxy_pass bss_num_socket;
    }
}

Nginx Plus的商业授权版开始具有TCP负载均衡的功能。从Nginx 1.7.7版本开始加入的，现在变成了一个商业收费版本，想要试用，需要在官网申请。也就是说，Nginx除了以前常用的HTTP负载均衡外，Nginx增加基于TCP协议实现的负载均衡方法。
HTTP负载均衡，也就是我们通常所有“七层负载均衡”，工作在第七层“应用层”。而TCP负载均衡，就是我们通常所说的“四层负载均衡”，工作在“网络层”和“传输层”。例如，LVS（Linux Virtual Server，Linux虚拟服务）和F5（一种硬件负载均衡设备），也是属于“四层负载均衡”。


TCP负载均衡的配置方式
Nginx使用了一个新的stream模块来实现TCP负载均衡，这个模块，类似于http和mail模块，允许我们配置一组监听TCP连接的服务。允许你配置多个服务的TCP连接，通过在upstream的server组中配置proxy_pass指令。
修改nginx.conf文件，在http模块的统计目录，添加一个stream模块（和http等同级）：
MySQL

1
2
3
4
5
6
7
8
9
10
11
12	stream {
    server {
        listen 1034;
        proxy_pass app;
    }

    upstream app {
        server 192.168.0.3:1034;
        server 192.168.0.4:1034;
        server 192.168.0.6:1034;
    }
}

TCP负载均衡的执行原理
当Nginx从监听端口收到一个新的客户端链接时，立刻执行路由调度算法，获得指定需要连接的服务IP，然后创建一个新的上游连接，连接到指定服务器。

TCP负载均衡支持Nginx原有的调度算法，包括Round Robin（默认，轮询调度），哈希（选择一致）等。同时，调度信息数据也会和健壮性检测模块一起协作，为每个连接选择适当的目标上游服务器。如果使用Hash负载均衡的调度方法，你可以使用$remote_addr（客户端IP）来达成简单持久化会话（同一个客户端IP的连接，总是落到同一个服务server上）。
和其他upstream模块一样，TCP的stream模块也支持自定义负载均和的转发权重（配置“weight=2”），还有backup和down的参数，用于踢掉失效的上游服务器。max_conns参数可以限制一台服务器的TCP连接数量，根据服务器的容量来设置恰当的配置数值，尤其在高并发的场景下，可以达到过载保护的目的。
Nginx监控客户端连接和上游连接，一旦接收到数据，则Nginx会立刻读取并且推送到上游连接，不会做TCP连接内的数据检测。Nginx维护一份内存缓冲区，用于客户端和上游数据的写入。如果客户端或者服务端传输了量很大的数据，缓冲区会适当增加内存的大小。

当Nginx收到任意一方的关闭连接通知，或者TCP连接被闲置超过了proxy_timeout配置的时间，连接将会被关闭。对于TCP长连接，我们更应该选择适当的proxy_timeout的时间，同时，关注监听socke的so_keepalive参数，防止过早地断开连接。

服务健壮性监控
TCP负载均衡模块支持内置健壮性检测，一台上游服务器如果拒绝TCP连接超过proxy_connect_timeout配置的时间，将会被认为已经失效。在这种情况下，Nginx立刻尝试连接upstream组内的另一台正常的服务器。连接失败信息将会记录到Nginx的错误日志中。

如果一台服务器，反复失败（超过了max_fails或者fail_timeout配置的参数），Nginx也会踢掉这台服务器。服务器被踢掉60秒后，Nginx会偶尔尝试重连它，检测它是否恢复正常。如果服务器恢复正常，Nginx将它加回到upstream组内，缓慢加大连接请求的比例。
之所“缓慢加大”，因为通常一个服务都有“热点数据”，也就是说，80%以上甚至更多的请求，实际都会被阻挡在“热点数据缓存”中，真正执行处理的请求只有很少的一部分。在机器刚刚启动的时候，“热点数据缓存”实际上还没有建立，这个时候爆发性地转发大量请求过来，很可能导致机器无法“承受”而再次挂掉。以mysql为例子，我们的mysql查询，通常95%以上都是落在了内存cache中，真正执行查询的并不多。
其实，无论是单台机器或者一个集群，在高并发请求场景下，重启或者切换，都存在这个风险，解决的途径主要是两种：
（1）请求逐步增加，从少到多，逐步积累热点数据，最终达到正常服务状态。
（2）提前准备好“常用”的数据，主动对服务做“预热”，预热完成之后，再开放服务器的访问。
TCP负载均衡原理上和LVS等是一致的，工作在更为底层，性能会高于原来HTTP负载均衡不少。但是，不会比LVS更为出色，LVS被置于内核模块，而Nginx工作在用户态，而且，Nginx相对比较重。另外一点，令人感到非常可惜，这个模块竟然是个付费功能。（补注：本文写于 2015 年 1 月，当初这个模块是收费的）

'', '''', 3, ''请选择'', 8, ''YC'', ''2019-06-18'', ''2019-06-18'', null, ''安装：解压
./configure --with-stream
Make
Make install
模块内容：
stream {
    # 添加socket转发的代理
    upstream bss_num_socket {
        hash $remote_addr consistent;
        # 转发的目的地址和端口
        server 130.51.11.33:19001 weight=5 max_fails=3 fail_timeout=30s;
    }
'', null, null, 0, 0, null);
INSERT INTO artical (ID, AUTHOR, ORIGINAUTHOR, ORIGINURL, TITTLE, IMGPATH, CONTENT, TAGS, NAVID, TOPICID, CATEGORIES, TYPE, CREATEDATE, UPDATEDATE, ARTICALURL, SUMMARY, LASTARTICALID, NEXTARTICALID, LIKENUMS, DISSNUMS, INTOP) VALUES (28, ''老干部'', '''', '''', ''hadoop2.7分布式安装'', ''images/6.jpg'', ''


hadoop	2.7.1
jdk	openjdk-7-jdk
ssh
rsync


1配置hosts

192.168.1.121	host1
192.168.1.114	host2
192.168.1.126	host3

192.168.1.121修改/etc/hosts和/etc/hostname
192.168.1.121   host1
192.168.1.114   host2
192.168.1.126   host3

/etc/hostname
host1

192.168.1.114和192.168.1.126修改如上

启动一下网络配置脚本：
/etc/init.d/hostname.sh start


2安装SSH，并让master免验证登陆自身服务器、节点服务器
ssh-keygen -t dsa -P'''''''' -f ~/.ssh/id_dsa cat ~/.ssh/id_dsa.pub>> ~/.ssh/authorized_keys
让主结点(master)能通过SSH免密码登录两个子结点（slave）
首先把master上面的id_rsa.pub 文件考到数据节点上面
 scp conca@192.168.1.121:~/.ssh/id_rsa.pub .
cat ~/id_rsa.pub >> ~/.ssh/authorized_keys
如果master ssh连接数据节点还需要密码请给数据节点的.ss权限设置
~/.ssh权限设置为700
~/.ssh/authorized_keys的权限设置为600


3、name节点hadoop安装
解压hadoop-2.7.1.tar.gz 到/usr/local
hadoop-2.7.1重命名hadoop
hadoop配置文件位置/usr/local/hadoop/etc/hadoop

配置core-site.xml：
<configuration>
	<property>
		<name>fs.defaultFS</name>
		<value>hdfs://host1:9000</value>
	</property>
<property>
             <name>dfs.namenode.name.dir</name>
             <value>file:/usr/local/data/hadoop/name</value>
       </property>
      <property>
              <name>dfs.datanode.data.dir</name>
              <value>file:/usr/local/data/hadoop/data</value>
       </property>
<property>
   <name>hadoop.tmp.dir</name>
   <value>/usr/local/data/hadoop/tmp</value>
   <description>A base for other temporary directories.</description>
</property>

</configuration>

配置hdfs-site.xml：

<configuration>
	<property>
		<name>dfs.replication</name>
		<value>2</value>
	</property>
	<property>
		<name>dfs.namenode.secondary.http-address</name>
		<value>host1:9001</value>
	</property>
</configuration>

配置mapred-site.xml：

<configuration>
	<property>
		<name>mapreduce.framework.name</name>
		<value>yarn</value>
	</property>
	<property>
		<name>mapreduce.jobhistory.address</name>
		<value>host1:10020</value>
	</property>
	<property>
		<name>mapreduce.jobhistory.webapp.address</name>
		<value>host1:19888</value>
	</property>
</configuration>

配置yarn-site.xml：

<configuration>
	<property>
		<name>yarn.nodemanager.aux-services</name>
		<value>mapreduce_shuffle</value>
	</property>
	<property>
		<name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
		<value>org.apache.hadoop.mapred.ShuffleHandler</value>
	</property>
	<property>
		<name>yarn.resourcemanager.address</name>
		<value>host1:8032</value>
	</property>
	<property>
		<name>yarn.resourcemanager.scheduler.address</name>
		<value>host1:8030</value>
	</property>
	<property>
		<name>yarn.resourcemanager.resource-tracker.address</name>
		<value>host1:8031</value>
	</property>
	<property>
		<name>yarn.resourcemanager.admin.address</name>
		<value>host1:8033</value>
	</property>
	<property>
		<name>yarn.resourcemanager.webapp.address</name>
		<value>host1:8088</value>
	</property>
</configuration>

配置java环境变量，查看java安装的位置：/usr/lib/jvm/java-6-openjdk-amd64

hadoop-env.sh、mapred-env.sh、yarn-env.sh这几个文件中的JAVA_HOME改为/usr/bin/java


slaves文件配置,增加如下两行内容
Host2
Host3
到此name节点已经配置好了，

4、把name节点的hadoop考到数据节点上面
scp -r conca@192.168.1.121:/usr/local/hadoop .
Mv hadoop /usr/local

报错1：：hadoop/NameNode : Unsupported major.minor version 51.0

jdk版本不队，我的安装是1.6 修改成1.7
sudo apt-get remove openjdk-6-jdk
sudo apt-get autoremove
sudo apt-get install openjdk-7-jdk

scp conca@192.168.1.121:/usr/local/hadoop/etc/hadoop/* .


报错2:::host2: Host key verification failed
host2数据节点的.ss权限设置
~/.ssh权限设置为700
~/.ssh/authorized_keys的权限设置为600

hadoop 19888不能访问
1.	mr-jobhistory-daemon.sh start historyserver


格式化命令bin/hdfs namenode -format
开启命令 /usr/local/hadoop/sbin/   ./start-all.sh

Daemon	Web Interface	Notes
NameNode	http://nn_host:port/
Default HTTP port is 50070.
ResourceManager	http://rm_host:port/
Default HTTP port is 8088.
MapReduce JobHistory Server	http://jhs_host:port/
Default HTTP port is 19888.


查看任务
hadoop job -list
查看文件夹
bin/hdfs dfs -ls /
创建文件
  $ bin/hdfs dfs -mkdir /user   $ bin/hdfs dfs -mkdir /user/<username>
上传文件
 $ bin/hdfs dfs -put etc/hadoop input
 dfs -put access.log  /nginx
删除文件
 $ bin/hdfs dfs -rm 文件
删除文件夹
 $ bin/hdfs dfs -rmr 文件夹

测试自己写的jar文件
 bin/hadoop jar ~/hadoop-jar/kpiBrowerV.jar com.conca.nginx.KpiBrowserSimpleV /nginx/access.log /ouput/nginx/access.log





'', '''', 3, ''请选择'', 8, ''YC'', ''2019-06-18'', ''2019-06-18'', null, ''hadoop	2.7.1
jdk	openjdk-7-jdk
ssh
rsync
'', null, null, 0, 0, null);
INSERT INTO artical (ID, AUTHOR, ORIGINAUTHOR, ORIGINURL, TITTLE, IMGPATH, CONTENT, TAGS, NAVID, TOPICID, CATEGORIES, TYPE, CREATEDATE, UPDATEDATE, ARTICALURL, SUMMARY, LASTARTICALID, NEXTARTICALID, LIKENUMS, DISSNUMS, INTOP) VALUES (29, ''老干部'', '''', '''', ''Hadoop2.7.0集群搭建'', ''images/4.jpg'', ''Hadoop2.7.0集群搭建
1.	系统配置
	电脑1(Lenovo E420)，win7 64位系统，8G内存，此电脑虚拟机上运行两个ubuntu14.10系统。
	电脑2(Lenovo SL410)，win7 64位系统，4G内存，此电脑虚拟机上运行一个ubuntu14.10系统。
	虚拟机：Vmware10.0
	Hadoop2.7.0
	Zookeeper3.4.6
2.	集群规划
由于本人电脑配置太差，经过实际操作发现E420最多只能运行两台虚拟机ubuntu系统，所以就在另一台电脑SL410上搭建了另一个虚拟机ubuntu系统，其具体规划如下：
主机名	IP	安装软件	运行的进程
Ubuntu1	192.168.1.120	Jdk,hadoop
zookeeper	NameNode、DFSZKFailoverController、DataNode、NodeManager、JournalNode、QuorumPeerMain
Ubuntu2	192.168.1.121	Jdk,hadoop
zookeeper	NameNode,DFSZKFailoverController,DataNode、NodeManager、JournalNode、QuorumPeerMain
Ubuntu3	192.168.1.122	Jdk,hadoop
zookeeper	DataNode、NodeManager、JournalNode、QuorumPeerMain,ResourceManager
 说明：
在hadoop2.0中通常由两个NameNode组成，一个处于active状态，另一个处于standby状态。Active NameNode对外提供服务，而Standby NameNode则不对外提供服务，仅同步activenamenode的状态，以便能够在它失败时快速进行切换。
hadoop2.0官方提供了两种HDFS HA的解决方案，一种是NFS，另一种是QJM。这里我们使用简单的QJM。
在该方案中，主备NameNode之间通过一组JournalNode同步元数据信息，一条
	数据只要成功写入多数JournalNode即认为写入成功。通常配置奇数个JournalNode
	这里还配置了一个zookeeper集群，用于ZKFC（DFSZKFailoverController）故障转移，当
	Active NameNode挂掉了，会自动切换Standby NameNode为standby状态。
3.	两台电脑之间的通信
	按路径“控制面板/网络和Internet/网络和共享中心/无线网络连接/详细信息”进入网络连接详细信息界面查看Win7网络通信相关信息。
在“网络连接详细信息”中要注意以下几个属性：描述(此属性用于在虚拟机中桥接通信时选择桥接目标)，IPv4地址，IPv4默认网关，以下是我的具体配置
电脑
类型	描述	IPv4地址	IPv4默认网关
E420	1x1  11b/g/n wireless LAN PCI Express Half Mini Card Adapter	192.168.1.104	192.168.1.1
SL410	Intel(R) WIFI Link 1000 BGN	192.168.1.103	192.168.1.1
	设置虚拟机网络信息
1)	按路径“编辑(E)/虚拟网络编辑器(N)”进入网络编辑器将WMnet0的VMnet信息设置成桥接模式，“桥接到”选项为上文提到的描述信息，其实这个描述信息就是当前电脑的网卡名称，如下图所示：

2)	按路径“虚拟机(M)/设置(S)”进入虚拟机设置界面，选择网络适配器为“桥接模式”，如下图所示：


3)	在ubuntu命令行Vim /etc/network/interfaces设置ubuntu IP，如下所示：

注意：address 	192.168.1.120(此IP必须和win7 IP在同一个网段)
gateway 	192.168.1.1 (此网关必须和win7 的网关相同)
4)	在ubuntu命令行vim /etc/hostname中设置ubuntu主机名，如下图所示：

5)	在ubuntu命令行vim /etc/hosts 中设置ubuntu主机名和ip地址的对应关系，如下图所示：

6)	验证各系统之间是否能够ping通。
4.	安装配置zookeeper集群
1)	解压zookeeper压缩包到/home/brian/hadoop
 tar –zxvf zookeeper-3.4.6.tar.gz –C /home/brian/hadoop
 mv /home/brian/hadoop/zookeeper-3.4.6 /home/brian/hadoop/zk
2)	在/home/brian/hadoop/zk/conf修改zookeeper配置zoo.cfg，具体配置如下图所示：


3)	在/home/brian/hadoop/zk中设置创建tmp目录
Mkdir /home/brian/hadoop/zk/tmp
4)	在/home/brian/hadoop/zk/tmp目录中创建空文件myid，并写入1
vim  /home/brian/hadoop/zk/tmp/myid。
5)	将配置好的zookeeper拷贝到ubuntu2和ubuntu3
scp -r /home/brian/hadoop/zk/ root@ubuntu2:/home/brian/hadoop
scp -r /home/brian/hadoop/zk/ root@ubuntu3:/home/brian/hadoop
6)	在ubuntu2和ubuntu3中分别修改myid为2和3。
5.	安装配置hadoop集群
1)	解压hadoop压缩包到/home/brian/hadoop
tar -zxvf hadoop-2.7.0.tar.gz -C /home/brian/hadoop/
2)	安装hadoop
mv  /home/brian/hadoop/hadoop-2.7.0  /home/brian/hadoop/hadoop
在~/.bashrc中配置hadoop的安装信息，如下图所示：

6.	配置hadoop
hadoop2.7.0的所有配置文件从存在/home/brian/hadoop/hadoop/etc/hadoop之中。
cd /home/brian/hadoop/hadoop/etc/hadoop
1)	修改hadoop-env.sh
export  JAVA_HOME=/home/brian/hadoop/jdk
2)	修改core-site.xml
	<configuration>
		<!-- 指定hdfs的nameservice为ns1 -->
		<property>
			<name>fs.defaultFS</name>
			<value>hdfs://ns1</value>
		</property>
		<!-- 指定hadoop临时目录 -->
		<property>
			<name>hadoop.tmp.dir</name>
			<value>/home/brian/hadoop/hadoop/tmp </value>
		</property>
		<!-- 指定zookeeper地址 -->
		<property>
			<name>ha.zookeeper.quorum</name>
			<value>ubuntu1:2181,ubuntu2:2181,ubuntu3:2181 </value>
		</property>
	</configuration>
3)	修改hdfs-site.xml
	<configuration>
		<!--指定hdfs的nameservice为ns1，需要和core-site.xml中的保持一致 -->
		<property>
			<name>dfs.nameservices</name>
			<value>ns1</value>
		</property>
		<!-- ns1下面有两个NameNode，分别是nn1，nn2 -->
		<property>
			<name>dfs.ha.namenodes.ns1</name>
			<value>nn1,nn2</value>
		</property>
		<!-- nn1的RPC通信地址 -->
		<property>
			<name>dfs.namenode.rpc-address.ns1.nn1</name>
			<value>ubuntu1:9000</value>
		</property>
		<!-- nn1的http通信地址 -->
		<property>
			<name>dfs.namenode.http-address.ns1.nn1</name>
			<value>ubuntu1:50070</value>
		</property>
		<!-- nn2的RPC通信地址 -->
		<property>
			<name>dfs.namenode.rpc-address.ns1.nn2</name>
			<value>ubuntu2:9000</value>
		</property>
		<!-- nn2的http通信地址 -->
		<property>
			<name>dfs.namenode.http-address.ns1.nn2</name>
			<value>ubuntu2:50070</value>
		</property>
		<!-- 指定NameNode的元数据在JournalNode上的存放位置 -->
		<property>
			<name>dfs.namenode.shared.edits.dir</name>									<value>qjournal://ubuntu1:8485;ubuntu2:8485;ubuntu3:8485/ns1</value>
		</property>
		<!-- 指定JournalNode在本地磁盘存放数据的位置 -->
		<property>
			<name>dfs.journalnode.edits.dir</name>
			<value>/home/brian/hadoop/hadoop/journal </value>
		</property>
		<!-- 开启NameNode失败自动切换 -->
		<property>
			<name>dfs.ha.automatic-failover.enabled</name>
			<value>true</value>
		</property>
		<!-- 配置失败自动切换实现方式 -->
		<property>
			<name>dfs.client.failover.proxy.provider.ns1</name>
			<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
		</property>
		<!-- 配置隔离机制方法，多个机制用换行分割，即每个机制暂用一行-->
		<property>
			<name>dfs.ha.fencing.methods</name>
			<value>
				sshfence
				shell(/bin/true)
			</value>
		</property>
		<!-- 使用sshfence隔离机制时需要ssh免登陆 -->
		<property>
			<name>dfs.ha.fencing.ssh.private-key-files</name>
			<value>/root/.ssh/id_rsa</value>
		</property>
		<!-- 配置sshfence隔离机制超时时间 -->
		<property>
			<name>dfs.ha.fencing.ssh.connect-timeout</name>
			<value>30000</value>
		</property>
	</configuration>
4)	修改mapred-site.xml
	<configuration>
		<!-- 指定mr框架为yarn方式 -->
		<property>
			<name>mapreduce.framework.name</name>
			<value>yarn</value>
		</property>
	</configuration>
5)	修改yarn-site.xml
	<configuration>
		<!-- 指定resourcemanager地址 -->
		<property>
			<name>yarn.resourcemanager.hostname</name>
			<value>ubuntu3</value>
		</property>
		<!-- 指定nodemanager启动时加载server的方式为shuffle server -->
		<property>
			<name>yarn.nodemanager.aux-services</name>
			<value>mapreduce_shuffle</value>
		</property>
	</configuration>
6)	修改slaves
slaves是指定子节点的位置，因为要在ubuntu1上启动HDFS、在ubuntu3启动yarn，所以ubuntu1上的slaves文件指定的是datanode的位置，ubuntu3上的slaves文件指定的是nodemanager的位置
cd /home/brian/hadoop/hadoop/etc/hadoop/
vim slaves
ubuntu1
ubuntu2
ubuntu3
7.	将配置好的hadoop拷贝到ubuntu2和ubuntu3
scp  -r /home/brian/hadoop/hadoop root@ubuntu2:/home/brian/hadoop/
scp  -r /home/brian/hadoop/hadoop root@ubuntu3:/home/brian/hadoop/
*********************注意：以下操作必须严格按照顺序*****************************
8.	启动zookeeper集群(在ubuntu1,ubuntu2,ubuntu3的/home/brian/hadoop/zk/bin/里开启)
cd /home/brian/hadoop/zk/bin
./zkServer.sh start(启动zookeeper节点)
./zkServer.sh status(查看zookeeper状态)
9.	启动journalnode(在ubuntu1,ubuntu2,ubuntu3的/home/brian/hadoop/hadoop/sbin里启动)
hadoop-daemons.sh start journalnode
jps(依次在每个节点中查看各节点是否多了Journalnode进程)
10.	格式化HDFS
在ubuntu1上执行格式化命令
hdfs  namenode  -format
格式化后会在根据core-site.xml中的hadoop.tmp.dir配置生成个文件，这里我配置的是/home/brian/hadoop/hadoop/tmp，然后将/home/brian/hadoop/hadoop/tmp拷贝到ubuntu2和ubuntu3的/home/brian/hadoop/hadoop下。
scp  -r /home/brian/hadoop/hadoop/tmp root@ubuntu2:/home/brian/hadoop/hadoop
scp  -r /home/brian/hadoop/hadoop/tmp root@ubuntu3:/home/brian/hadoop/hadoop
11.	格式化ZK
在ubuntu1上执行格式化命令
hdfs  zkfc  -formatZK
12.	启动HDFS
在ubuntu1的/home/brian/hadoop/hadoop/sbin中执行start-dfs.sh命令
cd  /home/brian/hadoop/hadoop/sbin/
start-dfs.sh
启动之后，分别进入ubuntu1,ubuntu2,ubuntu3中jps，查看是否多了NameNode 和 DFSZKFailoverController两个进程
13.	启动YARN
在ubuntu3中的/home/brian/hadoop/hadoop/sbin中执行start-yarn.sh命令
cd  /home/brian/hadoop/hadoop/sbin/
start-yarn.sh
是在ubuntu3上执行start-yarn.sh，把namenode和resourcemanager分开是因为性能问题，因为他们都要占用大量资源，所以把他们分开了，他们分开了就要分别在不同的机器上启动
14.	到此，hadoop2.7.0的配置完毕，可以通过浏览器访问来查看部署是否成功
'', '''', 3, ''请选择'', 8, ''YC'', ''2019-06-18'', ''2019-06-18'', null, ''1.	系统配置
	电脑1(Lenovo E420)，win7 64位系统，8G内存，此电脑虚拟机上运行两个ubuntu14.10系统。
	电脑2(Lenovo SL410)，win7 64位系统，4G内存，此电脑虚拟机上运行一个ubuntu14.10系统。
	虚拟机：Vmware10.0
	Hadoop2.7.0
	Zookeeper3.4.6
'', null, null, 0, 0, null);
INSERT INTO artical (ID, AUTHOR, ORIGINAUTHOR, ORIGINURL, TITTLE, IMGPATH, CONTENT, TAGS, NAVID, TOPICID, CATEGORIES, TYPE, CREATEDATE, UPDATEDATE, ARTICALURL, SUMMARY, LASTARTICALID, NEXTARTICALID, LIKENUMS, DISSNUMS, INTOP) VALUES (30, ''老干部'', '''', '''', ''Hadoop2.7.1安装手册'', ''images/5.jpg'', ''hadoop2.7.1安装手册
1、准备阶段述
·hadoop-2.7.1.tar.gz安装包
·jdk1.6以上版本，这里统一使用jdk1.8版本jdk-8u45-linux-x64.rpm
·CentOS-6.4安装包
2、安装步骤概述
2.1、安装Centos-6.4系统
2.2、安装jdk1.8
2.4、	如若使用64位机器，请编译hadoop-2.7.1文件
2.4、zookeeper安装，单机安装以及集群安装
2.5、关闭linux防火墙，安装已编译好的hadooop安装包以及配置QJM，或者配置High Availability With NFS，验证hadoop是否安装成功
2.6、sqoop的编译与安装
2.7、Mysql安装
2.8、HBASE安装
2.9、HIVE安装
3、集群规划
集群规划：
主机名	IP	安装的软件	运行的进程
hadoop01	172.16.112.113	jdk、hadoop	NameNode、DFSZKFailoverController(zkfc)
hadoop02	172.16.112.114	jdk、hadoop	NameNode、DFSZKFailoverController(zkfc)
hadoop03	172.16.112.115	jdk、hadoop	ResourceManager
hadoop04	172.16.112.116	jdk、hadoop	ResourceManager
hadoop05	172.16.112.117	jdk
hadoop
zookeeper	DataNode
NodeManager
JournalNode
QuorumPeerMain
hadoop06	172.16.112.118	jdk
hadoop
zookeeper	DataNode
NodeManager
JournalNode
QuorumPeerMain
hadoop07	172.16.112.119	jdk
hadoop
zookeeper	DataNode
NodeManager
JournalNode
QuorumPeerMain


4、安装具体步骤
	4.1、安装Centos-6.4系统
(1)、下载64位的CentOS-6.4镜像文件
	CentOS-6.4-x86_64-bin-DVD1.iso
	CentOS-6.4-x86_64-bin-DVD2.iso
	系统安装只用到CentOS-6.4-x86_64-bin-DVD1.iso这个镜像，第二个镜像是系统自带的软件安装包
	下载完成之后，使用光盘刻录软件将ISO镜像文件刻录在CD或者DVD光盘里得到一张安装光盘

(2)、安装CentOS
·使用安装介质启动电脑出现如下界面

·选择Install or upgrade an existing system，并跳过media test



·出现引导界面，点击next

·语言选择，选“English”，以防止出现乱码

·键盘布局选择：U.S.English

·选择“Basic Storage Devies”，点击next

·询问是否忽略所有数据，新电脑安装系统选择"Yes,discard any data"

·Hostname填写


·网络设置安装图示顺序点击就可以了

·时区可以在地图上点击，选择“shanghai”并取消System clock uses UTC前面的对勾

·设置root的密码


·硬盘分区，一定要按照图示点选

·调整分区，必须要有/home这个分区，如果没有这个分区，安装部分软件会出现不能安装的问题

·询问是否格式化分区

·将更改写入到硬盘

·引导程序安装位置

·选择安装模式选择Minimal Desktop安装模式，并且选择现在进行客户化定制

在进行“客户化定制时”可直接next，不过在language support时，选择“Chinese Support”，如下图：

·
(3)、修改虚拟机主机名并建立IP地址与主机名之间的映射关系，最后重启虚拟机
以root权限登录
	·修改主机名：vi /etc/sysconfig/network ；分别修改HOSTNAME的值，为对应的主机名hadoop01、hadoop02、hadoop03
	·建立IP地址与主机名之间的映射关系：vi /etc/hosts；
在hadoop01虚拟机的hosts文件中添加如下字段：
		172.16.112.113 hadoop01
在hadoop02虚拟机的hosts文件中添加如下字段：
172.16.112.114 hadoop02
在hadoop03虚拟机的hosts文件中添加如下字段：
172.16.112.115 hadoop03
在hadoop02虚拟机的hosts文件中添加如下字段：
172.16.112.116 hadoop04
在hadoop02虚拟机的hosts文件中添加如下字段：
172.16.112.117 hadoop05
在hadoop02虚拟机的hosts文件中添加如下字段：
172.16.112.118 hadoop06
在hadoop02虚拟机的hosts文件中添加如下字段：
172.16.112.119 hadoop07
4.2、安装jdk1.8
	(1)、在hadoop家目录下创建software文件夹，并使用Secure CRT工具,点击Secure FX将所需要的jdk安装包上传到linux系统上的software文件中
	·切换回当前用户：su – hadoop01
·创建目录：mkdir /home/hadoop01/software
·上传文件：（以二进制文件形式传输）

	(2)、安装jdk1.8
	·进入jdk1.8存放目录：cd /home/hadoop01/software/
	·切换为root用户：su，输入密码
	·安装jdk1.8: rpm -ivh jdk-8u45-linux-x64.rpm
	(3)、配置jdk环境变量
	·设置环境变量：vi /etc/profile
	·在profile文件中设置JAVA_HOME、CLASS_PATH、PATH三个环境变量：
# JAVA_HOME
export JAVA_HOME=/usr/java/jdk1.8.0_45

# CLASSPATH
export  CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar

#PATH
export PATH=$PATH:$JAVA_HOME/bin
	·启动配置项：source /etc/profile
	·验证jdk是否安装成功：java –version
如图：安装成功

4.3编译hadoop2.7.1
(1)、实现ssh登录，公钥自联
	·登录root用户：su ，输入密码
	·打开公钥验证服务：
#RSAAuthentication yes
#PubkeyAuthentication yes
#AuthorizedKeysFile     .ssh/authorized_keys
去掉这也项的#
	·重启ssh服务：service sshd restart
 	·以hadoop01账户登录linux系统：su – hadoop01
	·启动ssh协议：rpm -qa|grep openssh
			         rpm -qa|grep rsync
	·生成密钥对：ssh-keygen -t rsa -P ''''''''	 直接回车
	·将公钥写入授权文件：cat ~/.ssh/id_dsa.pub >> authorized-keys
	·修改授权文件权限：
			授权文件：chmod 600 ~/.ssh/authorized-keys
	·验证ssh登录：	ssh localhost
多次ssh登录到localhost用户观察是否还需要输入密码
如图时，成功

(2)、将hadoop01作为Master节点，配置ssh免密码登陆，使得hadoop01无密码登录所有的slave节点：
	·将其他两台hadoop02，hadoop03，hadoop04，hadoop05，hadoop06，hadoop07实现一次自联过程
	·分别修改hadoop02，hadoop03，hadoop04，hadoop05，hadoop06，hadoop07节点上.ssh文件的权限和authorized-keys文件的权限:
 chmod 700 ~/.ssh
chmod 600 authorized-keys
	·将hadoop01节点的公钥传给hadoop02，hadoop03，hadoop04，hadoop05，hadoop06，hadoop07:
scp ~/.ssh/id_rsa.pub hadoop@hadoop02:~/
scp ~/.ssh/id_rsa.pub hadoop@hadoop03:~/
scp ~/.ssh/id_rsa.pub hadoop@hadoop04:~/
scp ~/.ssh/id_rsa.pub hadoop@hadoop05:~/
scp ~/.ssh/id_rsa.pub hadoop@hadoop06:~/
scp ~/.ssh/id_rsa.pub hadoop@hadoop07:~/

	·将hadoop01的公钥追加到hadoop02，hadoop03，hadoop04，hadoop05，hadoop06，hadoop07的authorized-keys中：
cat ~/id_rsa.pub >> ~/.ssh/authorized-keys
·验证是否实现ssh登录
		ssh hadoop02
		ssh hadoop03
		ssh hadoop04
		ssh hadoop05
		ssh hadoop06
		ssh hadoop07

(3)、编译hadoop-2.7.1环境
	·所需软件：maven、protobuf、openssl库、CMake、ant
	·安装maven：
			1、解压缩压缩包：
			tar -zxvf apache-maven-3.3.3-bin.tar.gz
			2、设置Maven环境变量：
			#MAVEN
export MAVEN_HOME=/home/hadoop/software/apache-maven-3.3.3

			#environment path
export PATH= /home/hadoop/software/apache-maven-3.3.3/bin
3、生效
source /etc/profile
4、验证maven
mvn –v
	·安装protobuf-2.5.0
1、	安装依赖包
以root身份登录
yum install gcc-c++
2、	解压protobuf-2.5.0安装包
tar -zxvf protobuf-2.5.0.tar.gz
3、	进入protobuf-2.5.0文件夹，进行如下操作：
./configure
make
make check
make install
ldconfig
4、	修改环境变量：
vi /etc/profile
#protobuf
export LD_LIBRARY_PATH=/home/hadoop/software/protobuf-2.5.0
5、	生效
source /etc/profile
注意：配置/etc/profile，在虚拟机重启后，可能配置会失效，所以重启后，需要再次执行source操作。
6、	安装pache-ant-1.9.4-bin.tar.gz
·解压安装包：tar -zxvf apache-ant-1.9.4-bin.tar.gz
·配置环境变量：vi /etc/profile
#Ant
export ANT_HOME=/home/hadoop/software/apache-ant-1.9.4
#PATH
export PATH= $ANT_HOME/bin
				·生效
					source /etc/profile
				·校验
					ant -version
7、	编译hadoop-2.7.1
将hadoop-2.7.1-src.tar.gz解压缩，并进入hadoop-2.7.1-src文件夹
执行命令：mvn package -Pdist,native -DskipTests -Dtar
8、	在目录hadoop-2.4.0-src/hadoop-dist/target下有文件：
hadoop-2.4.0.tar.gz编译成功

4.4 Zookeeper 3.2 单机安装
本篇為Zookeeper 的獨立測試 （不包含搭配 Hadoop, Hbase 的協同合作）
•	測試於 Ubuntu 9.10 ， Zookeeper 為 3.2.1 版，java 版本為 1.6 ，並且於環境變數已經加入 JAVA_HOME=/usr/lib/jvm/java-6-sun
•	設定好 ssh localhost 免密碼
 安裝目錄	 /opt/zookeeper/
 工作目錄	 /var/zookeeper/

安装步骤
1.	下載 zookeeper 最新版，並且解壓縮到 /opt/zookeeper
2.	新建 /var/zookeeper 當作 zookeeper的工作目錄，並確實設定可讀寫權限
新建配置文档 /opt/zookeeper/conf/zoo.cfg
tickTime=2000
dataDir=/var/zookeeper
clientPort=2181

$ cd /local/software/zookeeper/;ln -s zookeeper-3.3.1/  zookeeper
$ export ZOOKEEPER_INSTALL=/local/software/zookeeper/zookeeper/
$ export PATH=$PATH:$ZOOKEEPER_INSTALL/bin


接着执行
$ cd /opt/zookeeper
$ bin/zkServer.sh start

完成启动

运行 netstat -tnl
可以看到 2181 端口已打开

关闭
＄bin/zkServer.sh stop

执行测试
接着执行
＄bin/zkCli.sh -server 127.0.0.1:2181


基本测试
[zkshell: 0] help
[zkshell: 8] ls /
[zookeeper]

[zkshell: 9] create /zk_test my_data
Created /zk_test

[zkshell: 11] ls /
[zookeeper, zk_test]

[zkshell: 12] get /zk_test
my_data

[zkshell: 14] set /zk_test junk

[zkshell: 15] get /zk_test
junk

[zkshell: 16] quit

·zooKeeper配置文件参数
参考：http://hadoop.apache.org/zookeeper/docs/r3.3.1/zookeeperAdmin.html#sc_configuration
ZooKeeper Server的行为受配置文件zoo.cfg的控制，zoo.cfg的设计目标是让所有服务器都可以使用相同的配置文件，如果需要使用不同的配置文件，需要保证关于cluster部分的参数相同。下面是具体的参数：
最小必要配置的参数
clientPort
服务的监听端口
dataDir
用于存放内存数据库快照的文件夹，同时用于集群的myid文件也存在这个文件夹里（注意：一个配置文件只能包含一个dataDir字样，即使它被注释掉了。）
tickTime
心跳时间，为了确保连接存在的，以毫秒为单位，最小超时时间为两个心跳时间
高级配置参数
dataLogDir
用于单独设置transaction log的目录，transaction log分离可以避免和普通log还有快照的竞争
globalOutstandingLimit
client请求队列的最大长度，防止内存溢出，默认值为1000
preAllocSize
预分配的Transaction log空间为block个proAllocSize KB，默认block为64M，一般不需要更改，除非snapshot过于频繁
snapCount
在snapCount个snapshot后写一次transaction log，默认值是100,000
traceFile
用于记录请求的log，打开会影响性能，用于debug的，最好不要定义
maxClientCnxns
最大并发客户端数，用于防止DOS的，默认值是10，设置为0是不加限制
clientPortBindAddress
3.3.0后新增参数，可是设置指定的client ip以及端口，不设置的话等于ANY:clientPort
minSessionTimeout
3.3.0后新增参数，最小的客户端session超时时间，默认值为2个tickTime，单位是毫秒
maxSessionTimeout
3.3.0后新增参数，最大的客户端session超时时间，默认值为20个tickTime，单位是毫秒
集群参数
electionAlg
用于选举的实现的参数，0为以原始的基于UDP的方式协作，1为不进行用户验证的基于UDP的快速选举，2为进行用户验证的基于UDP的快速选举，3为基于TCP的快速选举，默认值为3
initLimit
多少个心跳时间内，允许其他server连接并初始化数据，如果ZooKeeper管理的数据较大，则应相应增大这个值
leaderServes
leader是否接受客户端连接。默认值为yes。 leader负责协调更新。当更新吞吐量远高于读取吞吐量时，可以设置为不接受客户端连接，以便leader可以专注于同步协调工作。默认值是yes，说明leader可以接受客户端连接。（注意：当集群中有超过3台ZooKeeper Server时，强烈建议打开leader选举）
server.x=[hostname]:nnnnn[:nnnnn], etc
配置集群里面的主机信息，其中server.x的x要写在myid文件中，决定当前机器的id，第一个port用于连接leader，第二个用于leader选举。如果electionAlg为0，则不需要第二个port。hostname也可以填ip。
syncLimit
多少个tickTime内，允许follower同步，如果follower落后太多，则会被丢弃。
group.x=nnnnn[:nnnnn]
weight.x=nnnnn
这两个是用于集群分组的参数，暂时只有3台机器，没仔细研究，先给个例子看看吧
group.1=1:2:3
group.2=4:5:6
group.3=7:8:9

weight.1=1
weight.2=1
weight.3=1
weight.4=1
weight.5=1
weight.6=1
weight.7=1
weight.8=1
weight.9=1
用于用户认证的选项
略
不安全选项
略

·ZooKeeper集群部署管理
1. 约定：
a. ZooKeeper Server，[server1]的ip为172.16.104.241，[server2]的ip为172.16.104.242，[server3]的ip为172.16.104.243。
b. [zk_dir]表示ZooKeeper的根目录，假设为/home/user/zookeeper
c. [zk_data]表示ZooKeeper数据文件存放地址，假设为/home/user/zk_data
d. [zk_trlog]表示ZooKeeper的Transaction Log目录，假设为/home/user/zk_trlog
e. [zk_logs]表示ZooKeeper的一半log目录，假设为/home/user/zk_logs
2. 服务端环境要求：
a. Linux或者其他类UNIX系统（Windows及Mac OS只能作为开发环境，不能做生产环境）
b. JDK 1.6或更高
c. Server管理需要netcat或者telnet
3. 获得ZooKeeper发行版：
访问：http://hadoop.apache.org/zookeeper/releases.html，目前ZooKeeper的最新版本为3.3.1版本（2010年5月17日发行）
4． 修改配置文件：
因为ZooKeeper的配置文件设计目标是可供所有机器使用的通用配置文件，因此可以现在一台机器上写完，然后复制到其他server上。在[zk_dir]/conf下新建zoo.cfg文件，详细参数说明参见附录，这里给出一个配置文件的例子：
# BASIC SETTINGS

# The number of milliseconds of each tick
tickTime=2000

# the port at which the clients will connect
clientPort=2181

# the directory where the snapshot is stored.
dataDir=/home/user/zk_logs/zk_data

# the directory where the transaction log is stored
dataLogDir=/home/user/zk_logs/zk_trog

# BASIC SETTINGS END

##########################################################

# CLUSTER SETTINGS

# The number of ticks that the initial
# synchronization phase can take
initLimit=10

# The number of ticks that can pass between
# sending a request and getting an acknowledgement
syncLimit=5

# CLUSTER SERVER CONFIG
server.1=192.168.1.201:2888:3888
server.2=192.168.1.202:2888:3888
server.3=192.168.1.203:2888:3888

# CLUSTER SETTINGS END
其中的# CLUSTER SERVER CONFIG部分为集群的三台机器的ip
5． 为每台服务器设置id：
在[server1]的[zk_data]目录下新建myid文件，纯文本ASCII编码文件即可，内容为1，也就是配置文件中server.x中的x的值。其他两台机器上依此类推，也新建内容为自己id的myid文件。
6． 配置log文件信息：
ZooKeeper采用log4j记录日志，log4j.properties文件在[zk_dir]/conf目录下，编辑[zk_dir]/conf/log4j.properties文件，按需要配置，这里给出一个在文件里记录DEBUG, INFO, ERROR等级，并且文件每天重命名一次的例子：
#
# ZooKeeper Logging Configuration
#

log4j.rootLogger=INFO, DEBUG, ERROR

# DEBUG
log4j.appender.DEBUG=org.apache.log4j.DailyRollingFileAppender
log4j.appender.DEBUG.Threshold=DEBUG
log4j.appender.DEBUG.layout=org.apache.log4j.PatternLayout
log4j.appender.DEBUG.layout.ConversionPattern=%d{ISO8601} - %-5p [%t:%C{1}@%L] - %m%n
log4j.appender.DEBUG.datePattern=''''.''''yyyy-MM-dd''''.log''''
log4j.appender.DEBUG.append=true
log4j.appender.DEBUG.File=/home/user/zk_logs/zk_debug.log

# INFO
log4j.appender.INFO=org.apache.log4j.DailyRollingFileAppender
log4j.appender.INFO.Threshold=INFO
log4j.appender.INFO.layout=org.apache.log4j.PatternLayout
log4j.appender.INFO.layout.ConversionPattern=%d{ISO8601} - %-5p [%t:%C{1}@%L] - %m%n
log4j.appender.INFO.datePattern=''''.''''yyyy-MM-dd''''.log''''
log4j.appender.INFO.append=true
log4j.appender.INFO.File=/home/user/zk_logs/zk_error.log

# ERROR
log4j.appender.ERROR=org.apache.log4j.DailyRollingFileAppender
log4j.appender.ERROR.Threshold=ERROR
log4j.appender.ERROR.layout=org.apache.log4j.PatternLayout
log4j.appender.ERROR.layout.ConversionPattern=%d{ISO8601} - %-5p [%t:%C{1}@%L] - %m%n
log4j.appender.ERROR.datePattern=''''.''''yyyy-MM-dd''''.log''''
log4j.appender.ERROR.append=true
log4j.appender.ERROR.File=/home/user/zk_logs/zk_error.log
7. Server简单管理命令：
现在可以启动ZooKeeper服务器了：
# Server启动命令
$ [zk_dir]/bin/zkServer.sh start
# Server重启
$ [zk_dir]/bin/zkServer.sh restart
# Server停止
$ [zk_dir]/bin/zkServer.sh stop
# Server基本状态查看，需要netcat
$ [zk_dir]/bin/zkServer.sh status
8. ZooKeeper的管理命令：
需要使用telnet或者netcat连接到ZooKeeper Server的clientPort端口，命令均为4个字母，命令及功能如下：
conf
3.3.0新增: 打印server配置文件内容
cons
3.3.0新增:列出连接到本Server的Client的完整连接及Session信息。包括分组发送/接收信息，session id，操作延时，最后一个操作的执行等
crst
3.3.0新增: 重置所有连接/session
dump
Lists the outstanding sessions and ephemeral nodes. 只在leader server上有效。
envi
屏幕打印server的环境变量
ruok
测试server是否处于无错状态。 如果状态健康则返回”imok”，否则无任何结果。
A response of “imok” does not necessarily indicate that the server has joined the quorum, just that the server process is active and bound to the specified client port. Use “stat” for details on state wrt quorum and client connection information.
srst
Reset server statistics.
srvr
3.3.0新增: Lists full details for the server.
stat
Lists brief details for the server and connected clients.
wchs
3.3.0新增: Lists brief information on watches for the server.
wchc
3.3.0新增: Lists detailed information on watches for the server, by session. This outputs a list of sessions(connections) with associated watches (paths). Note, depending on the number of watches this operation may be expensive (ie impact server performance), use it carefully.
wchp
3.3.0新增: Lists detailed information on watches for the server, by path. This outputs a list of paths (znodes) with associated sessions. Note, depending on the number of watches this operation may be expensive (ie impact server performance), use it carefully.

4.5 oop-2.7.1安装
这里要涉及到的配置文件有7个：
/Hadoop-2.7.1/etc/hadoop/hadoop-env.sh
/Hadoop-2.7.1/etc/hadoop/slaves
/Hadoop-2.7.1/etc/hadoop/core-site.xml
/Hadoop-2.7.1/etc/hadoop/hdfs-site.xml
/Hadoop-2.7.1/etc/hadoop/mapred-site.xml
/Hadoop-2.7.1/etc/hadoop/yarn-site.xml
并且配置之前，需要在Cluster文件系统创建以下文件夹，用于存放命名空间以及数据信息。
~/dfs/name
~/dfs/data
~/temp
~/etc/hadoop/slave

每台机器的配置基本相同，所以现在作为master的hadoop01上进行部署，最终在复制到其他机器上去。

(1)、解压缩hadoop-2.7.1.tar.gz文件，注意完整的解压缩路径统一定为/home/hadoop/software/hadoop-2.7.1，进入到/hadoop-2.7.1/etc/hadoop文件夹
(2)、修改etc/hadoop/hadoop-env.sh中的JAVA_HOME,设置为hadoop所依赖的jdk路径
	export JAVA_HOME=/usr/java/jdk1.8.0_45
(3)、修改core-site.xml文件

参数	值	注释
fs.defaultFS	NameNode URI	hdfs://host:port/
io.file.buffer.size	131072	SequenceFiles文件中.读写缓存size设定

以hadoop01为例：
<configuration>
        <property>
                <name>fs.defaultFS</name>
                <value>hdfs://ns1</value>
        </property>
        <property>
                <name>hadoop.tmp.dir</name>
                <value>/home/hadoop/software/hadoop-2.7.0/tmp</value>
        </property>
<property>
                <name> io.file.buffer.size </name>
                <value>131072</value>
        </property>
<!-- 指定zookeeper地址 -->
		<property>
			<name>ha.zookeeper.quorum</name>
			<value>hadoop04:2181,hadoop06:2181,hadoop07:2181</value>
		</property>
</configuration>

(4)、修改hdfs-site.xml
•	Configurations for NameNode:
参数	值	Notes
dfs.namenode.name.dir	在本地文件系统所在的NameNode的存储空间和持续化处理日志	如果这是一个以逗号分隔的目录列表，然后将名称表被复制的所有目录，以备不时之需。
dfs.namenode.hosts
/dfs.namenode.hosts.exclude	Datanodes
permitted/excluded列表	如有必要，可以使用这些文件来控制允许数据节点的列表
dfs.blocksize	268435456	大型的文件系统HDFS块大小为256MB
dfs.namenode.handler.count	100	设置更多的namenode线程，处理从datanode发出的大量RPC请求
•	Configurations for DataNode:
Parameter	Value	Notes
dfs.datanode.data.dir	逗号分隔的一个DataNode上，它应该保存它的块的本地文件系统的路径列表	如果这是一个以逗号分隔的目录列表，那么数据将被存储在所有命名的目录，通常在不同的设备。

<configuration>
					<!--指定hdfs的nameservice为ns1，需要和core-site.xml中的保持一致 -->
					<property>
						<name>dfs.nameservices</name>
						<value>ns1</value>
					</property>
					<!-- ns1下面有两个NameNode，分别是nn1，nn2 -->
					<property>
						<name>dfs.ha.namenodes.ns1</name>
						<value>nn1,nn2</value>
					</property>
					<!-- nn1的RPC通信地址 -->
					<property>
						<name>dfs.namenode.rpc-address.ns1.nn1</name>
						<value>hadoop01:9000</value>
					</property>
					<!-- nn1的http通信地址 -->
					<property>
						<name>dfs.namenode.http-address.ns1.nn1</name>
						<value>hadoop01:50070</value>
					</property>
					<!-- nn2的RPC通信地址 -->
					<property>
						<name>dfs.namenode.rpc-address.ns1.nn2</name>
						<value>hadoop02:9000</value>
					</property>
					<!-- nn2的http通信地址 -->
					<property>
						<name>dfs.namenode.http-address.ns1.nn2</name>
						<value>hadoop02:50070</value>
					</property>
					<!-- 指定NameNode的元数据在JournalNode上的存放位置 -->
					<property>
						<name>dfs.namenode.shared.edits.dir</name>
						<value>qjournal://hadoop05:8485;hadoop06:8485;hadoop07:8485/ns1</value>
					</property>
					<!-- 指定JournalNode在本地磁盘存放数据的位置 -->
					<property>
						<name>dfs.journalnode.edits.dir</name>
						<value>/home/hadoop/software/hadoop-2.7.1/journal</value>
					</property>
					<!-- 开启NameNode失败自动切换 -->
					<property>
						<name>dfs.ha.automatic-failover.enabled</name>
						<value>true</value>
					</property>
					<!-- 配置失败自动切换实现方式 -->
					<property>
						<name>dfs.client.failover.proxy.provider.ns1</name>
						<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
					</property>
					<!-- 配置隔离机制方法，多个机制用换行分割，即每个机制暂用一行-->
					<property>
						<name>dfs.ha.fencing.methods</name>
						<value>
							sshfence
							shell(/bin/true)
						</value>
					</property>
					<!-- 使用sshfence隔离机制时需要ssh免登陆 -->
					<property>
						<name>dfs.ha.fencing.ssh.private-key-files</name>
						<value>/home/hadoop/.ssh/id_dsa</value>
					</property>
					<!-- 配置sshfence隔离机制超时时间 -->
					<property>
						<name>dfs.ha.fencing.ssh.connect-timeout</name>
						<value>30000</value>
					</property>
</configuration>
(5)、修改mapred-site.xml
mapred-site.xml文件是由mapred-site	.xml. template文件修改而来
执行：	mv mapred-site.xml.template mapred-site.xml
•	配置 MapReduce 应用程序:
参数	值	备注
mapreduce.framework.name	yarn	执行框架设置为 Hadoop YARN.
mapreduce.map.memory.mb	1536	对maps更大的资源限制的.
mapreduce.map.java.opts	-Xmx1024M	maps 中对jvm child设置更大的堆大小
mapreduce.reduce.memory.mb	3072	设置 reduces对于较大的资源限制
mapreduce.reduce.java.opts	-Xmx2560M	reduces对 child jvms  Larger heap-size 设置
mapreduce.task.io.sort.mb	512	更高的内存限制，而对数据进行排序的效率。
mapreduce.task.io.sort.factor	100	在文件排序中更多的流合并为一次
mapreduce.reduce.shuffle.parallelcopies	50	 通过reduces从非常多的map中读取较多的平行副本
•	配置MapReduce的JobHistory服务器：
Parameter	Value	Notes
mapreduce.jobhistory.address	MapReduce JobHistory Server host:port	默认端口号 10020.
mapreduce.jobhistory.webapp.address	MapReduce JobHistory Server Web UIhost:port	默认端口号 19888.
mapreduce.jobhistory.intermediate-done-dir	/mr-history/tmp	在历史文件被写入由MapReduce作业
mapreduce.jobhistory.done-dir	/mr-history/done	目录中的历史文件是由MR JobHistory Server管理。
指定MR运行在Yarn上：
<configuration>
        <property>
                <name>mapreduce.framework.name</name>
                <value>yarn</value>
        </property>
</configuration>

(6)、修改yarn-site.xml文件
•	Configurations for ResourceManager and NodeManager:
参数	值	备注
yarn.acl.enable	true /false	启用ACL的？默认为false。
yarn.admin.acl	Admin ACL	访问控制列表，在群集上设置管理员。 ACL是为逗号分隔usersspacecomma分隔组。默认为*特殊值这意味着任何人。只是空间的特殊值意味着没有人进入。
yarn.log-aggregation-enable	false	配置来启用或禁用日志聚合

•	Configurations for ResourceManager:
参数	值	备注
yarn.resourcemanager.address	客户端对ResourceManager主机通过 host:port 提交作业	host:port
yarn.resourcemanager.scheduler.address	ApplicationMasters 通过ResourceManager 主机访问host:port 跟踪调度程序获资源	host:port
yarn.resourcemanager.resource-tracker.address	NodeManagers通过ResourceManager主机访问 host:port 	host:port
yarn.resourcemanager.admin.address	管理命令通过ResourceManager 主机访问host:port	host:port
yarn.resourcemanager.webapp.address	ResourceManager web页面host:port.	host:port
yarn.resourcemanager.scheduler.class	ResourceManager 调度类（Scheduler class）	CapacityScheduler（推荐），FairScheduler（也推荐），orFifoScheduler
yarn.scheduler.minimum-allocation-mb	每个容器内存最低限额分配到的资源管理器要求	I以MB为单位
yarn.scheduler.maximum-allocation-mb	资源管理器分配给每个容器的内存最大限制	以MB为单位
yarn.resourcemanager.nodes.include-path
 /yarn.resourcemanager.nodes.exclude-path	NodeManagers 的permitted/excluded列表	如有必要，可使用这些文件来控制允许NodeManagers列




•	配置 NodeManager:
参数	值	备注
yarn.nodemanager.resource.
memory-mb	givenNodeManager即资源的可用物理内存，以MB为单位	定义在节点管理器总的可用资源，以提供给运行容器
yarn.nodemanager.vmem-pmem-ratio	最大比率为一些任务的虚拟内存使用量可能会超过物理内存率	每个任务的虚拟内存的使用可以通过这个比例超过了
物理内存的限制。虚拟内存的使用上的节点管理器任
务的总量可以通过这个比率超过其物理内存的使用。
yarn.nodemanager.local-dirs	数据写入本地文件系统路径的列表用逗号分隔	多条存储路径可以提高磁盘的读写速度
yarn.nodemanager.log-dirs	本地文件系统日志路径的列表逗号分隔。	多条存储路径可以提高磁盘的读写速度
yarn.nodemanager.log.retain
-seconds	10800	如果日志聚合被禁用。默认的时间（以秒为单位）保
留在节点管理器只适用日志文件，
yarn.nodemanager.remote
-app-log-dir	/logs	HDFS目录下的应用程序日志移动应用上完成。需要
设置相应的权限。仅适用日志聚合功能。
yarn.nodemanager.remote
-app-log-dir-suffix	logs	后缀追加到远程日志目录。日志将被汇总到 ${yarn.nodemanager.remote-app-log-dir}/${user}/
${thisParam} 仅适用日志聚合功能。
yarn.nodemanager.aux
-services	mapreduce_shuffle	Shuffle service 需要加以设置的Map Reduce的应
用程序服务。



•	Configurations for History Server (Needs to be moved elsewhere):

参数	值	备注
yarn.log-aggregation.retain-seconds	-1	如何长期保持聚集日志删除之前。 -1禁用。请注意，设置这个太小了，你将名称节点的垃圾邮件
yarn.log-aggregation.retain-check-interval-seconds	-1	检查汇总的日志保留的时间。如果设置为0或负值，则该值被计算为十分之一的聚合日志保留时间。请注意，设置这个太小了，你将称为名称节点的垃圾邮件。
<!-- 开启RM高可靠 -->
	<property>
		<name>yarn.resourcemanager.ha.enabled</name>
		<value>true</value>
	</property>
<!-- 指定RM的cluster id -->
	<property>
	   <name>yarn.resourcemanager.cluster-id</name>
	   <value>yrc</value>
	</property>
<!-- 指定RM的名字 -->
	<property>
	   <name>yarn.resourcemanager.ha.rm-ids</name>
	   <value>rm1,rm2</value>
	</property>
<!-- 分别指定RM的地址 -->
	<property>
	   <name>yarn.resourcemanager.hostname.rm1</name>
	   <value>hadoop03</value>
	</property>
	<property>
	   <name>yarn.resourcemanager.hostname.rm2</name>
	   <value>hadoop04</value>
	</property>
<!-- 指定zk集群地址 -->
	<property>
	   <name>yarn.resourcemanager.zk-address</name>
	   <value>hadoop05:2181,hadoop06:2181,hadoop07:2181</value>
	</property>
	<property>
	   <name>yarn.nodemanager.aux-services</name>
	   <value>mapreduce_shuffle</value>
	</property>

(7)、修改slaves
	在slaves文件中做如下修改：
			hadoop05
hadoop06
hadoop07
(8)、将在hadoop01上配置完成的hadoop-2.7.1拷贝到其他服务器上
scp -r /home/hadoop/software/hadoop-2.7.1
hadoop02@ hadoop:/home/hadoop/software/
(9)、配置hadoop环境变量
·修改：vim /etc/profile
·将hadoop的bin目录与sbin目录一起添加到环境变量中去
#hadoop_home
export HADOOP_HOME=/home/hadoop/software/hadoop-2.7.0

#enviroment parameter
export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
·生效：source /etc/profile
·并在其他服务器上也如此配置

(10)、启动Zookeeper
在hadoop05，hadoop06，hadoop07上启动
·进入bin目录：cd /home/hadoop/software/zookeeper-3.4.6/bin
·启动Zookeeper：./zkServer.sh start
·查看Zookeeper状态：./zkServer.sh status；一个leader，两个follower

(11)、启动journalnode
在hadoop05、hadoop06、hadoop07上启动
·进入sbin目录：cd /home/hadoop/software/hadoop-2.7.1/sbin/
·启动journalnode：./hadoop-daemon.sh start journalnode
·jps进行检测

(12)、初始化hadoop-2.7.1
·	在hadoop01上初始化hadoop-2.7.1：./hadoop namenode –format，出现format  success成功
·	让hadoop02共享tmp下的文件数据：
scp -r tmp/ hadoop02:/hadoop/hadoop-2.7.1/

(13)、格式化ZK（在hadoop01上执行）
·	格式化Zookeeper：hdfs zkfc -formatZK

(14)、启动HDFS（hadoop01执行）
·	输入命令：sbin/start-dfs.sh

(15)、启动YARN（hadoop03执行）
·	输入命令：sbin/start-yarn.sh

(16)、通过浏览器访问HDFS和Yarn，查看节点数
·	访问hadoop01
http:// 172.16.112.113:50070
NameNode ''''hadoop01:9000'''' (active)
·	访问hadoop02
http:// 172.16.112.114:50070
NameNode ''''itcast02:9000'''' (standby)
·	访问hadoop03的Yarn：
http:// 172.16.112.115:8088


如上为配置High Availablity with QJM的方法，也可以配置NFS代替QJM，
·配置 High Availablity with NFS
（1）、检查NFS包是否已经安装
[root@h1 ~]# rpm -qa | grep nfs
nfs-utils-1.2.2-7.el6.i686
nfs4-acl-tools-0.3.3-5.el6.i686
nfs-utils-lib-1.1.5-1.el6.i686
检查到已经安装到系统中了
（2）、检查rpcbind包是否已经安装
[root@h1 ~]# rpm -qa | grep rpcbind
rpcbind-0.2.0-8.el6.i686
现在都已经安装到系统中了
如果你的系统显示没有安装，可以使用yum install nfs-utils rpcbind  进行安装，然后配置
（3）、查看一下NFS服务和rpcbind服务是否启动
[root@h1 ~]# service nfs status
rcp.svcgssd  已停
rpc.mountd  已停
nfsd        已停
rpc.rquotad  已停                nfs已经停止了，我们现在应该启动nfs服务
[root@h1 ~]# service rpcbind status
rpcbind (pid  1431)  正在运行…….
（4）、启动服务
[root@h1 ~]# service nfs start
启动NFS服务                   【确定】
关掉NFS配额                   【确定】
启动FNS守护进程               【确定】
启动NFS mountd                【确定】
（5）、设置开机启动
[root@h1 ~]# chkconfig nfs on
[root@h1 ~]# chkconfig rpcbind on
（6）、把/home/grid/目录设置为共享目录
[root@h1 grid]# vim /etc/exports            在exports文件中添加/home/grid *(sync,rw)字符串
/home/grid *(sync,rw)
目录说明：
/home/grid       是NFS要共享的目录
星号             代表所有ip地址
Rw为读写，ro为只读
Sync为立刻写入硬盘，rsync为优先写入缓存
No_root_squas root用户具有根目录的完全管理访问权限（这个如果不配置会造成远程root用户只读）
[root@h1 grid]# cat /etc/exports
/home/grid *(sync,rw)
（7）、重启rpcbind和nfs服务
[root@h1 grid]# service rpcbind restart
停止 rpcbind：                    【确定】
正在启动rpcbind                  【确定】
[root@h1 grid]# service nfs restart
全部启动
注意这里也要关闭防火墙设置
（8）、输出本地挂载点（即master上的共享目录）
[root@h1 grid]# showmount -e localhost
Export list for localhost:
/home/grid *
解释：
/home/grid       是NFS要共享的目录
星号            代表所有ip地址
（9）、客户端h2 h4上配置
登陆h2
[root@h2 ~]# mkdir /nfs_share               在根目标下创建挂载点
[root@h2 ~]# mount -t nfs 192.168.2.102:/home/grid /nfs_share/
在h2上访问h1把/home/grid目录挂载到/ nfs_share/目录下
drwx------.  38 grid hadoop  4096   12月   15 15:00 nfs_share
切换到grid用户进入共享目录查看
[grid@h2 ~]$ cd /nfs_share/
-bash: cd: nfs_share/:  权限不够
报错啦，权限不够，这是为什么呢，经过了激烈的测试，发现是h1中/home/grid目录权限问题
[root@h1 home]# chmod -R 777 grid     为了方便我直接给了全部权限，在h1上操作
[root@h2 /]# mount 192.168.2.102:/home/grid/ /nfs_share/    在h2上重新挂载目录
[root@h2 /]# su – grid                 切换用户
[grid@h2 /]$ cd nfs_share/             ok我们现在可以畅通无阻了
[grid@h2 nfs_share]$ cd .ssh           没有问题进来啦，成功
（10）、测试
在h1的共享目录上创建一个11111111.txt文件，然后登陆h2的挂载点，测试是否能查询到
h1   服务端
[root@h1 grid]# touch 11111111.txt
[root@h1 grid]# ll | grep 11111111.txt
h2   客户端
[grid@h2 nfs_share]$ ll | grep 11111111.txt
-rw-r--r--.  1 root root          0    1月    27 14:27 11111111.txt
（11）、设置开机后自动挂载nfs共享目录
修改fstab文件，这个文件描述了开机后应该挂载哪些挂载点
[root@h2 ~]# vim /etc/fstab                     在最后添加这行命令
192.168.2.102:/home/grid  /nfs_share            nfs     defaults        1 1
[root@h2 ~]# cat /etc/fstab
tmpfs                   /dev/shm                tmpfs   defaults        0 0
devpts                  /dev/pts                devpts  gid=5,mode=620  0 0
sysfs                   /sys                    sysfs   defaults        0 0
proc                    /proc                   proc    defaults        0 0
192.168.2.102:/home/grid  /nfs_share            nfs     defaults        1 1
现在NFS配置成功
（12）、使用NFS共享密钥文件
h2   客户端
[grid@h2 .ssh]$ pwd
/nfs_share/.ssh
[grid@h2 .ssh]$ ln -s authorized_keys /home/grid/.ssh/authorized_keys
这种方式可能会导致软链接文件符号链接的层次过多，创建失败，但会有文件名注意文件名是红色的，这是不正常的，避免的方法是都使用绝对路径
还有另一种方法
[grid@h2 .ssh]$ cd ~/.ssh/
[grid@h2 .ssh]$ ln -s /nfs_share/.ssh/authorized_keys authorized_keys
authorized_keys -> /nfs_share/.ssh/authorized_keys
第一个authorized_keys指的是h2上的，第二个authorized_keys指的是h1上的，注意区分
我们用h1的authorized_keys文件来创建h2上authorized_keys文件软链接
注意如果原来h2上就有/home/grid/.ssh/authorized_keys文件需要先删除在创建
rm -rf /home/grid/.ssh/authorized_keys
我们在h2上看一下h1的authorized_keys文件内容
[grid@h2 .ssh]$ cat /nfs_share/.ssh/authorized_keys
ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAr6+D01KKqeMUrkyakulV3su+9RU+jJ6sNJMlydxFq38oGBsJBwcskVL/I9ds7vE5g7coP+cMzgtRyj1ns+elgF0g3/uhtSerad4QdWXVLZgUjyUxijkm+nI3SSdwLihzsNNgH4GzeKX3HQAH/7S+rLoZSBPi//w9HYfO6VeXdo7N2lkvUxNW2z/h7JuYPMEqiaOIWAeLK7AJXhjJaeJkZh/ccGuEx4uBLRxqce5zjbNsFapoD2bact1w80a7mrgzAN3cVcQuQPzmpdj750negxMtai+QRmPDlSx2ZXtbarI4opSVmBiqpY84PJ/h9m5wptQ3hg/1XIxv4gyqwLSxZw== grid@h4
ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEA5iKGfOGKh3d8BYr4vkkNaEtZkxCbBzBn6pfD0n3h82/1f9PwEtT4CEgqzBssYvQ2Nbc6dUy2NbDD9j5dIwQENS/fAJDwccdiJjEYMo5+o4ocPABx6OVM0r9nsUkyU7bxeHjap3ZUmcC1UvgW5asOsRMl7ePCze+rnt5D5ldZ+VOKh0NgtY2/CST8qXHmedfZFbQSEhIPf5Lh4A6oSoRHTFQbDN4apvf5s7Cm5/NgPiyhU+KbHBz96pNCxkjuOwj69a7kx4AgQYJoYc0T9O6YfjfVy3l1a7N2aJ6jp4SMv0GaohgzIrBNXwoFK6skuyf10yIxvNlGzkhTYK9GS9hjJw== grid@h2
ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEA5V1lyss14a8aWFEkTk/aBgKHFLMX/XZX/xtXVUqJl8NkTQVLQ37+XLyqvTfrcJSja70diqB3TrwBp3K5eXNxp3EOr6EGHsi0B6D8owsg0bCDhxHGHu8RX8WB4DH9UOv1uPL5BESAPHjuemQuQaQzLagqrnXbrKix8CzdIEgmnOknYiS49q9msnzawqo3luQFRU7MQvAU9UZqkxotrnzHqh0tgjJ3Sq6O6nscA7w//Xmb0JGobVQAFCDJQdn/z1kOq7E5WNhVa8ynF9GOF7cMdppug7Ibw1RZ9cKa+igi1KhhavS5H7XCM64NuGfC87aQE9nz0ysS3Kh8PT5h6zlxfw== grid@h1
查看h2的软链接文件内容是不是已经链过去了
[grid@h2 .ssh]$ cat authorized_keys
ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAr6+D01KKqeMUrkyakulV3su+9RU+jJ6sNJMlydxFq38oGBsJBwcskVL/I9ds7vE5g7coP+cMzgtRyj1ns+elgF0g3/uhtSerad4QdWXVLZgUjyUxijkm+nI3SSdwLihzsNNgH4GzeKX3HQAH/7S+rLoZSBPi//w9HYfO6VeXdo7N2lkvUxNW2z/h7JuYPMEqiaOIWAeLK7AJXhjJaeJkZh/ccGuEx4uBLRxqce5zjbNsFapoD2bact1w80a7mrgzAN3cVcQuQPzmpdj750negxMtai+QRmPDlSx2ZXtbarI4opSVmBiqpY84PJ/h9m5wptQ3hg/1XIxv4gyqwLSxZw== grid@h4
ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEA5iKGfOGKh3d8BYr4vkkNaEtZkxCbBzBn6pfD0n3h82/1f9PwEtT4CEgqzBssYvQ2Nbc6dUy2NbDD9j5dIwQENS/fAJDwccdiJjEYMo5+o4ocPABx6OVM0r9nsUkyU7bxeHjap3ZUmcC1UvgW5asOsRMl7ePCze+rnt5D5ldZ+VOKh0NgtY2/CST8qXHmedfZFbQSEhIPf5Lh4A6oSoRHTFQbDN4apvf5s7Cm5/NgPiyhU+KbHBz96pNCxkjuOwj69a7kx4AgQYJoYc0T9O6YfjfVy3l1a7N2aJ6jp4SMv0GaohgzIrBNXwoFK6skuyf10yIxvNlGzkhTYK9GS9hjJw== grid@h2
ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEA5V1lyss14a8aWFEkTk/aBgKHFLMX/XZX/xtXVUqJl8NkTQVLQ37+XLyqvTfrcJSja70diqB3TrwBp3K5eXNxp3EOr6EGHsi0B6D8owsg0bCDhxHGHu8RX8WB4DH9UOv1uPL5BESAPHjuemQuQaQzLagqrnXbrKix8CzdIEgmnOknYiS49q9msnzawqo3luQFRU7MQvAU9UZqkxotrnzHqh0tgjJ3Sq6O6nscA7w//Xmb0JGobVQAFCDJQdn/z1kOq7E5WNhVa8ynF9GOF7cMdppug7Ibw1RZ9cKa+igi1KhhavS5H7XCM64NuGfC87aQE9nz0ysS3Kh8PT5h6zlxfw== grid@h1
看一模一样
在H4节点上共享密钥文件
h4
[root@h4 ~]# mkdir /nfs_share                      在根目标下创建挂载点
[root@h4 ~]# mount -t nfs 192.168.2.102:/home/grid /nfs_share/
在h4上访问h1把/home/grid目录挂载到/ nfs_share/目录下
[root@h4 ~]# su – grid          切换到grid用户
[grid@h4 /]$ cd nfs_share/.ssh/   我们可以成功进入共享目录来访问h1中的文件
修改fstab文件，这个文件描述了开机后应该挂载哪些挂载点
[root@h4 ruby]# vim /etc/fstab
tmpfs                   /dev/shm                tmpfs   defaults        0 0
devpts                  /dev/pts                devpts  gid=5,mode=620  0 0
sysfs                   /sys                    sysfs   defaults        0 0
proc                    /proc                   proc    defaults        0 0
192.168.2.102:/home/grid  /nfs_share            nfs     defaults        1 1
在最后添加红色字符串一行，这样在重启时系统就会自动挂载NFS共享目录
[grid@h4 .ssh]$ cd ~/.ssh/      进入h4的.ssh目录
[grid@h4 .ssh]$ rm -rf authorized_keys    发现原来存在authorized_keys文件顾删除
[grid@h4 .ssh]$ ln -s /nfs_share/.ssh/authorized_keys ~/.ssh/authorized_keys
authorized_keys -> /nfs_share/.ssh/authorized_keys  软链接文件已经生成
[grid@h4 .ssh]$ cat authorized_keys               查看软链接文件内容
ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAr6+D01KKqeMUrkyakulV3su+9RU+jJ6sNJMlydxFq38oGBsJBwcskVL/I9ds7vE5g7coP+cMzgtRyj1ns+elgF0g3/uhtSerad4QdWXVLZgUjyUxijkm+nI3SSdwLihzsNNgH4GzeKX3HQAH/7S+rLoZSBPi//w9HYfO6VeXdo7N2lkvUxNW2z/h7JuYPMEqiaOIWAeLK7AJXhjJaeJkZh/ccGuEx4uBLRxqce5zjbNsFapoD2bact1w80a7mrgzAN3cVcQuQPzmpdj750negxMtai+QRmPDlSx2ZXtbarI4opSVmBiqpY84PJ/h9m5wptQ3hg/1XIxv4gyqwLSxZw== grid@h4
ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEA5iKGfOGKh3d8BYr4vkkNaEtZkxCbBzBn6pfD0n3h82/1f9PwEtT4CEgqzBssYvQ2Nbc6dUy2NbDD9j5dIwQENS/fAJDwccdiJjEYMo5+o4ocPABx6OVM0r9nsUkyU7bxeHjap3ZUmcC1UvgW5asOsRMl7ePCze+rnt5D5ldZ+VOKh0NgtY2/CST8qXHmedfZFbQSEhIPf5Lh4A6oSoRHTFQbDN4apvf5s7Cm5/NgPiyhU+KbHBz96pNCxkjuOwj69a7kx4AgQYJoYc0T9O6YfjfVy3l1a7N2aJ6jp4SMv0GaohgzIrBNXwoFK6skuyf10yIxvNlGzkhTYK9GS9hjJw== grid@h2
ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEA5V1lyss14a8aWFEkTk/aBgKHFLMX/XZX/xtXVUqJl8NkTQVLQ37+XLyqvTfrcJSja70diqB3TrwBp3K5eXNxp3EOr6EGHsi0B6D8owsg0bCDhxHGHu8RX8WB4DH9UOv1uPL5BESAPHjuemQuQaQzLagqrnXbrKix8CzdIEgmnOknYiS49q9msnzawqo3luQFRU7MQvAU9UZqkxotrnzHqh0tgjJ3Sq6O6nscA7w//Xmb0JGobVQAFCDJQdn/z1kOq7E5WNhVa8ynF9GOF7cMdppug7Ibw1RZ9cKa+igi1KhhavS5H7XCM64NuGfC87aQE9nz0ysS3Kh8PT5h6zlxfw== grid@h1
通过对比知道h1的authorized_keys授权文件和h2 h4上的软链接文件内容都是一模一样的，到此我们就可以免密码连入了

4.6 sqoop的编译与安装
·sqoop编译部分
安装编译sqoop所需的软件
* asciidoc
* make
* python 2.5+
* xmlto
* tar
* gzip

yum -y install asciidoc
yum -y install make
yum -y install xmlto
yum -y install tar
yum -y install gzip

第一步：解压 sqoop-1.4.4.tar.gz 文件到 /opt/software目录下(在该目录下将生成 sqoop-1.4.4 文件夹)
cd /opt/software
tar -xvf sqoop-1.4.4.tar.gz

第二步：cd 到 sqoop-1.4.4 文件夹, 修改build.xml文件中指定的hadoop版本为2.4.1(其他不变，其他相关版本尝试修改好像有问题，提示下载不到相关版本的文件)
cd /opt/software/sqoop-1.4.4

vi build.xml

    <elseif>
      <equals arg1="${hadoopversion}" arg2="200" />
      <then>
        <property name="hadoop.version" value="2.4.1" />
        <property name="hbase.version" value="0.94.2" />
        <property name="zookeeper.version" value="3.4.2" />
        <property name="hadoop.version.full" value="2.4.1" />
        <property name="hcatalog.version" value="0.11.0" />
      </then>
    </elseif>

 第三步：运行ant package
[root@funshion-hadoop194 sqoop-1.4.4]# ant package

...

[ivy:resolve] :: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS

BUILD FAILED
/opt/software/sqoop-1.4.4/build.xml:1282: impossible to resolve dependencies:
        resolve failed - see output for details

Total time: 27 seconds


[ivy:resolve]         com.google.protobuf#protobuf-java;2.4.1 by [com.google.protobuf#protobuf-java;2.5.0] in [hadoop200]
        ---------------------------------------------------------------------
        |                  |            modules            ||   artifacts   |
        |       conf       | number| search|dwnlded|evicted|| number|dwnlded|
        ---------------------------------------------------------------------
        |     hadoop200    |  154  |   59  |   58  |   37  ||  120  |   48  |
        ---------------------------------------------------------------------
[ivy:resolve]
[ivy:resolve] :: problems summary ::
[ivy:resolve] :::: WARNINGS
[ivy:resolve]                 [FAILED     ] org.mortbay.jetty#jetty;6.1.26!jetty.zip:  (0ms)
[ivy:resolve]         ==== fs: tried
[ivy:resolve]           /root/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.zip
[ivy:resolve]         ==== apache-snapshot: tried
[ivy:resolve]           https://repository.apache.org/co ... 26/jetty-6.1.26.zip
[ivy:resolve]         ==== datanucleus: tried
[ivy:resolve]           http://www.datanucleus.org/downl ... 26/jetty-6.1.26.zip
[ivy:resolve]         ==== cloudera-releases: tried
[ivy:resolve]           https://repository.cloudera.com/ ... 26/jetty-6.1.26.zip
[ivy:resolve]         ==== cloudera-staging: tried
[ivy:resolve]           https://repository.cloudera.com/ ... 26/jetty-6.1.26.zip
[ivy:resolve]         ==== maven2: tried
[ivy:resolve]           http://repo1.maven.org/maven2/or ... 26/jetty-6.1.26.zip
[ivy:resolve]                 ::::::::::::::::::::::::::::::::::::::::::::::
[ivy:resolve]                 ::              FAILED DOWNLOADS            ::
[ivy:resolve]                 :: ^ see resolution messages for details  ^ ::
[ivy:resolve]                 ::::::::::::::::::::::::::::::::::::::::::::::
[ivy:resolve]                 :: org.mortbay.jetty#jetty;6.1.26!jetty.zip
[ivy:resolve]                 ::::::::::::::::::::::::::::::::::::::::::::::
[ivy:resolve]
[ivy:resolve] :: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS

[ivy:resolve]         io.netty#netty;3.4.0.Final by [io.netty#netty;3.6.2.Final] in [hadoop200test]
[ivy:resolve]         asm#asm;[3.0, 4.0) by [asm#asm;3.1] in [hadoop200test]
[ivy:resolve]         asm#asm;3.1 by [asm#asm;3.2] in [hadoop200test]
[ivy:resolve]         com.google.protobuf#protobuf-java;2.4.1 by [com.google.protobuf#protobuf-java;2.5.0] in [hadoop200test]
        ---------------------------------------------------------------------
        |                  |            modules            ||   artifacts   |
        |       conf       | number| search|dwnlded|evicted|| number|dwnlded|
        ---------------------------------------------------------------------
        |   hadoop200test  |  156  |   0   |   0   |   38  ||  121  |   0   |
        ---------------------------------------------------------------------

-- 错误1（如上）解决方法：单独下载 jetty-6.1.26.zip 文件到 /root/.m2/repository/org/mortbay/jetty/jetty/6.1.26/目录下，解决。

------------------------------------------------------------------------------
[ivy:resolve]         com.google.protobuf#protobuf-java;2.4.1 by [com.google.protobuf#protobuf-java;2.5.0] in [hadoop200test]
        ---------------------------------------------------------------------
        |                  |            modules            ||   artifacts   |
        |       conf       | number| search|dwnlded|evicted|| number|dwnlded|
        ---------------------------------------------------------------------
        |   hadoop200test  |  156  |   2   |   2   |   38  ||  121  |   2   |
        ---------------------------------------------------------------------

ivy-retrieve-hadoop-test:
[ivy:retrieve] :: retrieving :: com.cloudera.sqoop#sqoop [sync]
[ivy:retrieve]         confs: [hadoop200test]
[ivy:retrieve]         121 artifacts copied, 0 already retrieved (113206kB/376ms)

compile-test:
    [mkdir] Created dir: /opt/software/sqoop-1.4.4/build/test/classes
    [javac] /opt/software/sqoop-1.4.4/build.xml:433: warning: ''''includeantruntime'''' was not set, defaulting to build.sysclasspath=last; set to false for repeatable builds
    [javac] Compiling 130 source files to /opt/software/sqoop-1.4.4/build/test/classes
    [javac] /opt/software/sqoop-1.4.4/src/test/org/apache/sqoop/TestExportUsingProcedure.java:244: repeat(java.lang.String,int) in org.apache.commons.lang.StringUtils cannot be applied to (java.lang.String,java.lang.String,int)
    [javac]     sql.append(StringUtils.repeat("?", ",  ",
    [javac]                           ^
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
    [javac] 1 error

BUILD FAILED
/opt/software/sqoop-1.4.4/build.xml:433: Compile failed; see the compiler error output for details.

Total time: 1 minute 9 seconds

-- 错误2（如上），解决方法：
-- 第一步：
vi +433 /opt/software/sqoop-1.4.4/build.xml

        debug="${javac.debug}">

-- 将第433行修改为如下两行：

        debug="${javac.debug}"
        includeantruntime="on">

-- 第二步：vi +244 /opt/software/sqoop-1.4.4/src/test/org/apache/sqoop/TestExportUsingProcedure.java
        sql.append(StringUtils.repeat("?", ",  ",

-- 将第244行修改为如下：
        sql.append(StringUtils.repeat("?,",

-- 继续重新运行 ant package，最后我们将看到：BUILD SUCCESSFUL　字样，表示编译成功。

...

     [move] Moving 1 file to /opt/software/sqoop-1.4.4
    [mkdir] Created dir: /opt/software/sqoop-1.4.4/build/sqoop-1.4.4.bin__hadoop-2.4.1/lib
     [copy] Copying 10 files to /opt/software/sqoop-1.4.4/build/sqoop-1.4.4.bin__hadoop-2.4.1/lib
     [copy] Copying 2 files to /opt/software/sqoop-1.4.4/build/sqoop-1.4.4.bin__hadoop-2.4.1/lib
     [copy] Copying 115 files to /opt/software/sqoop-1.4.4/build/sqoop-1.4.4.bin__hadoop-2.4.1/docs
     [copy] Copying 14 files to /opt/software/sqoop-1.4.4/build/sqoop-1.4.4.bin__hadoop-2.4.1/docs/man
     [copy] Copying 13 files to /opt/software/sqoop-1.4.4/build/sqoop-1.4.4.bin__hadoop-2.4.1/bin
     [copy] Copying 1 file to /opt/software/sqoop-1.4.4/build/sqoop-1.4.4.bin__hadoop-2.4.1/conf

BUILD SUCCESSFUL

-- 然后的/opt/software/sqoop-1.4.4/build目录下将生成 sqoop-1.4.4.bin__hadoop-2.4.1的文件夹，这就是我们的安装文件，将其压缩：
cd /opt/software/sqoop-1.4.4/build
tar -cvf sqoop-1.4.4.bin__hadoop-2.4.1.tar.gz ./sqoop-1.4.4.bin__hadoop-2.4.1

sqoop-1.4.4.bin__hadoop-2.4.1.tar.gz文件就是我们需要的sqoop安装包了。

-- 安装：
将sqoop-1.4.4.bin__hadoop-2.4.1.tar.gz解压并cp到/usr/local
tar -xvf sqoop-1.4.4.bin__hadoop-2.4.1.tar.gz
mv ./sqoop-1.4.4.bin__hadoop-2.4.1 /usr/local
chown -R hadoop.hadoop /usr/local/sqoop-1.4.4.bin__hadoop-2.4.1
ln -s /usr/local/sqoop-1.4.4.bin__hadoop-2.4.1 /usr/local/sqoop

vi ~/.bash_profile  -- 添加如下两行：
export SQOOP_HOME=/usr/local/sqoop
export PATH=$PATH:${SQOOP_HOME}/bin

source ~/.bash_profile

cd /usr/local/sqoop/conf
cp sqoop-env-template.sh sqoop-env.sh  -- 将sqoop-env-template.sh文件复制为sqoop-env.sh

vi sqoop-env.sh  -- 编辑刚才复制的文件sqoop-env.sh，添加如下三行（如果没有安装hive的话，将最后一行屏蔽）
export HADOOP_COMMON_HOME=/usr/local/hadoop
export HADOOP_MAPRED_HOME=/usr/local/hadoop/share/hadoop/mapreduce
export HIVE_HOME=/usr/local/hive

-- 编译成功后，测试(看能否访问mysql，测试前记得将mysql的jdbc包放到 $SQOOP_HOME/lib目录下)：
-- 我的mysql的jdbc包是：mysql-connector-java-5.1.30-bin.jar

sqoop list-databases --connect jdbc:mysql://funshion-hadoop32:3306/ --username hive --password bee56915

·sqoop安装部分
(1)、解压缩sqoop-1.4.6.tar.gz按照包
	tar –zxvf sqoop-1.4.6.tar.gz

(2)、sqoop配置
将$SQOOP_HOME配置在/etc/profile中
并且将$SQOOP_HOME/bin目录添加在Path中


(3)、将Mysql数据库链接驱动，放置在$	SQOOP_HOME/bin目录下

4.7 Mysql安装
Linux安装mysql服务分两种安装方法：
①源码安装，优点是安装包比较小，只有十多M，缺点是安装依赖的库多，安装编译时间长，安装步骤复杂容易出错；
②使用官方编译好的二进制文件安装，优点是安装速度快，安装步骤简单，缺点是安装包很大，300M左右。以下介绍linux使用官方编译好的二进制包安装mysql。

工具/原料
·mysql-5.6.17-linux-glibc2.5-i686.tar.gz
·mysql-5.6.17-linux-glibc2.5-x86_64.tar.gz
·linux系统，32位、64位均可
方法/步骤
1、到mysql官网下载mysql编译好的二进制安装包，在下载页面Select Platform:选项选择linux-generic，然后把页面拉到底部，64位系统下载Linux - Generic (glibc 2.5) (x86, 64-bit)，32位系统下载Linux - Generic (glibc 2.5) (x86, 32-bit)


2、解压32位安装包:
进入安装包所在目录，执行命令：tar mysql-5.6.17-linux-glibc2.5-i686.tar.gz

3、复制解压后的mysql目录到系统的本地软件目录:
执行命令：cp mysql-5.6.17-linux-glibc2.5-i686 /usr/local/mysql -r
注意：目录结尾不要加/

4、添加系统mysql组和mysql用户：
执行命令：groupadd mysql和useradd -r -g mysql mysql


5、安装数据库：
进入安装mysql软件目录：执行命令 cd /usr/local/mysql
修改当前目录拥有者为mysql用户：执行命令 chown -R mysql:mysql ./
安装数据库：执行命令 ./scripts/mysql_install_db --user=mysql
修改当前目录拥有者为root用户：执行命令 chown -R root:root ./
修改当前data目录拥有者为mysql用户：执行命令 chown -R mysql:mysql data
到此数据库安装完毕

6、启动mysql服务和添加开机启动mysql服务：
添加开机启动：执行命令cp support-files/mysql.server /etc/init.d/mysql，把启动脚本放到开机初始化目录
启动mysql服务：执行命令service mysql start
执行命令：ps -ef|grep mysql 看到mysql服务说明启动成功，如图

7、修改mysql的root用户密码，root初始密码为空的：
执行命令：./bin/mysqladmin -u root password ''''密码''''

8、把mysql客户端放到默认路径：
ln -s /usr/local/mysql/bin/mysql /usr/local/bin/mysql
注意：建议使用软链过去，不要直接包文件复制，便于系统安装多个版本的mysql


4.8 HBASE安装
Hbase的完全分布式安装概述：
         1. 配置hosts，确保涉及的主机名均可解析为ip
         2. 编辑hbase-env.xml
         3. 编辑hbase-site.xml
         4. 编辑regionservers文件，文件默认内容是localhost
/home/grid/hbase/conf/regionservers，将所有的slavenode添加到这个文件
         5. Hbase复制到其他节点
         6. 启动Hbase
         7. 验证

选择Hadoop和Hbase版本不同，可能会有不兼容的情况，
例如Hadoop 0.20
解决版本、jar包冲突：
1)删除hbase/lib/hadoop-core-0.20-append-r1056497.jar(备份到其它路径，以备万一)；
2)拷贝hadoop/hadoop-core-0.20.203.0.jar(注意是hadoop根目录下)，hadoop/lib/commons-collections-3.2.1.jar，hadoop/lib/commons-configuration-1.6.jar到hbase/lib下

Setp 1 下载解压hbase


Step 2 修改配置文件
第一个文件：/home/zhang/hbase/hbase-0.94.16/conf/hbase-env.sh






Step 3 设置环境变量


Step 4 配置/hbase/hbase-0.94.16/conf/hbase-site.xml
模板文件路径：~/hbase/hbase-0.94.16/src/main/resources/hbase-default.xml
拷贝需要的内容
添加修改到hbase-site.xml文件，内容如下：


hbase.rootdir ：存放数据目录
    hbase.rootdir
    hdfs://node01:9000/hbase


打开分布模式：
    hbase.cluster.distributed
    true

设置临时文件目录：
    hbase.tmp.dir
    /home/criss/hbase/tmp

添加Zookeeper的节点主机名：
    hbase.zookeeper.quorum
    node01,node02,node03

    hbase.zookeeper.property.dataDir
    /home/criss/hbase/tmp/zookeeper
    Property from ZooKeeper''''s config zoo.cfg.
    The directory where the snapshot is stored.

Step 5 编辑/home/grid/hbase/conf/regionservers，将所有的slavenode添加到这个文件


我在hbase-site.xml 没有配置hmater，所以这里吧3台机都添加进去了
Step6将Hbase拷贝到其他节点机并对其他节点机配置环境变量
scp -r hbase/ node03:/home/criss/hbase
scp -r hbase/ node02:/home/criss/hbase




Step 7 启动Hbase


Step 8验证HMaster
Node01主机：


验证Node03和Node02主机：


Step 9 测试Hbase shell
Create  ‘test’,’data’
Disable ‘test’
Dorp ‘test’

可以查看下tmp文件夹下生成的内容：

4.9 HIVE安装
Hive两种模式安装
数据仓库工具，可以把Hadoop下的原始结构化数据变成Hive中的表。
　　支持一种与SQL几乎完全相同的语言HiveQL，除了不支持更新、索引和事务。
　　可以看成是从SQL到Map-Reduce的映射器。
　　提供shell、JDBC/ODBC、thrift、Web等接口。


一、内嵌模式安装
　　这样安装的元数据保持在内嵌的Derby数据库中，只能允许一个会话连接，只适用于简单的测试。
1、解压Hive
[coder@h1 ~]$ tar -zxvf hive-0.10.0.tar.gz

2、配置环境变量/etc/profile
　　　　加入Hive的安装目录，并把Hive的bin目录配置到PATH
HIVE_HOME=/home/coder/hive-0.10.0
PATH=$HADOOP_INSTALL/bin:$PIG_INSTALL/bin:$JAVA_HOME/bin:$HIVE_HOME/bin:$PATH
　　　　执行 source /etc/profile命令，使得配置生效

3、新建Hive所需目录
　　　　在HDFS上建立/tmp和/user/hive/warehouse目录，并赋予组用户写权限。这是Hive默认的数据文件存放目录，可以在hive-site.xml文件中配置。

[coder@h1 hadoop-0.20.2]$ bin/hadoop fs -mkdir /tmp
[coder@h1 hadoop-0.20.2]$ bin/hadoop fs -mkdir /user/hive/warehouse
[coder@h1 hadoop-0.20.2]$ bin/hadoop fs -chmod g+w /tmp
[coder@h1 hadoop-0.20.2]$ bin/hadoop fs -chmod g+w /user/hive/warehouse

4、输入hive命令，出现类似下面的内容，说明安装成功。
[coder@h1 hadoop-0.20.2]$ hive
Logging initialized using configuration in jar:file:/home/coder/hive-0.10.0/lib/hive-common-0.10.0.jar!/hive-log4j.properties
Hive history file=/tmp/coder/hive_job_log_coder_201305072118_1272944282.txt
hive>
hive> show tables;
OK
Time taken: 24.479 seconds
hive> exit;


二、独立模式安装

　　支持多用户会话，需要一个独立的元数据库，常用的是使用MySQL作为元数据库。
1、启动MySQL
[root@h1 ~]# service mysqld start
Starting mysqld:  [  OK  ]
[root@h1 ~]#

2、为Hive建立相应的MySQL账号
[root@h1 ~]# mysql
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 2
Server version: 5.1.66 Source distribution

Copyright (c) 2000, 2012, Oracle and/or its affiliates. All rights reserved.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type ''''help;'''' or ''''\h'''' for help. Type ''''\c'''' to clear the current input statement.

mysql> create user ''''hive'''' identified by ''''123456'''';
Query OK, 0 rows affected (0.00 sec)

mysql> GRANT ALL PRIVILEGES ON *.* TO ''''hive''''@''''localhost'''' IDENTIFIED BY ''''123456'''' WITH GRANT OPTION;
Query OK, 0 rows affected (0.00 sec)

mysql> flush privileges;
Query OK, 0 rows affected (0.00 sec)

mysql> exit
Bye
[root@h1 ~]#

然后从客户端用hive账号登陆MySQL

3、建立Hive专用元数据库
mysql>create database hive;

4、配置Hive
　　　　在Hive安装目录的conf目录下，将hive-default.xml.template复制一份命名为：hive-site.xml

　　修改以下内容，配置上mysql数据连接、驱动、用户名和密码

<property>
   <name>javax.jdo.option.ConnectionURL</name>
   <value>jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true</value>
</property>
<property>
   <name>javax.jdo.option.ConnectionDriverName</name>
   <value>com.mysql.jdbc.Driver</value>
</property>
<property>
   <name>javax.jdo.option.ConnectionUserName</name>
   <value>hive</value>
</property>
<property>
   <name>javax.jdo.option.ConnectionPassword</name>
   <value>123456</value>
</property>

5、把mysql的驱动包拷贝到Hive安装路径下的lib目录

6、进入Hive，没报错说明独立模式安装成功
[coder@h1 ~]$ hive
Logging initialized using configuration in jar:file:/home/coder/hive-0.10.0/lib/hive-common-0.10.0.jar!/hive-log4j.properties
Hive history file=/tmp/coder/hive_job_log_coder_201305072212_717503278.txt
hive> show tables;
OK
Time taken: 24.783 seconds
hive> exit;

7、Hive运行示例：
　　Hive提供了一个CLI（Command Line Interface）客户端，我们可以通过CLI进行直观的DDL、DML及SQL操作。以下是CLI使用示例：
[root@192.168.1.111] # 打开Hive客户端
[root@192.168.1.111] $HIVE_HOME/bin/hive
hive>CREATE TABLE tt (
id INT,
name string
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '''',''''
COLLECTION ITEMS TERMINATED BY ''''\n''''
STORED AS TEXTFILE;
hive>select * from tt;
hive>drop table tt;
　　在hive控制台，执行命令成功后会打印如下所求的提示：
OK
Time taken: 5.004 seconds
　　如果有以上提示就证明你的Hive已经安装成功并能运行了。

'', ''#hadoop#'', 3, ''请选择'', 8, ''YC'', ''2019-06-18'', ''2019-06-18'', null, ''1、准备阶段述
·hadoop-2.7.1.tar.gz安装包
·jdk1.6以上版本，这里统一使用jdk1.8版本jdk-8u45-linux-x64.rpm
·CentOS-6.4安装包
2、安装步骤概述
2.1、安装Centos-6.4系统
2.2、安装jdk1.8
2.4、	如若使用64位机器，请编译hadoop-2.7.1文件
2.4、zookeeper安装，单机安装以及集群安装
2.5、关闭linux防火墙，安装已编译好的hadooop安装包以及配置QJM，或者配置High Availability With NFS，验证hadoop是否安装成功
2.6、sqoop的编译与安装
2.7、Mysql安装
2.8、HBASE安装
2.9、HIVE安装
'', null, null, 0, 0, null);
DROP TABLE artical_categories;
CREATE TABLE artical_categories (ID int NOT NULL AUTO_INCREMENT COMMENT ''编号'', CATEGORY_NAME varchar(50) COMMENT ''分类名称'', IS_SHOW varchar(1) COMMENT ''是否首页展示'', SHOW_ORDER int COMMENT ''展示序号'', ARTICAL_COUNT int COMMENT ''文章数量'', introduction varchar(1000), PRIMARY KEY (ID)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=''分类'';
INSERT INTO artical_categories (ID, CATEGORY_NAME, IS_SHOW, SHOW_ORDER, ARTICAL_COUNT, introduction) VALUES (1, ''随笔感悟'', ''N'', null, 0, '''');
INSERT INTO artical_categories (ID, CATEGORY_NAME, IS_SHOW, SHOW_ORDER, ARTICAL_COUNT, introduction) VALUES (2, ''日常积累'', ''Y'', 3, 0, '''');
INSERT INTO artical_categories (ID, CATEGORY_NAME, IS_SHOW, SHOW_ORDER, ARTICAL_COUNT, introduction) VALUES (3, ''智慧生活'', ''N'', null, 0, '''');
INSERT INTO artical_categories (ID, CATEGORY_NAME, IS_SHOW, SHOW_ORDER, ARTICAL_COUNT, introduction) VALUES (4, ''名家佳作'', ''Y'', 2, 0, '''');
INSERT INTO artical_categories (ID, CATEGORY_NAME, IS_SHOW, SHOW_ORDER, ARTICAL_COUNT, introduction) VALUES (5, ''博文转载'', ''Y'', 4, 0, '''');
INSERT INTO artical_categories (ID, CATEGORY_NAME, IS_SHOW, SHOW_ORDER, ARTICAL_COUNT, introduction) VALUES (6, ''天下杂谈'', ''N'', null, 0, '''');
INSERT INTO artical_categories (ID, CATEGORY_NAME, IS_SHOW, SHOW_ORDER, ARTICAL_COUNT, introduction) VALUES (7, ''十个冷笑话'', ''N'', null, 0, '''');
INSERT INTO artical_categories (ID, CATEGORY_NAME, IS_SHOW, SHOW_ORDER, ARTICAL_COUNT, introduction) VALUES (8, ''Java随笔'', ''Y'', 1, 0, '''');
INSERT INTO artical_categories (ID, CATEGORY_NAME, IS_SHOW, SHOW_ORDER, ARTICAL_COUNT, introduction) VALUES (9, ''操作系统'', ''N'', null, 0, '''');
INSERT INTO artical_categories (ID, CATEGORY_NAME, IS_SHOW, SHOW_ORDER, ARTICAL_COUNT, introduction) VALUES (10, ''数据库'', ''N'', null, 0, '''');
INSERT INTO artical_categories (ID, CATEGORY_NAME, IS_SHOW, SHOW_ORDER, ARTICAL_COUNT, introduction) VALUES (11, ''金融行业'', ''N'', null, 0, '''');
DROP TABLE artical_topics;
CREATE TABLE artical_topics (ID int NOT NULL AUTO_INCREMENT COMMENT ''专题编号'', TOPIC_NAME varchar(50) COMMENT ''专题名称'', ARTICAL_COUNT int COMMENT ''内容数量'', introduction varchar(1000), PRIMARY KEY (ID)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=''专题'';
INSERT INTO artical_topics (ID, TOPIC_NAME, ARTICAL_COUNT, introduction) VALUES (1, ''Java基础知识大全'', 0, '''');
INSERT INTO artical_topics (ID, TOPIC_NAME, ARTICAL_COUNT, introduction) VALUES (2, ''分布式开发'', 0, '''');
INSERT INTO artical_topics (ID, TOPIC_NAME, ARTICAL_COUNT, introduction) VALUES (3, ''大数据分析'', 0, '''');
INSERT INTO artical_topics (ID, TOPIC_NAME, ARTICAL_COUNT, introduction) VALUES (4, ''反向代理与负载均衡'', 0, '''');
INSERT INTO artical_topics (ID, TOPIC_NAME, ARTICAL_COUNT, introduction) VALUES (5, ''生活小妙招'', 0, '''');
INSERT INTO artical_topics (ID, TOPIC_NAME, ARTICAL_COUNT, introduction) VALUES (6, ''Spring帝國'', 0, '''');
INSERT INTO artical_topics (ID, TOPIC_NAME, ARTICAL_COUNT, introduction) VALUES (7, ''SpringBoot'', 0, '''');
INSERT INTO artical_topics (ID, TOPIC_NAME, ARTICAL_COUNT, introduction) VALUES (8, ''架构师之路'', 0, '''');
INSERT INTO artical_topics (ID, TOPIC_NAME, ARTICAL_COUNT, introduction) VALUES (9, ''如何快速转型'', 0, '''');
INSERT INTO artical_topics (ID, TOPIC_NAME, ARTICAL_COUNT, introduction) VALUES (10, ''你不知道的数据模型'', 0, '''');
DROP TABLE books;
CREATE TABLE books (ID int NOT NULL AUTO_INCREMENT COMMENT ''序号'', BOOK_NAME varchar(255) COMMENT ''书籍名称'', AUTHOR varchar(255) COMMENT ''作者'', PUBLISH_DATE varchar(20) COMMENT ''发布日期'', URL varchar(255) COMMENT ''书籍所在网络URL'', LOCAL_PATH varchar(255) COMMENT ''本地存放地址'', ADD_DATE varchar(20), PRIMARY KEY (ID)) ENGINE=InnoDB DEFAULT CHARSET=utf8;
INSERT INTO books (ID, BOOK_NAME, AUTHOR, PUBLISH_DATE, URL, LOCAL_PATH, ADD_DATE) VALUES (1, ''普罗旺斯的一年'', ''（英）彼得·梅尔'', ''2011-05-01'', null, ''E:/myblog/普罗旺斯的一年.pdf'', ''2019-06-17'');
INSERT INTO books (ID, BOOK_NAME, AUTHOR, PUBLISH_DATE, URL, LOCAL_PATH, ADD_DATE) VALUES (2, ''不抱怨的世界'', ''威尔 鲍温'', ''2009-04-01'', null, ''E:/myblog/不抱怨的世界.pdf'', ''2019-06-17'');
INSERT INTO books (ID, BOOK_NAME, AUTHOR, PUBLISH_DATE, URL, LOCAL_PATH, ADD_DATE) VALUES (3, ''钢铁是怎样炼成的'', ''保尔·柯察金'', ''1996-10-01'', null, ''E:/myblog/钢铁是怎样炼成的.pdf'', ''2019-06-17'');
INSERT INTO books (ID, BOOK_NAME, AUTHOR, PUBLISH_DATE, URL, LOCAL_PATH, ADD_DATE) VALUES (4, ''平凡的世界'', ''路遥'', ''1986-01-01'', null, ''E:/myblog/平凡的世界.pdf'', ''2019-06-17'');
INSERT INTO books (ID, BOOK_NAME, AUTHOR, PUBLISH_DATE, URL, LOCAL_PATH, ADD_DATE) VALUES (5, ''苏菲的世界'', ''乔斯坦·贾德'', ''1991-01-01'', null, ''E:/myblog/苏菲的世界.pdf'', ''2019-06-17'');
INSERT INTO books (ID, BOOK_NAME, AUTHOR, PUBLISH_DATE, URL, LOCAL_PATH, ADD_DATE) VALUES (6, ''围城'', ''钱钟书'', ''1947-01-01'', null, ''E:/myblog/围城.pdf'', ''2019-06-17'');
INSERT INTO books (ID, BOOK_NAME, AUTHOR, PUBLISH_DATE, URL, LOCAL_PATH, ADD_DATE) VALUES (7, ''普罗旺斯的一年'', ''（英）彼得·梅尔'', ''2011-05-01'', null, ''E:/myblog/普罗旺斯的一年.pdf'', ''2019-06-17'');
INSERT INTO books (ID, BOOK_NAME, AUTHOR, PUBLISH_DATE, URL, LOCAL_PATH, ADD_DATE) VALUES (8, ''不抱怨的世界'', ''威尔 鲍温'', ''2009-04-01'', null, ''E:/myblog/不抱怨的世界.pdf'', ''2019-06-17'');
INSERT INTO books (ID, BOOK_NAME, AUTHOR, PUBLISH_DATE, URL, LOCAL_PATH, ADD_DATE) VALUES (9, ''钢铁是怎样炼成的'', ''保尔·柯察金'', ''1996-10-01'', null, ''E:/myblog/钢铁是怎样炼成的.pdf'', ''2019-06-17'');
INSERT INTO books (ID, BOOK_NAME, AUTHOR, PUBLISH_DATE, URL, LOCAL_PATH, ADD_DATE) VALUES (10, ''平凡的世界'', ''路遥'', ''1986-01-01'', null, ''E:/myblog/平凡的世界.pdf'', ''2019-06-17'');
INSERT INTO books (ID, BOOK_NAME, AUTHOR, PUBLISH_DATE, URL, LOCAL_PATH, ADD_DATE) VALUES (11, ''苏菲的世界'', ''乔斯坦·贾德'', ''1991-01-01'', null, ''E:/myblog/苏菲的世界.pdf'', ''2019-06-17'');
INSERT INTO books (ID, BOOK_NAME, AUTHOR, PUBLISH_DATE, URL, LOCAL_PATH, ADD_DATE) VALUES (12, ''围城'', ''钱钟书'', ''1947-01-01'', null, ''E:/myblog/围城.pdf'', ''2019-06-17'');
DROP TABLE editmd;
CREATE TABLE editmd (id int NOT NULL AUTO_INCREMENT COMMENT ''序号'', content longtext COMMENT ''文本内容'', PRIMARY KEY (id)) ENGINE=InnoDB DEFAULT CHARSET=utf8;
INSERT INTO editmd (id, content) VALUES (1, ''**asdfa
# Markdown语法
## 一、更改字体、大小、颜色
<font face="黑体">黑体</font>  <font face="微软雅黑">微软雅黑</font>  <font face="宋体">宋体</font>  <font face="STCAIYUN">我是华文彩云</font>
<font color=red>我是红色</font>  <font color=#008000>我是绿色</font>  <font color=Blue>我是蓝色</font>
<font size=5>我是尺寸</font>
<font face="黑体" color=green size=5>我是黑体，绿色，尺寸为5</font>
## 二、为文字添加背景色
<table><tr><td bgcolor=green><font face="黑体" size=5>背景色-green</font></td></tr><tr><td bgcolor=yellow>背景色-yellow</td></tr><tr><td bgcolor=blue>背景色-blue</td></tr></table>'');
DROP TABLE enterprise_report;
CREATE TABLE enterprise_report (RPT_NO varchar(30) NOT NULL, RPT_CONTENT text, PRIMARY KEY (RPT_NO)) ENGINE=InnoDB DEFAULT CHARSET=utf8;
DROP TABLE my_info;
CREATE TABLE my_info (ID int NOT NULL AUTO_INCREMENT COMMENT ''编号'', NICKNAME varchar(30) COMMENT ''网名'', WEBNAME varchar(40) COMMENT ''网站名称'', OCCUPATION varchar(80) COMMENT ''职业'', ADDRESS varchar(120) COMMENT ''地址'', EMAIL varchar(60) COMMENT ''邮箱'', WEBSITE varchar(200) COMMENT ''网址'', QQ varchar(20) COMMENT ''QQ号码'', WECHAT varchar(30) COMMENT ''微信号'', WEBROOT varchar(100), PRIMARY KEY (ID)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=''个人信息'';
INSERT INTO my_info (ID, NICKNAME, WEBNAME, OCCUPATION, ADDRESS, EMAIL, WEBSITE, QQ, WECHAT, WEBROOT) VALUES (1, ''骑鱼的猫 | 老干部'', ''老干部的咖啡屋'', ''程序员、软件工程师、艺术家'', ''陕西省-西安市'', ''lihairuizone@sina.com'', ''WWW.NERSSIA.CN'', null, null, ''/myblog'');
DROP TABLE nav_index;
CREATE TABLE nav_index (ID int NOT NULL AUTO_INCREMENT COMMENT ''编号'', NAME varchar(50) COMMENT ''名称'', SHOW_HOMEPAGE varchar(1) COMMENT ''是否首页展示 Y-展示 N/null-不展示'', PRIMARY KEY (ID)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=''首页索引'';
INSERT INTO nav_index (ID, NAME, SHOW_HOMEPAGE) VALUES (1, ''个人随笔'', ''Y'');
INSERT INTO nav_index (ID, NAME, SHOW_HOMEPAGE) VALUES (2, ''美文鉴赏'', ''Y'');
INSERT INTO nav_index (ID, NAME, SHOW_HOMEPAGE) VALUES (3, ''天下杂谈'', ''Y'');
INSERT INTO nav_index (ID, NAME, SHOW_HOMEPAGE) VALUES (4, ''每日一乐'', ''Y'');
INSERT INTO nav_index (ID, NAME, SHOW_HOMEPAGE) VALUES (5, ''技术专栏'', ''Y'');
DROP TABLE online_tools;
CREATE TABLE online_tools (ID int NOT NULL AUTO_INCREMENT COMMENT ''序号'', TOOL_NAME varchar(50) COMMENT ''工具名称'', URL varchar(255) COMMENT ''网址'', INTRODUCE longtext COMMENT ''工具介绍'', ADD_DATE varchar(20) COMMENT ''添加日期'', PRIMARY KEY (ID)) ENGINE=InnoDB DEFAULT CHARSET=utf8;
INSERT INTO online_tools (ID, TOOL_NAME, URL, INTRODUCE, ADD_DATE) VALUES (1, ''程序员在线工具'', ''http://www.ofmonkey.com/'', '''', ''2019-06-17'');
INSERT INTO online_tools (ID, TOOL_NAME, URL, INTRODUCE, ADD_DATE) VALUES (2, ''在线代码格式化'', ''http://tool.oschina.net/codeformat/'', '''', ''2019-06-17'');
INSERT INTO online_tools (ID, TOOL_NAME, URL, INTRODUCE, ADD_DATE) VALUES (3, ''身份证号码查询验证'', ''http://qq.ip138.com/baidu-id/index.asp'', '''', ''2019-06-17'');
INSERT INTO online_tools (ID, TOOL_NAME, URL, INTRODUCE, ADD_DATE) VALUES (4, ''全国各地车牌查询表'', ''http://www.ip138.com/carlist.htm'', '''', ''2019-06-17'');
INSERT INTO online_tools (ID, TOOL_NAME, URL, INTRODUCE, ADD_DATE) VALUES (5, ''彩票开奖结果查询'', ''https://caipiao.ip138.com/'', '''', ''2019-06-17'');
INSERT INTO online_tools (ID, TOOL_NAME, URL, INTRODUCE, ADD_DATE) VALUES (6, ''邮编查询区号查询'', ''http://www.ip138.com/post/'', '''', ''2019-06-17'');
INSERT INTO online_tools (ID, TOOL_NAME, URL, INTRODUCE, ADD_DATE) VALUES (7, ''有道在线翻译'', ''http://fanyi.youdao.com/'', '''', ''2019-06-17'');
INSERT INTO online_tools (ID, TOOL_NAME, URL, INTRODUCE, ADD_DATE) VALUES (8, ''代码在线运行'', ''https://tool.lu/coderunner/'', '''', ''2019-06-17'');
INSERT INTO online_tools (ID, TOOL_NAME, URL, INTRODUCE, ADD_DATE) VALUES (9, ''在线透明favicon ico图标文件制作'', ''http://www.atool9.com/ico.php'', '''', ''2019-06-17'');
INSERT INTO online_tools (ID, TOOL_NAME, URL, INTRODUCE, ADD_DATE) VALUES (10, ''脚本之家在线工具'', ''http://tools.jb51.net/'', '''', ''2019-06-17'');
